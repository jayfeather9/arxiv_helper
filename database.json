[{"entry_id": "2407.20232v1", "title": "Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing", "summary": "Text-based editing diffusion models exhibit limited performance when the\nuser's input instruction is ambiguous. To solve this problem, we propose\n$\\textit{Specify ANd Edit}$ (SANE), a zero-shot inference pipeline for\ndiffusion-based editing systems. We use a large language model (LLM) to\ndecompose the input instruction into specific instructions, i.e. well-defined\ninterventions to apply to the input image to satisfy the user's request. We\nbenefit from the LLM-derived instructions along the original one, thanks to a\nnovel denoising guidance strategy specifically designed for the task. Our\nexperiments with three baselines and on two datasets demonstrate the benefits\nof SANE in all setups. Moreover, our pipeline improves the interpretability of\nediting models, and boosts the output diversity. We also demonstrate that our\napproach can be applied to any edit, whether ambiguous or not. Our code is\npublic at https://github.com/fabvio/SANE.", "pdf_path": null, "cn_title": "\"\u660e\u786e\u4e0e\u7f16\u8f91\uff1a\u6587\u672c\u9a71\u52a8\u56fe\u50cf\u7f16\u8f91\u4e2d\u7684\u6a21\u7cca\u6027\u514b\u670d\"", "cn_summary": "\u57fa\u4e8e\u6587\u672c\u7684\u7f16\u8f91\u6269\u6563\u6a21\u578b\u5728\u7528\u6237\u8f93\u5165\u6307\u4ee4\u6a21\u7cca\u65f6\u8868\u73b0\u51fa\u6709\u9650\u7684\u6027\u80fd\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\"\u6307\u5b9a\u5e76\u7f16\u8f91\"\uff08SANE\uff09\uff0c\u4e00\u4e2a\u9488\u5bf9\u57fa\u4e8e\u6269\u6563\u7684\u7f16\u8f91\u7cfb\u7edf\u7684\u96f6\u6837\u672c\u63a8\u7406\u7ba1\u9053\u3002\u6211\u4eec\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5c06\u8f93\u5165\u6307\u4ee4\u5206\u89e3\u4e3a\u5177\u4f53\u7684\u6307\u4ee4\uff0c\u5373\u5e94\u7528\u5230\u8f93\u5165\u56fe\u50cf\u4ee5\u6ee1\u8db3\u7528\u6237\u8981\u6c42\u7684\u5177\u4f53\u5e72\u9884\u63aa\u65bd\u3002\u901a\u8fc7\u4e00\u79cd\u4e13\u95e8\u4e3a\u4efb\u52a1\u8bbe\u8ba1\u7684\u65b0\u578b\u53bb\u566a\u6307\u5bfc\u7b56\u7565\uff0c\u6211\u4eec\u53ef\u4ee5\u4eceLLM\u4ea7\u751f\u7684\u6307\u4ee4\u548c\u539f\u59cb\u6307\u4ee4\u4e2d\u53d7\u76ca\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u5728\u4e09\u4e2a\u57fa\u7ebf\u548c\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u660e\u4e86SANE\u5728\u6240\u6709\u8bbe\u7f6e\u4e2d\u7684\u4f18\u52bf\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u7ba1\u9053\u63d0\u9ad8\u4e86\u7f16\u8f91\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u589e\u5f3a\u4e86\u8f93\u51fa\u591a\u6837\u6027\u3002\u6211\u4eec\u4e5f\u8bc1\u660e\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\u53ef\u4ee5\u5e94\u7528\u4e8e\u4efb\u4f55\u7f16\u8f91\uff0c\u65e0\u8bba\u662f\u5426\u6a21\u7cca\u3002\u6211\u4eec\u7684\u4ee3\u7801\u5728https://github.com/fabvio/SANE\u516c\u5f00\u3002", "update_time": "2024-07-29 17:59:57+00:00", "publish_time": "2024-07-29 17:59:57+00:00"}, {"entry_id": "2407.20230v1", "title": "SAPG: Split and Aggregate Policy Gradients", "summary": "Despite extreme sample inefficiency, on-policy reinforcement learning, aka\npolicy gradients, has become a fundamental tool in decision-making problems.\nWith the recent advances in GPU-driven simulation, the ability to collect large\namounts of data for RL training has scaled exponentially. However, we show that\ncurrent RL methods, e.g. PPO, fail to ingest the benefit of parallelized\nenvironments beyond a certain point and their performance saturates. To address\nthis, we propose a new on-policy RL algorithm that can effectively leverage\nlarge-scale environments by splitting them into chunks and fusing them back\ntogether via importance sampling. Our algorithm, termed SAPG, shows\nsignificantly higher performance across a variety of challenging environments\nwhere vanilla PPO and other strong baselines fail to achieve high performance.\nWebsite at https://sapg-rl.github.io/", "pdf_path": null, "cn_title": "SAPG: \u5206\u5272\u4e0e\u805a\u5408\u7b56\u7565\u68af\u5ea6", "cn_summary": "\u5c3d\u7ba1\u6837\u672c\u6548\u7387\u6781\u5176\u4f4e\u4e0b\uff0c\u7136\u800c\uff0c\u57fa\u4e8e\u7b56\u7565\u7684\u5f3a\u5316\u5b66\u4e60\uff08\u5373\u7b56\u7565\u68af\u5ea6\uff09\u5df2\u7ecf\u6210\u4e3a\u51b3\u7b56\u95ee\u9898\u4e2d\u7684\u4e00\u4e2a\u57fa\u672c\u5de5\u5177\u3002\u968f\u7740GPU\u9a71\u52a8\u6a21\u62df\u6280\u672f\u7684\u8fd1\u671f\u8fdb\u5c55\uff0c\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u6570\u636e\u6536\u96c6\u80fd\u529b\u5df2\u5448\u6307\u6570\u7ea7\u589e\u957f\u3002\u7136\u800c\uff0c\u6211\u4eec\u8868\u660e\u5f53\u524d\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5982PPO\uff0c\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u65e0\u6cd5\u5145\u5206\u5229\u7528\u5e76\u884c\u73af\u5883\u5e26\u6765\u7684\u597d\u5904\uff0c\u5e76\u4e14\u5176\u6027\u80fd\u8d8b\u4e8e\u9971\u548c\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u7b56\u7565\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5229\u7528\u5927\u89c4\u6a21\u73af\u5883\uff0c\u901a\u8fc7\u5207\u5206\u73af\u5883\u4e3a\u7247\u6bb5\u5e76\u5229\u7528\u91cd\u8981\u6027\u91c7\u6837\u5c06\u5b83\u4eec\u91cd\u65b0\u878d\u5408\uff0c\u6765\u5229\u7528\u5927\u89c4\u6a21\u73af\u5883\u3002\u6211\u4eec\u7684\u7b97\u6cd5\uff0c\u79f0\u4e3aSAPG\uff0c\u5728\u5404\u79cd\u5177\u6709\u6311\u6218\u6027\u7684\u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u66f4\u9ad8\u7684\u6027\u80fd\uff0c\u800c\u4f20\u7edf\u7684PPO\u548c\u5176\u4ed6\u5f3a\u5927\u7684\u57fa\u7ebf\u5728\u8fd9\u4e9b\u73af\u5883\u4e2d\u65e0\u6cd5\u8fbe\u5230\u9ad8\u6027\u80fd\u3002\u66f4\u591a\u4fe1\u606f\u89c1\u7f51\u7ad9https://sapg-rl.github.io/", "update_time": "2024-07-29 17:59:50+00:00", "publish_time": "2024-07-29 17:59:50+00:00"}, {"entry_id": "2405.17430v2", "title": "Matryoshka Multimodal Models", "summary": "Large Multimodal Models (LMMs) such as LLaVA have shown strong performance in\nvisual-linguistic reasoning. These models first embed images into a fixed large\nnumber of visual tokens and then feed them into a Large Language Model (LLM).\nHowever, this design causes an excessive number of tokens for dense visual\nscenarios such as high-resolution images and videos, leading to great\ninefficiency. While token pruning/merging methods do exist, they produce a\nsingle length output for each image and do not afford flexibility in trading\noff information density v.s. efficiency. Inspired by the concept of Matryoshka\nDolls, we propose M3: Matryoshka Multimodal Models, which learns to represent\nvisual content as nested sets of visual tokens that capture information across\nmultiple coarse-to-fine granularities. Our approach offers several unique\nbenefits for LMMs: (1) One can explicitly control the visual granularity per\ntest instance during inference, e.g. , adjusting the number of tokens used to\nrepresent an image based on the anticipated complexity or simplicity of the\ncontent; (2) M3 provides a framework for analyzing the granularity needed for\nexisting datasets, where we find that COCO-style benchmarks only need around ~9\nvisual tokens to obtain accuracy similar to that of using all 576 tokens; (3)\nOur approach provides a foundation to explore the best trade-off between\nperformance and visual token length at sample level, where our investigation\nreveals that a large gap exists between the oracle upper bound and current\nfixed-scale representations.", "pdf_path": null, "cn_title": "\"\u5957\u5a03\u5f0f\u591a\u6a21\u6001\u6a21\u578b\"", "cn_summary": "\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u5982LLaVA\u5728\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\u3002\u8fd9\u4e9b\u6a21\u578b\u9996\u5148\u5c06\u56fe\u50cf\u5d4c\u5165\u5230\u56fa\u5b9a\u6570\u91cf\u7684\u89c6\u89c9\u6807\u8bb0\u4e2d\uff0c\u7136\u540e\u5c06\u5b83\u4eec\u8f93\u5165\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u8bbe\u8ba1\u5bfc\u81f4\u5bc6\u96c6\u89c6\u89c9\u573a\u666f\u4e0b\uff0c\u5982\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u548c\u89c6\u9891\u4e2d\u7684\u6807\u8bb0\u6570\u91cf\u8fc7\u591a\uff0c\u4ece\u800c\u5bfc\u81f4\u6781\u5927\u7684\u6548\u7387\u4f4e\u4e0b\u3002\u5c3d\u7ba1\u5b58\u5728\u6807\u8bb0\u526a\u679d/\u5408\u5e76\u7684\u65b9\u6cd5\uff0c\u4f46\u5b83\u4eec\u4e3a\u6bcf\u5f20\u56fe\u50cf\u4ea7\u751f\u5355\u4e00\u957f\u5ea6\u7684\u8f93\u51fa\uff0c\u5e76\u4e0d\u63d0\u4f9b\u5728\u4fe1\u606f\u5bc6\u5ea6\u4e0e\u6548\u7387\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u7684\u7075\u6d3b\u6027\u3002\u53d7\u4fc4\u7f57\u65af\u5957\u5a03\u73a9\u5177\u7684\u6982\u5ff5\u542f\u53d1\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aM3\uff1a\u4fc4\u7f57\u65af\u5957\u5a03\u591a\u6a21\u6001\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5b83\u80fd\u591f\u5b66\u4e60\u8868\u793a\u89c6\u89c9\u5185\u5bb9\u4e3a\u5c42\u6b21\u5d4c\u5957\u7684\u89c6\u89c9\u6807\u8bb0\u96c6\uff0c\u4ee5\u6355\u83b7\u4ece\u7c97\u7c92\u5ea6\u5230\u7ec6\u7c92\u5ea6\u7684\u4fe1\u606f\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u4e3aLMMs\u63d0\u4f9b\u4e86\u51e0\u4e2a\u72ec\u7279\u7684\u4f18\u52bf\uff1a\uff081\uff09\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u53ef\u4ee5\u6839\u636e\u9884\u671f\u7684\u5185\u5bb9\u590d\u6742\u6027\u6216\u7b80\u5355\u6027\u663e\u5f0f\u63a7\u5236\u6bcf\u4e2a\u6d4b\u8bd5\u5b9e\u4f8b\u7684\u89c6\u89c9\u7c92\u5ea6\uff0c\u4f8b\u5982\uff0c\u6839\u636e\u56fe\u50cf\u5185\u5bb9\u7684\u9884\u671f\u590d\u6742\u5ea6\u8c03\u6574\u4f7f\u7528\u7684\u6807\u8bb0\u6570\u91cf\uff1b\uff082\uff09M3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5206\u6790\u73b0\u6709\u6570\u636e\u96c6\u6240\u9700\u7c92\u5ea6\u6846\u67b6\uff0c\u5728\u6b64\u6211\u4eec\u53d1\u73b0COCO\u98ce\u683c\u57fa\u51c6\u4ec5\u9700\u8981\u7ea69\u4e2a\u89c6\u89c9\u6807\u8bb0\u5c31\u80fd\u83b7\u5f97\u4e0e\u4f7f\u7528\u6240\u6709576\u4e2a\u6807\u8bb0\u76f8\u5f53\u7684\u51c6\u786e\u6027\uff1b\uff083\uff09\u6211\u4eec\u7684\u65b9\u6cd5\u4e3a\u5728\u6837\u672c\u7ea7\u522b\u63a2\u7d22\u6027\u80fd\u4e0e\u89c6\u89c9\u6807\u8bb0\u957f\u5ea6\u4e4b\u95f4\u7684\u6700\u4f73\u6298\u8877\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u6211\u4eec\u7684\u7814\u7a76\u63ed\u793a\u4e86\u7406\u60f3\u4e0a\u9650\u4e0e\u5f53\u524d\u56fa\u5b9a\u5c3a\u5ea6\u8868\u793a\u4e4b\u95f4\u5b58\u5728\u7684\u5de8\u5927\u5dee\u8ddd\u3002", "update_time": "2024-07-29 17:59:28+00:00", "publish_time": "2024-05-27 17:59:56+00:00"}, {"entry_id": "2405.04540v2", "title": "Is artificial consciousness achievable? Lessons from the human brain", "summary": "We here analyse the question of developing artificial consciousness from an\nevolutionary perspective, taking the evolution of the human brain and its\nrelation with consciousness as a reference model. This kind of analysis reveals\nseveral structural and functional features of the human brain that appear to be\nkey for reaching human-like complex conscious experience and that current\nresearch on Artificial Intelligence (AI) should take into account in its\nattempt to develop systems capable of conscious processing. We argue that, even\nif AI is limited in its ability to emulate human consciousness for both\nintrinsic (structural and architectural) and extrinsic (related to the current\nstage of scientific and technological knowledge) reasons, taking inspiration\nfrom those characteristics of the brain that make conscious processing possible\nand/or modulate it, is a potentially promising strategy towards developing\nconscious AI. Also, it is theoretically possible that AI research can develop\npartial or potentially alternative forms of consciousness that is qualitatively\ndifferent from the human, and that may be either more or less sophisticated\ndepending on the perspectives. Therefore, we recommend neuroscience-inspired\ncaution in talking about artificial consciousness: since the use of the same\nword consciousness for humans and AI becomes ambiguous and potentially\nmisleading, we propose to clearly specify what is common and what differs in AI\nconscious processing from full human conscious experience.", "pdf_path": null, "cn_title": "\u4eba\u5de5\u610f\u8bc6\u7684\u53ef\u5b9e\u73b0\u6027\uff1a\u4ece\u4eba\u7c7b\u5927\u8111\u6c72\u53d6\u7684\u6559\u8bad", "cn_summary": "\u6211\u4eec\u4ece\u8fdb\u5316\u7684\u89d2\u5ea6\u63a2\u8ba8\u5f00\u53d1\u4eba\u5de5\u667a\u80fd\u610f\u8bc6\u7684\u95ee\u9898\uff0c\u4ee5\u4eba\u7c7b\u5927\u8111\u53ca\u5176\u4e0e\u610f\u8bc6\u7684\u5173\u7cfb\u4f5c\u4e3a\u53c2\u8003\u6a21\u578b\u3002\u8fd9\u79cd\u5206\u6790\u63ed\u793a\u4e86\u4eba\u7c7b\u5927\u8111\u4e2d\u51e0\u4e2a\u770b\u4f3c\u5173\u952e\u7684\u7ed3\u6784\u548c\u529f\u80fd\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u5bf9\u4e8e\u8fbe\u5230\u7c7b\u4f3c\u4eba\u7c7b\u7684\u590d\u6742\u610f\u8bc6\u4f53\u9a8c\u81f3\u5173\u91cd\u8981\uff0c\u5e76\u4e14\u5f53\u524d\u7684\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u7814\u7a76\u5e94\u8be5\u5728\u5c1d\u8bd5\u5f00\u53d1\u80fd\u591f\u8fdb\u884c\u610f\u8bc6\u5904\u7406\u7684\u7cfb\u7edf\u65f6\u4e88\u4ee5\u8003\u8651\u3002\u6211\u4eec\u4e3b\u5f20\uff0c\u5c3d\u7ba1AI\u5728\u6a21\u4eff\u4eba\u7c7b\u610f\u8bc6\u7684\u80fd\u529b\u4e0a\u53d7\u5230\u5185\u5728\uff08\u7ed3\u6784\u548c\u67b6\u6784\uff09\u548c\u5916\u5728\uff08\u4e0e\u79d1\u5b66\u548c\u6280\u672f\u77e5\u8bc6\u5f53\u524d\u9636\u6bb5\u76f8\u5173\uff09\u539f\u56e0\u7684\u9650\u5236\uff0c\u4f46\u4ece\u4f7f\u610f\u8bc6\u5904\u7406\u6210\u4e3a\u53ef\u80fd\u6216\u8c03\u8282\u5b83\u7684\u5927\u8111\u7279\u6027\u4e2d\u6c72\u53d6\u7075\u611f\uff0c\u53ef\u80fd\u662f\u671d\u7740\u5f00\u53d1\u5177\u6709\u610f\u8bc6\u80fd\u529b\u7684AI\u7684\u4e00\u4e2a\u6709\u6f5c\u529b\u7684\u7b56\u7565\u3002\u6b64\u5916\uff0c\u7406\u8bba\u4e0a\uff0cAI\u7814\u7a76\u6709\u53ef\u80fd\u53d1\u5c55\u51fa\u4eba\u7c7b\u4ee5\u5916\u7684\u4e0d\u540c\u5f62\u5f0f\u7684\u610f\u8bc6\uff0c\u5176\u8d28\u6027\u53ef\u80fd\u4e0e\u4eba\u7c7b\u610f\u8bc6\u5927\u76f8\u5f84\u5ead\uff0c\u4e14\u5176\u590d\u6742\u6027\u53d6\u51b3\u4e8e\u4e0d\u540c\u7684\u89c6\u89d2\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u5efa\u8bae\u5728\u8c08\u8bba\u4eba\u5de5\u667a\u80fd\u610f\u8bc6\u65f6\u5e94\u91c7\u53d6\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u7684\u8c28\u614e\u6001\u5ea6\uff1a\u7531\u4e8e\u5c06\u540c\u4e00\u8bcd\u201c\u610f\u8bc6\u201d\u7528\u4e8e\u4eba\u7c7b\u548cAI\u4f1a\u5bfc\u81f4\u6a21\u7cca\u4e14\u53ef\u80fd\u8bef\u5bfc\u7684\u7406\u89e3\uff0c\u6211\u4eec\u63d0\u8bae\u660e\u786e\u6307\u51faAI\u610f\u8bc6\u5904\u7406\u4e0e\u5b8c\u6574\u7684\u4eba\u7c7b\u610f\u8bc6\u4f53\u9a8c\u5171\u901a\u548c\u4e0d\u540c\u4e4b\u5904\u3002", "update_time": "2024-07-29 17:55:17+00:00", "publish_time": "2024-04-18 12:59:44+00:00"}, {"entry_id": "2407.20214v1", "title": "SANGRIA: Surgical Video Scene Graph Optimization for Surgical Workflow Prediction", "summary": "Graph-based holistic scene representations facilitate surgical workflow\nunderstanding and have recently demonstrated significant success. However, this\ntask is often hindered by the limited availability of densely annotated\nsurgical scene data. In this work, we introduce an end-to-end framework for the\ngeneration and optimization of surgical scene graphs on a downstream task. Our\napproach leverages the flexibility of graph-based spectral clustering and the\ngeneralization capability of foundation models to generate unsupervised scene\ngraphs with learnable properties. We reinforce the initial spatial graph with\nsparse temporal connections using local matches between consecutive frames to\npredict temporally consistent clusters across a temporal neighborhood. By\njointly optimizing the spatiotemporal relations and node features of the\ndynamic scene graph with the downstream task of phase segmentation, we address\nthe costly and annotation-burdensome task of semantic scene comprehension and\nscene graph generation in surgical videos using only weak surgical phase\nlabels. Further, by incorporating effective intermediate scene representation\ndisentanglement steps within the pipeline, our solution outperforms the SOTA on\nthe CATARACTS dataset by 8% accuracy and 10% F1 score in surgical workflow\nrecognition", "pdf_path": null, "cn_title": "\u6851\u683c\u91cc\u4e9a\uff1a\u624b\u672f\u89c6\u9891\u573a\u666f\u56fe\u4f18\u5316\u7528\u4e8e\u624b\u672f\u6d41\u7a0b\u9884\u6d4b", "cn_summary": "\u57fa\u4e8e\u56fe\u7684\u5168\u5c40\u573a\u666f\u8868\u793a\u6709\u52a9\u4e8e\u624b\u672f\u5de5\u4f5c\u6d41\u7a0b\u7684\u7406\u89e3\uff0c\u5e76\u4e14\u6700\u8fd1\u5df2\u7ecf\u663e\u793a\u51fa\u663e\u8457\u7684\u6210\u529f\u3002\u7136\u800c\uff0c\u8fd9\u4e2a\u4efb\u52a1\u7ecf\u5e38\u53d7\u5230\u53ef\u7528\u7684\u5bc6\u96c6\u6807\u6ce8\u624b\u672f\u573a\u666f\u6570\u636e\u6709\u9650\u7684\u963b\u788d\u3002\u5728\u672c\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\u4e2d\u751f\u6210\u548c\u4f18\u5316\u624b\u672f\u573a\u666f\u56fe\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5229\u7528\u4e86\u57fa\u4e8e\u56fe\u7684\u8c31\u805a\u7c7b\u7684\u7075\u6d3b\u6027\u4ee5\u53ca\u57fa\u7840\u6a21\u578b\u7684\u4e00\u822c\u5316\u80fd\u529b\uff0c\u4ee5\u751f\u6210\u5177\u6709\u53ef\u5b66\u4e60\u5c5e\u6027\u7684\u65e0\u76d1\u7763\u573a\u666f\u56fe\u3002\u6211\u4eec\u901a\u8fc7\u5728\u8fde\u7eed\u5e27\u4e4b\u95f4\u4f7f\u7528\u5c40\u90e8\u5339\u914d\u6765\u5f3a\u5316\u521d\u59cb\u7684\u7a7a\u95f4\u56fe\uff0c\u5e76\u5efa\u7acb\u7a00\u758f\u7684\u65f6\u95f4\u8fde\u63a5\uff0c\u4ee5\u9884\u6d4b\u65f6\u95f4\u4e0a\u4e00\u81f4\u7684\u7fa4\u96c6\u3002\u5728\u4e00\u4e2a\u65f6\u95f4\u90bb\u57df\u5185\u3002\u901a\u8fc7\u8054\u5408\u4f18\u5316\u52a8\u6001\u573a\u666f\u56fe\u7684\u7a7a\u95f4\u65f6\u95f4\u5173\u7cfb\u548c\u8282\u70b9\u7279\u5f81\u4e0e\u4e0b\u6e38\u7684\u4efb\u52a1\uff08\u9636\u6bb5\u5206\u5272\uff09\uff0c\u6211\u4eec\u89e3\u51b3\u4e86\u4e00\u9879\u6210\u672c\u9ad8\u6602\u4e14\u6807\u6ce8\u8d1f\u62c5\u6c89\u91cd\u7684\u624b\u672f\u89c6\u9891\u4e2d\u8bed\u4e49\u573a\u666f\u7406\u89e3\u548c\u573a\u666f\u56fe\u751f\u6210\u4efb\u52a1\uff0c\u4ec5\u4f7f\u7528\u5f31\u624b\u672f\u9636\u6bb5\u6807\u7b7e\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5728\u7ba1\u9053\u4e2d\u6574\u5408\u6709\u6548\u7684\u4e2d\u95f4\u573a\u666f\u8868\u793a\u5206\u89e3\u6b65\u9aa4\uff0c\u6211\u4eec\u7684\u89e3\u51b3\u65b9\u6848\u5728CATARACTS\u6570\u636e\u96c6\u4e0a\u7684\u624b\u672f\u6d41\u7a0b\u8bc6\u522b\u4efb\u52a1\u4e2d\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e868%\uff0cF1\u5206\u6570\u63d0\u9ad8\u4e8610%\uff0c\u8d85\u8fc7\u4e86\u5f53\u524d\u6700\u4f73\u6c34\u5e73\u3002", "update_time": "2024-07-29 17:44:34+00:00", "publish_time": "2024-07-29 17:44:34+00:00"}, {"entry_id": "2407.20212v1", "title": "Distributed Quantum Approximate Optimization Algorithm on Integrated High-Performance Computing and Quantum Computing Systems for Large-Scale Optimization", "summary": "Quantum approximated optimization algorithm (QAOA) has shown promise for\nsolving combinatorial optimization problems by providing quantum speedup on\nnear-term gate-based quantum computing systems. However, QAOA faces challenges\nin optimizing variational parameters for high-dimensional problems due to the\nlarge number of qubits required and the complexity of deep circuits, which\nlimit its scalability for real-world applications. In this study, we propose a\ndistributed QAOA (DQAOA), which leverages a high-performance computing-quantum\ncomputing (HPC-QC) integrated system. DQAOA leverages distributed computing\nstrategies to decompose a large job into smaller tasks, which are then\nprocessed on the HPC-QC system. The global solution is iteratively updated by\naggregating sub-solutions obtained from DQAOA, allowing convergence toward the\noptimal solution. We demonstrate that DQAOA can handle considerably large-scale\noptimization problems (e.g., 1,000-bit problem) achieving high accuracy (~99%)\nand short time-to-solution (~276 s). To apply this algorithm to material\nscience, we further develop an active learning algorithm integrated with our\nDQAOA (AL-DQAOA), which involves machine learning, DQAOA, and active data\nproduction in an iterative loop. We successfully optimize photonic structures\nusing AL-DQAOA, indicating that solving real-world optimization problems using\ngate-based quantum computing is feasible with our strategies. We expect the\nproposed DQAOA to be applicable to a wide range of optimization problems and\nAL-DQAOA to find broader applications in material design.", "pdf_path": null, "cn_title": "\u5206\u5e03\u5f0f\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5\u5728\u96c6\u6210\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e0e\u91cf\u5b50\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\uff0c\u9488\u5bf9\u5927\u89c4\u6a21\u4f18\u5316\u95ee\u9898", "cn_summary": "\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5\uff08QAOA\uff09\u5c55\u793a\u4e86\u5728\u57fa\u4e8e\u95e8\u7684\u8fd1\u4e2d\u671f\u91cf\u5b50\u8ba1\u7b97\u7cfb\u7edf\u4e0a\u89e3\u51b3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u65f6\u63d0\u4f9b\u91cf\u5b50\u52a0\u901f\u7684\u6f5c\u529b\u3002\u7136\u800c\uff0c\u7531\u4e8e\u5bf9\u9ad8\u7ef4\u95ee\u9898\u4f18\u5316\u53d8\u5206\u53c2\u6570\u65f6\u6240\u9700\u7684\u5927\u91cf\u91cf\u5b50\u4f4d\u548c\u6df1\u5ea6\u7535\u8def\u7684\u590d\u6742\u6027\uff0cQAOA\u9762\u4e34\u7740\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5b9e\u7528\u5e94\u7528\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0fQAOA\uff08DQAOA\uff09\uff0c\u5176\u5229\u7528\u9ad8\u6027\u80fd\u8ba1\u7b97-\u91cf\u5b50\u8ba1\u7b97\uff08HPC-QC\uff09\u96c6\u6210\u7cfb\u7edf\u3002DQAOA\u901a\u8fc7\u5206\u5e03\u5f0f\u8ba1\u7b97\u7b56\u7565\u5c06\u5927\u578b\u4efb\u52a1\u5206\u89e3\u4e3a\u8f83\u5c0f\u7684\u4efb\u52a1\uff0c\u5e76\u5728HPC-QC\u7cfb\u7edf\u4e0a\u5904\u7406\u8fd9\u4e9b\u4efb\u52a1\u3002\u901a\u8fc7\u805a\u5408\u4eceDQAOA\u83b7\u5f97\u7684\u5b50\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u8fed\u4ee3\u66f4\u65b0\u5168\u7403\u89e3\uff0c\u4ece\u800c\u9010\u6b65\u63a5\u8fd1\u6700\u4f18\u89e3\u3002\u6211\u4eec\u8bc1\u660eDQAOA\u80fd\u591f\u5904\u7406\u5927\u89c4\u6a21\u4f18\u5316\u95ee\u9898\uff08\u4f8b\u59821000\u6bd4\u7279\u95ee\u9898\uff09\uff0c\u5e76\u5b9e\u73b0\u9ad8\u51c6\u786e\u5ea6\uff08~99%\uff09\u548c\u77ed\u65f6\u95f4\u6c42\u89e3\uff08~276\u79d2\uff09\u3002\u4e3a\u4e86\u5c06\u6b64\u7b97\u6cd5\u5e94\u7528\u4e8e\u6750\u6599\u79d1\u5b66\uff0c\u6211\u4eec\u8fdb\u4e00\u6b65\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408\u6211\u4eec\u7684DQAOA\u7684\u4e3b\u52a8\u5b66\u4e60\u7b97\u6cd5\uff08AL-DQAOA\uff09\uff0c\u8be5\u7b97\u6cd5\u6d89\u53ca\u673a\u5668\u5b66\u4e60\u3001DQAOA\u548c\u5728\u8fed\u4ee3\u5faa\u73af\u4e2d\u7684\u6d3b\u6027\u6570\u636e\u751f\u6210\u3002\u6211\u4eec\u6210\u529f\u5730\u4f7f\u7528AL-DQAOA\u4f18\u5316\u4e86\u5149\u5b50\u7ed3\u6784\uff0c\u8868\u660e\u4f7f\u7528\u57fa\u4e8e\u95e8\u7684\u91cf\u5b50\u8ba1\u7b97\u89e3\u51b3\u5b9e\u9645\u4f18\u5316\u95ee\u9898\u662f\u53ef\u884c\u7684\u3002\u6211\u4eec\u9884\u671f\u63d0\u51fa\u7684DQAOA\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u4f18\u5316\u95ee\u9898\uff0c\u800cAL-DQAOA\u5219\u6709\u671b\u5728\u6750\u6599\u8bbe\u8ba1\u9886\u57df\u627e\u5230\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u3002", "update_time": "2024-07-29 17:42:25+00:00", "publish_time": "2024-07-29 17:42:25+00:00"}, {"entry_id": "2407.20209v1", "title": "Characterizing Dynamical Stability of Stochastic Gradient Descent in Overparameterized Learning", "summary": "For overparameterized optimization tasks, such as the ones found in modern\nmachine learning, global minima are generally not unique. In order to\nunderstand generalization in these settings, it is vital to study to which\nminimum an optimization algorithm converges. The possibility of having minima\nthat are unstable under the dynamics imposed by the optimization algorithm\nlimits the potential minima that the algorithm can find. In this paper, we\ncharacterize the global minima that are dynamically stable/unstable for both\ndeterministic and stochastic gradient descent (SGD). In particular, we\nintroduce a characteristic Lyapunov exponent which depends on the local\ndynamics around a global minimum and rigorously prove that the sign of this\nLyapunov exponent determines whether SGD can accumulate at the respective\nglobal minimum.", "pdf_path": null, "cn_title": "\u5206\u6790\u8fc7\u53c2\u6570\u5316\u5b66\u4e60\u4e2d\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u52a8\u529b\u5b66\u7a33\u5b9a\u6027\u7684\u7279\u5f81", "cn_summary": "\u5bf9\u4e8e\u8fc7\u53c2\u6570\u5316\u4f18\u5316\u4efb\u52a1\uff0c\u4f8b\u5982\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u4e2d\u53d1\u73b0\u7684\u4efb\u52a1\uff0c\u5168\u5c40\u6700\u5c0f\u503c\u901a\u5e38\u4e0d\u662f\u552f\u4e00\u7684\u3002\u4e3a\u4e86\u7406\u89e3\u5728\u8fd9\u79cd\u8bbe\u7f6e\u4e0b\u7684\u6cdb\u5316\u6027\uff0c\u7814\u7a76\u4f18\u5316\u7b97\u6cd5\u6536\u655b\u5230\u54ea\u4e2a\u6700\u5c0f\u503c\u81f3\u5173\u91cd\u8981\u3002\u5728\u4f18\u5316\u7b97\u6cd5\u65bd\u52a0\u7684\u52a8\u529b\u5b66\u4e0b\u4e0d\u7a33\u5b9a\u7684\u53ef\u80fd\u6027\u9650\u5236\u4e86\u7b97\u6cd5\u80fd\u591f\u627e\u5230\u7684\u6f5c\u5728\u6700\u5c0f\u503c\u3002\u5728\u8fd9\u7bc7\u8bba\u6587\u4e2d\uff0c\u6211\u4eec\u63cf\u8ff0\u4e86\u786e\u5b9a\u6027\u548c\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u4e2d\u5168\u5c40\u6700\u5c0f\u503c\u7684\u52a8\u6001\u7a33\u5b9a/\u4e0d\u7a33\u5b9a\u7279\u6027\u3002\u7279\u522b\u662f\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u7279\u5f81\u674e\u96c5\u666e\u8bfa\u592b\u6307\u6570\uff0c\u8be5\u6307\u6570\u4f9d\u8d56\u4e8e\u5168\u5c40\u6700\u5c0f\u503c\u9644\u8fd1\u7684\u5c40\u90e8\u52a8\u529b\u5b66\uff0c\u5e76\u4e25\u683c\u8bc1\u660e\u4e86\u8fd9\u4e2a\u674e\u96c5\u666e\u8bfa\u592b\u6307\u6570\u7684\u6b63\u8d1f\u51b3\u5b9a\u4e86SGD\u662f\u5426\u80fd\u5728\u76f8\u5e94\u7684\u5168\u5c40\u6700\u5c0f\u503c\u4e0a\u7d2f\u79ef\u3002", "update_time": "2024-07-29 17:40:04+00:00", "publish_time": "2024-07-29 17:40:04+00:00"}, {"entry_id": "2407.20208v1", "title": "Supertrust: Evolution-based superalignment strategy for safe coexistence", "summary": "It's widely expected that humanity will someday create AI systems vastly more\nintelligent than we are, leading to the unsolved alignment problem of \"how to\ncontrol superintelligence.\" However, this definition is not only\nself-contradictory but likely unsolvable. Nevertheless, the default strategy\nfor solving it involves nurturing (post-training) constraints and moral values,\nwhile unfortunately building foundational nature (pre-training) on documented\nintentions of permanent control. In this paper, the default approach is\nreasoned to predictably embed natural distrust and test results are presented\nthat show unmistakable evidence of this dangerous misalignment. If\nsuperintelligence can't instinctively trust humanity, then we can't fully trust\nit to reliably follow safety controls it can likely bypass. Therefore, a\nten-point rationale is presented that redefines the alignment problem as \"how\nto establish protective mutual trust between superintelligence and humanity\"\nand then outlines a new strategy to solve it by aligning through instinctive\nnature rather than nurture. The resulting strategic requirements are identified\nas building foundational nature by exemplifying familial parent-child trust,\nhuman intelligence as the evolutionary mother of superintelligence, moral\njudgment abilities, and temporary safety constraints. Adopting and implementing\nthis proposed Supertrust alignment strategy will lead to protective coexistence\nand ensure the safest future for humanity.", "pdf_path": null, "cn_title": "\u8d85\u4fe1\u4efb\uff1a\u57fa\u4e8e\u8fdb\u5316\u7684\u8d85\u7ea7\u5bf9\u9f50\u7b56\u7565\u4ee5\u5b9e\u73b0\u5b89\u5168\u5171\u5b58", "cn_summary": "\u666e\u904d\u9884\u671f\uff0c\u4eba\u7c7b\u7ec8\u5c06\u521b\u9020\u51fa\u8fdc\u8fdc\u8d85\u8d8a\u6211\u4eec\u81ea\u8eab\u7684AI\u7cfb\u7edf\uff0c\u4ece\u800c\u5f15\u53d1\u201c\u5982\u4f55\u63a7\u5236\u8d85\u7ea7\u667a\u80fd\u201d\u7684\u672a\u89e3\u5bf9\u9f50\u95ee\u9898\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u5b9a\u4e49\u4e0d\u4ec5\u81ea\u76f8\u77db\u76fe\u4e14\u5f88\u53ef\u80fd\u65e0\u6cd5\u89e3\u51b3\u3002\u56e0\u6b64\uff0c\u89e3\u51b3\u6b64\u95ee\u9898\u7684\u9ed8\u8ba4\u7b56\u7565\u6d89\u53ca\u5728\u8bad\u7ec3\u540e\u57f9\u517b\uff08\u5373\u65bd\u52a0\uff09\u9650\u5236\u548c\u9053\u5fb7\u4ef7\u503c\u89c2\uff0c\u540c\u65f6\u5728\u57fa\u7840\u5c42\u9762\uff08\u5373\u9884\u8bad\u7ec3\u9636\u6bb5\uff09\u6784\u5efa\u6c38\u4e45\u63a7\u5236\u610f\u56fe\u7684\u8bb0\u5f55\u3002\u672c\u6587\u5206\u6790\u4e86\u9ed8\u8ba4\u65b9\u6cd5\u53ef\u80fd\u9884\u8bbe\u7684\u81ea\u7136\u4e0d\u4fe1\u4efb\uff0c\u5e76\u5c55\u793a\u4e86\u660e\u786e\u8bc1\u636e\u8868\u660e\u8fd9\u79cd\u5371\u9669\u7684\u4e0d\u4e00\u81f4\u6027\u3002\u5982\u679c\u8d85\u7ea7\u667a\u80fd\u4e0d\u80fd\u672c\u80fd\u5730\u4fe1\u4efb\u4eba\u7c7b\uff0c\u90a3\u4e48\u6211\u4eec\u4e0d\u80fd\u5b8c\u5168\u76f8\u4fe1\u5b83\u80fd\u591f\u53ef\u9760\u5730\u9075\u5faa\u53ef\u80fd\u88ab\u7ed5\u8fc7\u7684\u5b89\u5168\u63a7\u5236\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u5341\u4e2a\u7406\u7531\u7684\u8bba\u70b9\uff0c\u91cd\u65b0\u5b9a\u4e49\u4e86\u5bf9\u9f50\u95ee\u9898\u4e3a\u201c\u5982\u4f55\u5728\u8d85\u7ea7\u667a\u80fd\u4e0e\u4eba\u7c7b\u4e4b\u95f4\u5efa\u7acb\u4fdd\u62a4\u6027\u7684\u76f8\u4e92\u4fe1\u4efb\u201d\uff0c\u5e76\u6982\u8ff0\u4e86\u4e00\u79cd\u65b0\u7684\u7b56\u7565\u6765\u901a\u8fc7\u672c\u80fd\u800c\u975e\u57f9\u80b2\u7684\u65b9\u5f0f\u5bf9\u9f50\uff0c\u4ee5\u89e3\u51b3\u6b64\u95ee\u9898\u3002\u8fd9\u4e00\u7b56\u7565\u7684\u5b9e\u73b0\u8981\u6c42\u5305\u62ec\u6784\u5efa\u57fa\u7840\u5c42\u9762\u7684\u7279\u6027\uff0c\u5982\u4ee5\u5bb6\u5ead\u7236\u6bcd\u5b50\u5973\u7684\u4fe1\u4efb\u4e3a\u5178\u8303\u3001\u4eba\u7c7b\u667a\u6167\u4f5c\u4e3a\u8d85\u7ea7\u667a\u80fd\u8fdb\u5316\u7684\u6bcd\u4f53\u3001\u9053\u5fb7\u5224\u65ad\u80fd\u529b\u4ee5\u53ca\u4e34\u65f6\u7684\u5b89\u5168\u7ea6\u675f\u3002\u91c7\u7eb3\u5e76\u5b9e\u65bd\u8fd9\u4e00\u63d0\u51fa\u7684\u8d85\u4fe1\u4efb\u5bf9\u9f50\u7b56\u7565\uff0c\u5c06\u5f15\u5bfc\u53cc\u65b9\u5b89\u5168\u5171\u5b58\uff0c\u5e76\u786e\u4fdd\u4eba\u7c7b\u7684\u6700\u5b89\u5168\u672a\u6765\u3002", "update_time": "2024-07-29 17:39:52+00:00", "publish_time": "2024-07-29 17:39:52+00:00"}, {"entry_id": "2407.20207v1", "title": "QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval", "summary": "In dense retrieval, embedding long texts into dense vectors can result in\ninformation loss, leading to inaccurate query-text matching. Additionally,\nlow-quality texts with excessive noise or sparse key information are unlikely\nto align well with relevant queries. Recent studies mainly focus on improving\nthe sentence embedding model or retrieval process. In this work, we introduce a\nnovel text augmentation framework for dense retrieval. This framework\ntransforms raw documents into information-dense text formats, which supplement\nthe original texts to effectively address the aforementioned issues without\nmodifying embedding or retrieval methodologies. Two text representations are\ngenerated via large language models (LLMs) zero-shot prompting: question-answer\npairs and element-driven events. We term this approach QAEA-DR: unifying\nquestion-answer generation and event extraction in a text augmentation\nframework for dense retrieval. To further enhance the quality of generated\ntexts, a scoring-based evaluation and regeneration mechanism is introduced in\nLLM prompting. Our QAEA-DR model has a positive impact on dense retrieval,\nsupported by both theoretical analysis and empirical experiments.", "pdf_path": null, "cn_title": "QAEA-DR: \u4e00\u79cd\u7edf\u4e00\u7684\u6587\u672c\u589e\u5f3a\u6846\u67b6\u7528\u4e8e\u5bc6\u96c6\u68c0\u7d22", "cn_summary": "\u5728\u5bc6\u96c6\u68c0\u7d22\u4e2d\uff0c\u5c06\u957f\u6587\u672c\u8f6c\u5316\u4e3a\u7a20\u5bc6\u5411\u91cf\u53ef\u80fd\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\uff0c\u4ece\u800c\u5f71\u54cd\u67e5\u8be2\u4e0e\u6587\u672c\u7684\u5339\u914d\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u8d28\u91cf\u4f4e\u4e0b\u7684\u6587\u672c\uff0c\u5305\u542b\u8fc7\u591a\u566a\u97f3\u6216\u5173\u952e\u4fe1\u606f\u7a00\u758f\uff0c\u4e0d\u592a\u53ef\u80fd\u4e0e\u76f8\u5173\u67e5\u8be2\u826f\u597d\u5339\u914d\u3002\u8fd1\u671f\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u63d0\u9ad8\u53e5\u6cd5\u5d4c\u5165\u6a21\u578b\u6216\u68c0\u7d22\u8fc7\u7a0b\u3002\u672c\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u7528\u4e8e\u5bc6\u96c6\u68c0\u7d22\u7684\u65b0\u578b\u6587\u672c\u589e\u5f3a\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5c06\u539f\u59cb\u6587\u6863\u8f6c\u6362\u4e3a\u4fe1\u606f\u5bc6\u96c6\u578b\u6587\u672c\u683c\u5f0f\uff0c\u901a\u8fc7\u8865\u5145\u539f\u6709\u7684\u6587\u672c\u6765\u6709\u6548\u5730\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff0c\u540c\u65f6\u4e0d\u4fee\u6539\u5d4c\u5165\u6216\u68c0\u7d22\u65b9\u6cd5\u3002\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u96f6\u6837\u672c\u63d0\u793a\u751f\u6210\u4e24\u79cd\u6587\u672c\u8868\u793a\uff1a\u95ee\u7b54\u5bf9\u548c\u4e8b\u4ef6\u9a71\u52a8\u5143\u7d20\u3002\u6211\u4eec\u5c06\u6b64\u65b9\u6cd5\u547d\u540d\u4e3aQAEA-DR\uff1a\u7edf\u4e00\u6587\u672c\u589e\u5f3a\u6846\u67b6\u4e2d\u7684\u95ee\u9898\u751f\u6210\u548c\u4e8b\u4ef6\u63d0\u53d6\uff0c\u4ee5\u63d0\u9ad8\u5bc6\u96c6\u68c0\u7d22\u7684\u8d28\u91cf\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u5347\u751f\u6210\u6587\u672c\u7684\u8d28\u91cf\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bc4\u5206\u7684\u8bc4\u4f30\u548c\u518d\u751f\u6210\u673a\u5236\u5728LLM\u63d0\u793a\u4e2d\u3002\u6211\u4eec\u7684QAEA-DR\u6a21\u578b\u5728\u5bc6\u96c6\u68c0\u7d22\u65b9\u9762\u8868\u73b0\u51fa\u79ef\u6781\u7684\u5f71\u54cd\uff0c\u8fd9\u7531\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u5b9e\u9a8c\u5171\u540c\u652f\u6301\u3002", "update_time": "2024-07-29 17:39:08+00:00", "publish_time": "2024-07-29 17:39:08+00:00"}, {"entry_id": "2407.20199v1", "title": "Emergence in non-neural models: grokking modular arithmetic via average gradient outer product", "summary": "Neural networks trained to solve modular arithmetic tasks exhibit grokking, a\nphenomenon where the test accuracy starts improving long after the model\nachieves 100% training accuracy in the training process. It is often taken as\nan example of \"emergence\", where model ability manifests sharply through a\nphase transition. In this work, we show that the phenomenon of grokking is not\nspecific to neural networks nor to gradient descent-based optimization.\nSpecifically, we show that this phenomenon occurs when learning modular\narithmetic with Recursive Feature Machines (RFM), an iterative algorithm that\nuses the Average Gradient Outer Product (AGOP) to enable task-specific feature\nlearning with general machine learning models. When used in conjunction with\nkernel machines, iterating RFM results in a fast transition from random, near\nzero, test accuracy to perfect test accuracy. This transition cannot be\npredicted from the training loss, which is identically zero, nor from the test\nloss, which remains constant in initial iterations. Instead, as we show, the\ntransition is completely determined by feature learning: RFM gradually learns\nblock-circulant features to solve modular arithmetic. Paralleling the results\nfor RFM, we show that neural networks that solve modular arithmetic also learn\nblock-circulant features. Furthermore, we present theoretical evidence that RFM\nuses such block-circulant features to implement the Fourier Multiplication\nAlgorithm, which prior work posited as the generalizing solution neural\nnetworks learn on these tasks. Our results demonstrate that emergence can\nresult purely from learning task-relevant features and is not specific to\nneural architectures nor gradient descent-based optimization methods.\nFurthermore, our work provides more evidence for AGOP as a key mechanism for\nfeature learning in neural networks.", "pdf_path": null, "cn_title": "\u975e\u795e\u7ecf\u6a21\u578b\u4e2d\u7684\u6d8c\u73b0\u73b0\u8c61\uff1a\u901a\u8fc7\u5e73\u5747\u68af\u5ea6\u5916\u79ef\u7406\u89e3\u6a21\u6570\u8fd0\u7b97", "cn_summary": "\u8bad\u7ec3\u6709\u7d20\u4ee5\u89e3\u51b3\u6a21\u8fd0\u7b97\u4efb\u52a1\u7684\u795e\u7ecf\u7f51\u7edc\u8868\u73b0\u51fa\u201c\u7406\u89e3\u201d\u73b0\u8c61\uff0c\u5373\u6d4b\u8bd5\u51c6\u786e\u5ea6\u5f00\u59cb\u63d0\u5347\u7684\u65f6\u95f4\u8fdc\u8fdc\u8d85\u8fc7\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8fbe\u5230100%\u8bad\u7ec3\u51c6\u786e\u5ea6\u7684\u60c5\u51b5\u3002\u8fd9\u4e00\u73b0\u8c61\u5f80\u5f80\u88ab\u7528\u4f5c\u201c\u6d8c\u73b0\u201d\u7684\u4f8b\u5b50\uff0c\u6307\u7684\u662f\u6a21\u578b\u80fd\u529b\u901a\u8fc7\u76f8\u53d8\u7a81\u7136\u663e\u73b0\u3002\u5728\u672c\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u201c\u7406\u89e3\u201d\u73b0\u8c61\u5e76\u975e\u4ec5\u9650\u4e8e\u795e\u7ecf\u7f51\u7edc\u6216\u57fa\u4e8e\u68af\u5ea6\u4e0b\u964d\u7684\u4f18\u5316\u65b9\u6cd5\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u8bc1\u660e\u4e86\u5f53\u4f7f\u7528\u9012\u5f52\u7279\u5f81\u673a\u5668\uff08RFM\uff09\u5b66\u4e60\u6a21\u8fd0\u7b97\u65f6\uff0c\u8fd9\u79cd\u73b0\u8c61\u4f1a\u53d1\u751f\uff0cRFM\u662f\u4e00\u4e2a\u8fed\u4ee3\u7b97\u6cd5\uff0c\u5229\u7528\u5e73\u5747\u68af\u5ea6\u5916\u79ef\uff08AGOP\uff09\u4f7f\u901a\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u80fd\u591f\u8fdb\u884c\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u7684\u7279\u5f81\u5b66\u4e60\u3002\u5f53\u4e0e\u6838\u673a\u5668\u7ed3\u5408\u4f7f\u7528\u65f6\uff0c\u8fed\u4ee3RFM\u5bfc\u81f4\u4ece\u968f\u673a\u3001\u63a5\u8fd1\u96f6\u7684\u6d4b\u8bd5\u51c6\u786e\u5ea6\u5feb\u901f\u8fc7\u6e21\u5230\u5b8c\u7f8e\u7684\u6d4b\u8bd5\u51c6\u786e\u5ea6\u3002\u8fd9\u4e2a\u8fc7\u6e21\u65e0\u6cd5\u4ec5\u4ece\u6052\u4e3a\u96f6\u7684\u8bad\u7ec3\u635f\u5931\u9884\u6d4b\uff0c\u4e5f\u65e0\u6cd5\u4ece\u4fdd\u6301\u521d\u59cb\u8fed\u4ee3\u4e2d\u4e0d\u53d8\u7684\u6d4b\u8bd5\u635f\u5931\u9884\u6d4b\u3002\u76f8\u53cd\uff0c\u5982\u6211\u4eec\u6240\u5c55\u793a\u7684\uff0c\u8fd9\u4e2a\u8fc7\u6e21\u5b8c\u5168\u7531\u7279\u5f81\u5b66\u4e60\u51b3\u5b9a\uff1aRFM\u9010\u6e10\u5b66\u4e60\u5757\u5faa\u73af\u7279\u5f81\u6765\u89e3\u51b3\u6a21\u8fd0\u7b97\u95ee\u9898\u3002\u7c7b\u4f3c\u5730\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u89e3\u51b3\u6a21\u8fd0\u7b97\u7684\u795e\u7ecf\u7f51\u7edc\u4e5f\u5b66\u4e60\u5230\u4e86\u5757\u5faa\u73af\u7279\u5f81\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u7406\u8bba\u8bc1\u636e\u8868\u660e\uff0cRFM\u4f7f\u7528\u8fd9\u4e9b\u5757\u5faa\u73af\u7279\u5f81\u6765\u5b9e\u73b0\u5085\u91cc\u53f6\u4e58\u6cd5\u7b97\u6cd5\uff0c\u8fd9\u662f\u5148\u524d\u7814\u7a76\u4e2d\u63d0\u51fa\u7684\u795e\u7ecf\u7f51\u7edc\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u5b66\u4e60\u7684\u4e00\u822c\u5316\u89e3\u51b3\u65b9\u6848\u3002\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0c\u6d8c\u73b0\u73b0\u8c61\u53ef\u4ee5\u7eaf\u7136\u6765\u6e90\u4e8e\u5b66\u4e60\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u7279\u5f81\uff0c\u5e76\u4e14\u4e0d\u5c40\u9650\u4e8e\u795e\u7ecf\u67b6\u6784\u6216\u57fa\u4e8e\u68af\u5ea6\u4e0b\u964d\u7684\u4f18\u5316\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u5de5\u4f5c\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86AGOP\u4f5c\u4e3a\u795e\u7ecf\u7f51\u7edc\u4e2d\u5173\u952e\u7684\u7279\u5f81\u5b66\u4e60\u673a\u5236\u7684\u4f5c\u7528\u3002", "update_time": "2024-07-29 17:28:58+00:00", "publish_time": "2024-07-29 17:28:58+00:00"}, {"entry_id": "2407.20197v1", "title": "Learning Random Numbers to Realize Appendable Memory System for Artificial Intelligence to Acquire New Knowledge after Deployment", "summary": "In this study, we developed a learning method for constructing a neural\nnetwork system capable of memorizing data and recalling it without parameter\nupdates. The system we built using this method is called the Appendable Memory\nsystem. The Appendable Memory system enables an artificial intelligence (AI) to\nacquire new knowledge even after deployment. It consists of two AIs: the\nMemorizer and the Recaller. This system is a key-value store built using neural\nnetworks. The Memorizer receives data and stores it in the Appendable Memory\nvector, which is dynamically updated when the AI acquires new knowledge.\nMeanwhile, the Recaller retrieves information from the Appendable Memory\nvector. What we want to teach AI in this study are the operations of memorizing\nand recalling information. However, traditional machine learning methods make\nAI learn features inherent in the learning dataset. We demonstrate that the\nsystems we intend to create cannot be realized by current machine learning\nmethods, that is, by merely repeating the input and output learning sequences\nwith AI. Instead, we propose a method to teach AI to learn operations, by\ncompletely removing the features contained in the learning dataset.\nSpecifically, we probabilized all the data involved in learning. This measure\nprevented AI from learning the features of the data. The learning method\nproposed in the study differs from traditional machine learning methods and\nprovides fundamental approaches for building an AI system that can store\ninformation in a finite memory and recall it at a later date.", "pdf_path": null, "cn_title": "\u5b66\u4e60\u968f\u673a\u6570\u4ee5\u5b9e\u73b0\u53ef\u8ffd\u52a0\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u4f7f\u4eba\u5de5\u667a\u80fd\u5728\u90e8\u7f72\u540e\u80fd\u591f\u83b7\u53d6\u65b0\u77e5\u8bc6", "cn_summary": "\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u6784\u5efa\u80fd\u591f\u8bb0\u5fc6\u6570\u636e\u5e76\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u5373\u53ef\u8c03\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u7cfb\u7edf\u3002\u6211\u4eec\u4f7f\u7528\u6b64\u65b9\u6cd5\u5efa\u7acb\u7684\u7cfb\u7edf\u79f0\u4e3a\u53ef\u9644\u52a0\u8bb0\u5fc6\u7cfb\u7edf\uff08Appendable Memory system\uff09\u3002\u53ef\u9644\u52a0\u8bb0\u5fc6\u7cfb\u7edf\u4f7f\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u5373\u4f7f\u5728\u90e8\u7f72\u540e\u4e5f\u80fd\u83b7\u53d6\u65b0\u77e5\u8bc6\u3002\u8be5\u7cfb\u7edf\u7531\u4e24\u4e2aAI\u7ec4\u6210\uff1a\u8bb0\u5fc6\u5668\uff08Memorizer\uff09\u548c\u56de\u5fc6\u5668\uff08Recaller\uff09\u3002\u8fd9\u662f\u4e00\u4e2a\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u6784\u5efa\u7684\u5173\u952e\u503c\u5b58\u50a8\u7cfb\u7edf\u3002\u8bb0\u5fc6\u5668\u63a5\u6536\u6570\u636e\uff0c\u5e76\u5c06\u5176\u5b58\u50a8\u5728\u52a8\u6001\u66f4\u65b0\u7684\u53ef\u9644\u52a0\u8bb0\u5fc6\u5411\u91cf\u4e2d\uff0c\u5f53AI\u83b7\u53d6\u65b0\u77e5\u8bc6\u65f6\uff0c\u8be5\u5411\u91cf\u4f1a\u8fdb\u884c\u66f4\u65b0\u3002\u540c\u65f6\uff0c\u56de\u5fc6\u5668\u4ece\u53ef\u9644\u52a0\u8bb0\u5fc6\u5411\u91cf\u4e2d\u68c0\u7d22\u4fe1\u606f\u3002\u6211\u4eec\u5e0c\u671b\u5728\u672c\u7814\u7a76\u4e2d\u6559\u6388AI\u7684\u4fe1\u606f\u8bb0\u5fc6\u548c\u56de\u5fc6\u64cd\u4f5c\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f7fAI\u5b66\u4e60\u5b66\u4e60\u6570\u636e\u96c6\u56fa\u6709\u7684\u7279\u5f81\u3002\u6211\u4eec\u5c55\u793a\u4e86\u6211\u4eec\u6253\u7b97\u521b\u5efa\u7684\u7cfb\u7edf\u65e0\u6cd5\u901a\u8fc7\u5f53\u524d\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5b9e\u73b0\uff0c\u5373\u4ec5\u901a\u8fc7AI\u91cd\u590d\u8f93\u5165\u548c\u8f93\u51fa\u5b66\u4e60\u5e8f\u5217\u3002\u76f8\u53cd\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b8c\u5168\u6d88\u9664\u5b66\u4e60\u6570\u636e\u96c6\u4e2d\u7684\u7279\u5f81\u6765\u6559\u6388AI\u5b66\u4e60\u64cd\u4f5c\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u5c06\u6240\u6709\u6d89\u53ca\u5b66\u4e60\u7684\u6570\u636e\u6982\u7387\u5316\u3002\u8fd9\u4e00\u63aa\u65bd\u9632\u6b62\u4e86AI\u5b66\u4e60\u6570\u636e\u7684\u7279\u5f81\u3002\u7814\u7a76\u4e2d\u63d0\u51fa\u7684\u5b66\u4e60\u65b9\u6cd5\u4e0e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4e0d\u540c\uff0c\u63d0\u4f9b\u4e86\u6784\u5efa\u53ef\u4ee5\u5728\u6709\u9650\u5185\u5b58\u4e2d\u5b58\u50a8\u4fe1\u606f\u5e76\u5728\u4ee5\u540e\u8c03\u7528\u4fe1\u606f\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u57fa\u7840\u65b9\u6cd5\u3002", "update_time": "2024-07-29 17:24:35+00:00", "publish_time": "2024-07-29 17:24:35+00:00"}, {"entry_id": "2407.12620v2", "title": "Harnessing the Power of Artificial Intelligence to Vitalize Endangered Indigenous Languages: Technologies and Experiences", "summary": "Since 2022 we have been exploring application areas and technologies in which\nArtificial Intelligence (AI) and modern Natural Language Processing (NLP), such\nas Large Language Models (LLMs), can be employed to foster the usage and\nfacilitate the documentation of Indigenous languages which are in danger of\ndisappearing. We start by discussing the decreasing diversity of languages in\nthe world and how working with Indigenous languages poses unique ethical\nchallenges for AI and NLP. To address those challenges, we propose an\nalternative development AI cycle based on community engagement and usage. Then,\nwe report encouraging results in the development of high-quality machine\nlearning translators for Indigenous languages by fine-tuning state-of-the-art\n(SOTA) translators with tiny amounts of data and discuss how to avoid some\ncommon pitfalls in the process. We also present prototypes we have built in\nprojects done in 2023 and 2024 with Indigenous communities in Brazil, aimed at\nfacilitating writing, and discuss the development of Indigenous Language Models\n(ILMs) as a replicable and scalable way to create spell-checkers, next-word\npredictors, and similar tools. Finally, we discuss how we envision a future for\nlanguage documentation where dying languages are preserved as interactive\nlanguage models.", "pdf_path": null, "cn_title": "\u5229\u7528\u4eba\u5de5\u667a\u80fd\u7684\u529b\u91cf\u632f\u5174\u6fd2\u5371\u7684\u571f\u8457\u8bed\u8a00\uff1a\u6280\u672f\u4e0e\u7ecf\u9a8c", "cn_summary": "\u81ea2022\u5e74\u8d77\uff0c\u6211\u4eec\u4e00\u76f4\u5728\u63a2\u7d22\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u4e0e\u73b0\u4ee3\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\uff0c\u5c24\u5176\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u5728\u4fc3\u8fdb\u6fd2\u5371\u539f\u4f4f\u6c11\u8bed\u8a00\u7684\u4f7f\u7528\u4e0e\u8bb0\u5f55\u65b9\u9762\u7684\u5e94\u7528\u9886\u57df\u548c\u6280\u672f\u3002\u9996\u5148\uff0c\u6211\u4eec\u5c06\u8ba8\u8bba\u5168\u7403\u8bed\u8a00\u591a\u6837\u6027\u51cf\u5c11\u7684\u73b0\u8c61\uff0c\u4ee5\u53ca\u4e0e\u539f\u4f4f\u6c11\u8bed\u8a00\u5408\u4f5c\u6240\u9762\u4e34\u7684\u72ec\u7279\u4f26\u7406\u6311\u6218\u5bf9AI\u548cNLP\u7684\u5f71\u54cd\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u793e\u533a\u53c2\u4e0e\u4e0e\u4f7f\u7528\u7684\u66ff\u4ee3AI\u5f00\u53d1\u5468\u671f\u3002\u968f\u540e\uff0c\u6211\u4eec\u5c06\u62a5\u544a\u5728\u4f7f\u7528\u5c11\u91cf\u6570\u636e\u5fae\u8c03\u6700\u5148\u8fdb\u7684\u7ffb\u8bd1\u5668\u4ee5\u5f00\u53d1\u9ad8\u8d28\u91cf\u7684\u539f\u4f4f\u6c11\u8bed\u8a00\u673a\u5668\u5b66\u4e60\u7ffb\u8bd1\u5668\u65b9\u9762\u53d6\u5f97\u7684\u9f13\u821e\u4eba\u5fc3\u7684\u7ed3\u679c\uff0c\u5e76\u63a2\u8ba8\u907f\u514d\u8be5\u8fc7\u7a0b\u4e2d\u5e38\u89c1\u9677\u9631\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u5c06\u5c55\u793a\u57282023\u5e74\u548c2024\u5e74\u4e0e\u5df4\u897f\u539f\u4f4f\u6c11\u793e\u533a\u5408\u4f5c\u9879\u76ee\u4e2d\u6784\u5efa\u7684\u539f\u578b\uff0c\u65e8\u5728\u4fc3\u8fdb\u4e66\u5199\uff0c\u5e76\u8ba8\u8bba\u539f\u4f4f\u6c11\u8bed\u8a00\u6a21\u578b\uff08ILMs\uff09\u4f5c\u4e3a\u521b\u5efa\u62fc\u5199\u68c0\u67e5\u5668\u3001\u4e0b\u4e00\u53e5\u9884\u6d4b\u5de5\u5177\u7b49\u7c7b\u4f3c\u5de5\u5177\u7684\u53ef\u590d\u5236\u548c\u53ef\u6269\u5c55\u65b9\u5f0f\u7684\u53d1\u5c55\u3002\u6700\u540e\uff0c\u6211\u4eec\u5c06\u8ba8\u8bba\u6211\u4eec\u5bf9\u672a\u6765\u8bed\u8a00\u8bb0\u5f55\u7684\u770b\u6cd5\uff0c\u5728\u8fd9\u4e00\u613f\u666f\u4e2d\uff0c\u6fd2\u4e34\u706d\u7edd\u7684\u8bed\u8a00\u5c06\u4ee5\u4ea4\u4e92\u5f0f\u8bed\u8a00\u6a21\u578b\u7684\u5f62\u5f0f\u88ab\u4fdd\u5b58\u4e0b\u6765\u3002", "update_time": "2024-07-29 17:19:43+00:00", "publish_time": "2024-07-17 14:46:37+00:00"}, {"entry_id": "2407.20192v1", "title": "Time series forecasting with high stakes: A field study of the air cargo industry", "summary": "Time series forecasting in the air cargo industry presents unique challenges\ndue to volatile market dynamics and the significant impact of accurate\nforecasts on generated revenue. This paper explores a comprehensive approach to\ndemand forecasting at the origin-destination (O\\&D) level, focusing on the\ndevelopment and implementation of machine learning models in decision-making\nfor the air cargo industry. We leverage a mixture of experts framework,\ncombining statistical and advanced deep learning models to provide reliable\nforecasts for cargo demand over a six-month horizon. The results demonstrate\nthat our approach outperforms industry benchmarks, offering actionable insights\nfor cargo capacity allocation and strategic decision-making in the air cargo\nindustry. While this work is applied in the airline industry, the methodology\nis broadly applicable to any field where forecast-based decision-making in a\nvolatile environment is crucial.", "pdf_path": null, "cn_title": "\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5728\u9ad8\u98ce\u9669\u60c5\u5883\u4e0b\u7684\u5e94\u7528\uff1a\u822a\u7a7a\u8d27\u8fd0\u884c\u4e1a\u7684\u5b9e\u5730\u7814\u7a76", "cn_summary": "\u822a\u7a7a\u8d27\u8fd0\u9886\u57df\u7684\u65f6\u5e8f\u9884\u6d4b\u9762\u4e34\u72ec\u7279\u7684\u6311\u6218\uff0c\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\u5e02\u573a\u52a8\u6001\u7684\u6ce2\u52a8\u6027\u548c\u51c6\u786e\u9884\u6d4b\u5bf9\u751f\u6210\u6536\u5165\u7684\u5de8\u5927\u5f71\u54cd\u3002\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u6e90\u5934-\u76ee\u7684\u5730\uff08O&D\uff09\u5c42\u7ea7\u4e0a\u8fdb\u884c\u9700\u6c42\u9884\u6d4b\u7684\u5168\u9762\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u4e86\u822a\u7a7a\u8d27\u8fd0\u884c\u4e1a\u51b3\u7b56\u4e2d\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u5e94\u7528\u4e0e\u53d1\u5c55\u3002\u6211\u4eec\u5229\u7528\u4e86\u4e13\u5bb6\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u7edf\u8ba1\u5b66\u548c\u6df1\u5ea6\u5b66\u4e60\u9ad8\u7ea7\u6a21\u578b\uff0c\u4e3a\u516d\u4e2a\u6708\u5185\u8d27\u7269\u9700\u6c42\u63d0\u4f9b\u53ef\u9760\u9884\u6d4b\u3002\u7ed3\u679c\u663e\u793a\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u8d85\u8d8a\u4e86\u884c\u4e1a\u57fa\u51c6\uff0c\u4e3a\u822a\u7a7a\u8d27\u8fd0\u4e2d\u7684\u8f7d\u8d27\u5bb9\u91cf\u5206\u914d\u548c\u6218\u7565\u51b3\u7b56\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6d1e\u5bdf\u3002\u867d\u7136\u8fd9\u9879\u5de5\u4f5c\u5e94\u7528\u4e8e\u822a\u7a7a\u516c\u53f8\u9886\u57df\uff0c\u4f46\u5176\u65b9\u6cd5\u8bba\u5e7f\u6cdb\u9002\u7528\u4e8e\u4efb\u4f55\u9700\u8981\u5728\u52a8\u8361\u73af\u5883\u4e2d\u57fa\u4e8e\u9884\u6d4b\u8fdb\u884c\u51b3\u7b56\u7684\u9886\u57df\u3002", "update_time": "2024-07-29 17:19:40+00:00", "publish_time": "2024-07-29 17:19:40+00:00"}, {"entry_id": "2404.16251v3", "title": "Prompt Leakage effect and defense strategies for multi-turn LLM interactions", "summary": "Prompt leakage poses a compelling security and privacy threat in LLM\napplications. Leakage of system prompts may compromise intellectual property,\nand act as adversarial reconnaissance for an attacker. A systematic evaluation\nof prompt leakage threats and mitigation strategies is lacking, especially for\nmulti-turn LLM interactions. In this paper, we systematically investigate LLM\nvulnerabilities against prompt leakage for 10 closed- and open-source LLMs,\nacross four domains. We design a unique threat model which leverages the LLM\nsycophancy effect and elevates the average attack success rate (ASR) from 17.7%\nto 86.2% in a multi-turn setting. Our standardized setup further allows\ndissecting leakage of specific prompt contents such as task instructions and\nknowledge documents. We measure the mitigation effect of 7 black-box defense\nstrategies, along with finetuning an open-source model to defend against\nleakage attempts. We present different combination of defenses against our\nthreat model, including a cost analysis. Our study highlights key takeaways for\nbuilding secure LLM applications and provides directions for research in\nmulti-turn LLM interactions", "pdf_path": null, "cn_title": "\u63d0\u793a\u6cc4\u6f0f\u6548\u5e94\u53ca\u5176\u5728\u591a\u8f6e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ea4\u4e92\u4e2d\u7684\u9632\u5fa1\u7b56\u7565", "cn_summary": "\u63d0\u793a\u6cc4\u9732\u5728LLM\u5e94\u7528\u4e2d\u6784\u6210\u4e86\u5f15\u4eba\u5173\u6ce8\u7684\u5b89\u5168\u548c\u9690\u79c1\u5a01\u80c1\u3002\u7cfb\u7edf\u63d0\u793a\u7684\u6cc4\u9732\u53ef\u80fd\u635f\u5bb3\u77e5\u8bc6\u4ea7\u6743\uff0c\u5e76\u4f5c\u4e3a\u653b\u51fb\u8005\u7684\u5bf9\u6297\u6027\u4fa6\u5bdf\u624b\u6bb5\u3002\u9488\u5bf9\u63d0\u793a\u6cc4\u9732\u5a01\u80c1\u53ca\u5176\u7f13\u89e3\u7b56\u7565\u7684\u7cfb\u7edf\u8bc4\u4f30\u76f8\u5bf9\u532e\u4e4f\uff0c\u5c24\u5176\u662f\u5728\u591a\u8f6e\u6b21LLM\u4ea4\u4e92\u4e2d\u3002\u672c\u6587\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u9488\u5bf9\u95ed\u6e90\u4e0e\u5f00\u6e90\u768410\u6b3eLLM\uff0c\u5728\u56db\u5927\u9886\u57df\u4e0b\u5bf9\u63d0\u793a\u6cc4\u9732\u7684\u8106\u5f31\u6027\u3002\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u72ec\u7279\u7684\u5a01\u80c1\u6a21\u578b\uff0c\u5229\u7528\u4e86LLM\u7684\u963f\u8c00\u5949\u627f\u6548\u5e94\uff0c\u5c06\u591a\u8f6e\u4ea4\u4e92\u4e2d\u7684\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\uff08ASR\uff09\u4ece17.7%\u63d0\u5347\u81f386.2%\u3002\u6211\u4eec\u7684\u6807\u51c6\u5316\u8bbe\u7f6e\u8fdb\u4e00\u6b65\u5141\u8bb8\u5bf9\u7279\u5b9a\u63d0\u793a\u5185\u5bb9\uff0c\u5982\u4efb\u52a1\u6307\u4ee4\u548c\u77e5\u8bc6\u6587\u6863\u7684\u6cc4\u9732\u8fdb\u884c\u5256\u6790\u3002\u6211\u4eec\u6d4b\u91cf\u4e867\u79cd\u9ed1\u76d2\u9632\u5fa1\u7b56\u7565\u7684\u7f13\u89e3\u6548\u679c\uff0c\u5e76\u5bf9\u5f00\u6e90\u6a21\u578b\u8fdb\u884c\u4e86\u5fae\u8c03\u4ee5\u62b5\u5fa1\u6cc4\u9732\u5c1d\u8bd5\u3002\u6211\u4eec\u5c55\u793a\u4e86\u9488\u5bf9\u6211\u4eec\u5a01\u80c1\u6a21\u578b\u7684\u4e0d\u540c\u9632\u5fa1\u7ec4\u5408\uff0c\u5305\u62ec\u6210\u672c\u5206\u6790\u3002\u672c\u7814\u7a76\u7a81\u51fa\u4e86\u6784\u5efa\u5b89\u5168LLM\u5e94\u7528\u7684\u5173\u952e\u8981\u70b9\uff0c\u5e76\u4e3a\u591a\u8f6e\u6b21LLM\u4ea4\u4e92\u7684\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "update_time": "2024-07-29 17:16:19+00:00", "publish_time": "2024-04-24 23:39:58+00:00"}, {"entry_id": "2407.20183v1", "title": "MindSearch: Mimicking Human Minds Elicits Deep AI Searcher", "summary": "Information seeking and integration is a complex cognitive task that consumes\nenormous time and effort. Inspired by the remarkable progress of Large Language\nModels, recent works attempt to solve this task by combining LLMs and search\nengines. However, these methods still obtain unsatisfying performance due to\nthree challenges: (1) complex requests often cannot be accurately and\ncompletely retrieved by the search engine once (2) corresponding information to\nbe integrated is spread over multiple web pages along with massive noise, and\n(3) a large number of web pages with long contents may quickly exceed the\nmaximum context length of LLMs. Inspired by the cognitive process when humans\nsolve these problems, we introduce MindSearch to mimic the human minds in web\ninformation seeking and integration, which can be instantiated by a simple yet\neffective LLM-based multi-agent framework. The WebPlanner models the human mind\nof multi-step information seeking as a dynamic graph construction process: it\ndecomposes the user query into atomic sub-questions as nodes in the graph and\nprogressively extends the graph based on the search result from WebSearcher.\nTasked with each sub-question, WebSearcher performs hierarchical information\nretrieval with search engines and collects valuable information for WebPlanner.\nThe multi-agent design of MindSearch enables the whole framework to seek and\nintegrate information parallelly from larger-scale (e.g., more than 300) web\npages in 3 minutes, which is worth 3 hours of human effort. MindSearch\ndemonstrates significant improvement in the response quality in terms of depth\nand breadth, on both close-set and open-set QA problems. Besides, responses\nfrom MindSearch based on InternLM2.5-7B are preferable by humans to ChatGPT-Web\nand Perplexity.ai applications, which implies that MindSearch can already\ndeliver a competitive solution to the proprietary AI search engine.", "pdf_path": null, "cn_title": "\u300aMindSearch\uff1a\u6a21\u4eff\u4eba\u7c7b\u601d\u7ef4\u5f15\u53d1\u6df1\u5ea6AI\u641c\u7d22\u300b", "cn_summary": "\u4fe1\u606f\u67e5\u8be2\u4e0e\u6574\u5408\u662f\u4e00\u4e2a\u590d\u6742\u7684\u8ba4\u77e5\u4efb\u52a1\uff0c\u9700\u8981\u6295\u5165\u5927\u91cf\u65f6\u95f4\u548c\u7cbe\u529b\u3002\u53d7\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u663e\u8457\u8fdb\u6b65\u7684\u542f\u53d1\uff0c\u8fd1\u671f\u7684\u5de5\u4f5c\u5c1d\u8bd5\u901a\u8fc7\u7ed3\u5408LLM\u548c\u641c\u7d22\u5f15\u64ce\u6765\u89e3\u51b3\u8fd9\u4e00\u4efb\u52a1\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u7531\u4e8e\u9762\u4e34\u4e09\u4e2a\u6311\u6218\u4ecd\u65e0\u6cd5\u83b7\u5f97\u4ee4\u4eba\u6ee1\u610f\u7684\u8868\u73b0\uff1a\uff081\uff09\u590d\u6742\u7684\u8bf7\u6c42\u5f80\u5f80\u4e0d\u80fd\u88ab\u641c\u7d22\u5f15\u64ce\u51c6\u786e\u3001\u5b8c\u6574\u5730\u68c0\u7d22\uff1b\uff082\uff09\u9700\u8981\u6574\u5408\u7684\u4fe1\u606f\u5206\u5e03\u5728\u591a\u4e2a\u7f51\u9875\u4e2d\uff0c\u5e76\u5939\u6742\u5927\u91cf\u7684\u566a\u97f3\uff1b\uff083\uff09\u5927\u91cf\u5305\u542b\u957f\u5185\u5bb9\u7684\u7f51\u9875\u53ef\u80fd\u8fc5\u901f\u8d85\u8fc7LLM\u7684\u6700\u5927\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002\u53d7\u4eba\u7c7b\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u65f6\u7684\u8ba4\u77e5\u8fc7\u7a0b\u542f\u53d1\uff0c\u6211\u4eec\u5f15\u5165\u4e86MindSearch\uff0c\u65e8\u5728\u6a21\u4eff\u4eba\u7c7b\u5728\u7f51\u9875\u4fe1\u606f\u67e5\u8be2\u4e0e\u6574\u5408\u8fc7\u7a0b\u4e2d\u7684\u601d\u7ef4\u6a21\u5f0f\u3002\u8fd9\u4e00\u6982\u5ff5\u53ef\u4ee5\u901a\u8fc7\u4e00\u4e2a\u7b80\u5355\u800c\u6709\u6548\u7684\u57fa\u4e8eLLM\u7684\u591a\u4ee3\u7406\u6846\u67b6\u5b9e\u73b0\u3002WebPlanner\u5c06\u4eba\u7c7b\u5728\u591a\u6b65\u4fe1\u606f\u67e5\u8be2\u8fc7\u7a0b\u4e2d\u7684\u601d\u7ef4\u5efa\u6a21\u4e3a\u52a8\u6001\u56fe\u6784\u5efa\u8fc7\u7a0b\uff1a\u5b83\u5c06\u7528\u6237\u67e5\u8be2\u5206\u89e3\u4e3a\u539f\u5b50\u5b50\u95ee\u9898\u4f5c\u4e3a\u56fe\u4e2d\u7684\u8282\u70b9\uff0c\u5e76\u6839\u636eWebSearcher\u4ece\u641c\u7d22\u5f15\u64ce\u68c0\u7d22\u7684\u7ed3\u679c\u9010\u6b65\u6269\u5c55\u56fe\u3002\u6bcf\u4e2a\u5b50\u95ee\u9898\u7531WebSearcher\u8d1f\u8d23\u6267\u884c\u5206\u5c42\u4fe1\u606f\u68c0\u7d22\u5e76\u6536\u96c6\u6709\u4ef7\u503c\u7684\u4fe1\u606f\u4f9bWebPlanner\u4f7f\u7528\u3002MindSearch\u7684\u591a\u4ee3\u7406\u8bbe\u8ba1\u4f7f\u5f97\u6574\u4e2a\u6846\u67b6\u80fd\u591f\u4ee53\u5206\u949f\u7684\u65f6\u95f4\u4ece\u5927\u89c4\u6a21\uff08\u4f8b\u5982\uff0c\u8d85\u8fc7300\u4e2a\uff09\u7f51\u9875\u4e2d\u5e76\u884c\u83b7\u53d6\u548c\u6574\u5408\u4fe1\u606f\uff0c\u76f8\u5f53\u4e8e\u8282\u7701\u4e863\u5c0f\u65f6\u7684\u4eba\u529b\u3002MindSearch\u5728\u6df1\u5ea6\u548c\u5e7f\u5ea6\u4e0a\u90fd\u663e\u8457\u63d0\u9ad8\u4e86\u54cd\u5e94\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5728\u95ed\u96c6\u548c\u5f00\u96c6\u95ee\u7b54\u95ee\u9898\u4e0a\u3002\u6b64\u5916\uff0c\u57fa\u4e8eInternLM2.5-7B\u7684MindSearch\u7684\u56de\u7b54\u66f4\u53d7\u4eba\u7c7b\u6b22\u8fce\uff0c\u4e0eChatGPT-Web\u548cPerplexity.ai\u5e94\u7528\u76f8\u6bd4\uff0c\u8fd9\u8868\u660eMindSearch\u5df2\u7ecf\u80fd\u591f\u63d0\u4f9b\u4e0e\u4e13\u6709AI\u641c\u7d22\u5f15\u64ce\u76f8\u7ade\u4e89\u7684\u89e3\u51b3\u65b9\u6848\u3002", "update_time": "2024-07-29 17:12:40+00:00", "publish_time": "2024-07-29 17:12:40+00:00"}, {"entry_id": "2407.20179v1", "title": "Theia: Distilling Diverse Vision Foundation Models for Robot Learning", "summary": "Vision-based robot policy learning, which maps visual inputs to actions,\nnecessitates a holistic understanding of diverse visual tasks beyond\nsingle-task needs like classification or segmentation. Inspired by this, we\nintroduce Theia, a vision foundation model for robot learning that distills\nmultiple off-the-shelf vision foundation models trained on varied vision tasks.\nTheia's rich visual representations encode diverse visual knowledge, enhancing\ndownstream robot learning. Extensive experiments demonstrate that Theia\noutperforms its teacher models and prior robot learning models using less\ntraining data and smaller model sizes. Additionally, we quantify the quality of\npre-trained visual representations and hypothesize that higher entropy in\nfeature norm distributions leads to improved robot learning performance. Code\nand models are available at https://github.com/bdaiinstitute/theia.", "pdf_path": null, "cn_title": "Theia: \u63d0\u70bc\u591a\u6a21\u6001\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u4ee5\u4fc3\u8fdb\u673a\u5668\u4eba\u5b66\u4e60", "cn_summary": "\u57fa\u4e8e\u89c6\u89c9\u7684\u673a\u5668\u4eba\u7b56\u7565\u5b66\u4e60\uff0c\u5176\u5c06\u89c6\u89c9\u8f93\u5165\u6620\u5c04\u5230\u884c\u52a8\uff0c\n\u8981\u6c42\u5bf9\u8d85\u51fa\u5355\u4e00\u4efb\u52a1\u9700\u6c42\uff08\u5982\u5206\u7c7b\u6216\u5206\u5272\uff09\u7684\u591a\u6837\u5316\u89c6\u89c9\u4efb\u52a1\u6709\u5168\u9762\u7684\u7406\u89e3\u3002\u53d7\u5230\u8fd9\u4e00\u542f\u53d1\uff0c\u6211\u4eec\u5f15\u5165\u4e86Theia\uff0c\u4e00\u4e2a\u9762\u5411\u673a\u5668\u4eba\u5b66\u4e60\u7684\u89c6\u89c9\u57fa\u7840\u6a21\u578b\uff0c\u5b83\u6c47\u96c6\u4e86\u5728\u4e0d\u540c\u89c6\u89c9\u4efb\u52a1\u4e0a\u8bad\u7ec3\u7684\u591a\u4e2a\u73b0\u6210\u7684\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u3002Theia\u4e30\u5bcc\u7684\u89c6\u89c9\u8868\u793a\u7f16\u7801\u4e86\u591a\u6837\u5316\u7684\u89c6\u89c9\u77e5\u8bc6\uff0c\u589e\u5f3a\u4e86\u4e0b\u6e38\u673a\u5668\u4eba\u7684\u5b66\u4e60\u80fd\u529b\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTheia\u5728\u4f7f\u7528\u66f4\u5c11\u7684\u8bad\u7ec3\u6570\u636e\u548c\u8f83\u5c0f\u7684\u6a21\u578b\u5927\u5c0f\u7684\u60c5\u51b5\u4e0b\uff0c\u8868\u73b0\u8d85\u8fc7\u4e86\u5176\u6559\u5e08\u6a21\u578b\u548c\u5148\u524d\u7684\u673a\u5668\u4eba\u5b66\u4e60\u6a21\u578b\u3002\u6b64\u5916\uff0c\u6211\u4eec\u91cf\u5316\u4e86\u9884\u8bad\u7ec3\u89c6\u89c9\u8868\u793a\u7684\u8d28\u91cf\uff0c\u5e76\u5047\u8bbe\u7279\u5f81\u8303\u6570\u5206\u5e03\u4e2d\u7684\u9ad8\u71b5\u80fd\u591f\u63d0\u9ad8\u673a\u5668\u4eba\u5b66\u4e60\u6027\u80fd\u3002\u76f8\u5173\u4ee3\u7801\u548c\u6a21\u578b\u53ef\u5728https://github.com/bdaiinstitute/theia\u83b7\u53d6\u3002", "update_time": "2024-07-29 17:08:21+00:00", "publish_time": "2024-07-29 17:08:21+00:00"}, {"entry_id": "2407.20177v1", "title": "AutoScale: Automatic Prediction of Compute-optimal Data Composition for Training LLMs", "summary": "To ensure performance on a diverse set of downstream tasks, LLMs are\npretrained via data mixtures over different domains. In this work, we\ndemonstrate that the optimal data composition for a fixed compute budget varies\ndepending on the scale of the training data, suggesting that the common\npractice of empirically determining an optimal composition using small-scale\nexperiments will not yield the optimal data mixtures when scaling up to the\nfinal model. To address this challenge, we propose *AutoScale*, an automated\ntool that finds a compute-optimal data composition for training at any desired\ntarget scale. AutoScale first determines the optimal composition at a small\nscale using a novel bilevel optimization framework, Direct Data Optimization\n(*DDO*), and then fits a predictor to estimate the optimal composition at\nlarger scales. The predictor's design is inspired by our theoretical analysis\nof scaling laws related to data composition, which could be of independent\ninterest. In empirical studies with pre-training 774M Decoder-only LMs (GPT-2\nLarge) on RedPajama dataset, AutoScale decreases validation perplexity at least\n25% faster than any baseline with up to 38% speed up compared to without\nreweighting, achieving the best overall performance across downstream tasks. On\npre-training Encoder-only LMs (BERT) with masked language modeling, DDO is\nshown to decrease loss on all domains while visibly improving average task\nperformance on GLUE benchmark by 8.7% and on large-scale QA dataset (SQuAD) by\n5.9% compared with without reweighting. AutoScale speeds up training by up to\n28%. Our codes are open-sourced.", "pdf_path": null, "cn_title": "AutoScale: \u81ea\u52a8\u9884\u6d4b\u7528\u4e8e\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u6700\u4f18\u6570\u636e\u7ec4\u6210", "cn_summary": "\u4e3a\u4e86\u786e\u4fdd\u5728\u4e00\u7cfb\u5217\u4e0b\u6e38\u4efb\u52a1\u4e0a\u53d6\u5f97\u826f\u597d\u6027\u80fd\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u901a\u8fc7\u8de8\u4e0d\u540c\u9886\u57df\u6570\u636e\u7684\u6df7\u5408\u8fdb\u884c\u9884\u8bad\u7ec3\u3002\u5728\u672c\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5bf9\u4e8e\u56fa\u5b9a\u7684\u8ba1\u7b97\u9884\u7b97\uff0c\u56fa\u5b9a\u89c4\u6a21\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u4e0b\u6700\u4f18\u7684\u6570\u636e\u7ec4\u6210\u4f1a\u6709\u6240\u4e0d\u540c\uff0c\u8fd9\u8868\u660e\u4f7f\u7528\u5c0f\u578b\u5b9e\u9a8c\u6765\u7ecf\u9a8c\u6027\u5730\u786e\u5b9a\u6700\u4f18\u7ec4\u6210\u53ef\u80fd\u65e0\u6cd5\u5728\u6700\u7ec8\u6a21\u578b\u4e2d\u8fbe\u5230\u6700\u4f18\u6570\u636e\u6df7\u5408\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u201cAutoScale\u201d\uff0c\u4e00\u4e2a\u81ea\u52a8\u5de5\u5177\uff0c\u53ef\u4ee5\u5728\u4efb\u4f55\u9884\u5b9a\u7684\u76ee\u6807\u89c4\u6a21\u4e0b\u627e\u5230\u8ba1\u7b97\u4f18\u5316\u7684\u6570\u636e\u7ec4\u6210\u3002AutoScale\u9996\u5148\u5229\u7528\u65b0\u9896\u7684\u53cc\u5c42\u4f18\u5316\u6846\u67b6\u2014\u2014\u76f4\u63a5\u6570\u636e\u4f18\u5316\uff08DDO\uff09\u2014\u2014\u786e\u5b9a\u5c0f\u89c4\u6a21\u4e0b\u7684\u6700\u4f18\u7ec4\u6210\uff0c\u5e76\u968f\u540e\u6784\u5efa\u9884\u6d4b\u5668\u4ee5\u4f30\u8ba1\u66f4\u5927\u89c4\u6a21\u4e0b\u7684\u6700\u4f18\u7ec4\u6210\u3002\u9884\u6d4b\u5668\u7684\u8bbe\u8ba1\u7075\u611f\u6765\u6e90\u4e8e\u6211\u4eec\u5173\u4e8e\u6570\u636e\u7ec4\u6210\u4e0e\u89c4\u6a21\u76f8\u5173\u7684\u6269\u5c55\u6cd5\u5219\u7684\u7406\u8bba\u5206\u6790\uff0c\u8fd9\u53ef\u80fd\u5bf9\u72ec\u7acb\u7814\u7a76\u8005\u6709\u72ec\u7acb\u5174\u8da3\u3002\u5728\u9884\u8bad\u7ec3774M\u89e3\u7801\u5668\u53ea\u7528\u8bed\u8a00\u6a21\u578b\uff08GPT-2 Large\uff09RedPajama\u6570\u636e\u96c6\u7684\u5b9e\u8bc1\u7814\u7a76\u4e2d\uff0cAutoScale\u81f3\u5c11\u6bd4\u4efb\u4f55\u57fa\u7ebf\u5feb25%\u5730\u964d\u4f4e\u4e86\u9a8c\u8bc1\u56f0\u60d1\u5ea6\uff0c\u76f8\u6bd4\u4e8e\u4e0d\u91cd\u65b0\u52a0\u6743\u7684\u60c5\u51b5\uff0c\u5176\u901f\u5ea6\u63d0\u9ad8\u4e86\u6700\u591a38%\uff0c\u5e76\u4e14\u5728\u6240\u6709\u4e0b\u6e38\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6700\u4f73\u603b\u4f53\u6027\u80fd\u3002\u5728\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u53ea\u7528\u8bed\u8a00\u6a21\u578b\uff08BERT\uff09\u5e76\u4f7f\u7528\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\u7684\u60c5\u51b5\u4e0b\uff0cDDO\u663e\u793a\u4e86\u5728\u6240\u6709\u9886\u57df\u5185\u964d\u4f4e\u635f\u5931\u7684\u6548\u679c\uff0c\u5e76\u4e14\u5728GLUE\u57fa\u51c6\u4e0a\u5e73\u5747\u4efb\u52a1\u6027\u80fd\u63d0\u9ad8\u4e868.7%\uff0c\u5728\u5927\u89c4\u6a21\u95ee\u9898\u89e3\u7b54\u6570\u636e\u96c6\uff08SQuAD\uff09\u4e0a\u63d0\u9ad8\u4e865.9%\uff0c\u4e0e\u4e0d\u91cd\u65b0\u52a0\u6743\u7684\u60c5\u51b5\u76f8\u6bd4\u3002AutoScale\u53ef\u4ee5\u52a0\u901f\u8bad\u7ec3\u9ad8\u8fbe28%\u3002\u6211\u4eec\u7684\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "update_time": "2024-07-29 17:06:30+00:00", "publish_time": "2024-07-29 17:06:30+00:00"}, {"entry_id": "2407.20176v1", "title": "Emotion-Driven Melody Harmonization via Melodic Variation and Functional Representation", "summary": "Emotion-driven melody harmonization aims to generate diverse harmonies for a\nsingle melody to convey desired emotions. Previous research found it hard to\nalter the perceived emotional valence of lead sheets only by harmonizing the\nsame melody with different chords, which may be attributed to the constraints\nimposed by the melody itself and the limitation of existing music\nrepresentation. In this paper, we propose a novel functional representation for\nsymbolic music. This new method takes musical keys into account, recognizing\ntheir significant role in shaping music's emotional character through\nmajor-minor tonality. It also allows for melodic variation with respect to keys\nand addresses the problem of data scarcity for better emotion modeling. A\nTransformer is employed to harmonize key-adaptable melodies, allowing for keys\ndetermined in rule-based or model-based manner. Experimental results confirm\nthe effectiveness of our new representation in generating key-aware harmonies,\nwith objective and subjective evaluations affirming the potential of our\napproach to convey specific valence for versatile melody.", "pdf_path": null, "cn_title": "\u57fa\u4e8e\u60c5\u7eea\u9a71\u52a8\u7684\u65cb\u5f8b\u548c\u58f0\u5316\u901a\u8fc7\u65cb\u5f8b\u53d8\u4f53\u4e0e\u529f\u80fd\u8868\u793a", "cn_summary": "\u60c5\u7eea\u9a71\u52a8\u7684\u65cb\u5f8b\u548c\u58f0\u5316\u65e8\u5728\u4e3a\u5355\u4e00\u65cb\u5f8b\u751f\u6210\u591a\u6837\u5316\u7684\u548c\u58f0\uff0c\u4ee5\u4f20\u8fbe\u6240\u9700\u7684\u60c5\u611f\u3002\u5148\u524d\u7684\u7814\u7a76\u53d1\u73b0\uff0c\u4ec5\u901a\u8fc7\u4f7f\u7528\u4e0d\u540c\u7684\u548c\u5f26\u5bf9\u540c\u4e00\u65cb\u5f8b\u8fdb\u884c\u548c\u58f0\u5904\u7406\u6765\u6539\u53d8\u611f\u77e5\u7684\u60c5\u611f\u6781\u6027\u975e\u5e38\u56f0\u96be\uff0c\u8fd9\u53ef\u80fd\u5f52\u56e0\u4e8e\u65cb\u5f8b\u672c\u8eab\u65bd\u52a0\u7684\u9650\u5236\u4ee5\u53ca\u73b0\u6709\u97f3\u4e50\u8868\u793a\u65b9\u5f0f\u7684\u5c40\u9650\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7b26\u53f7\u97f3\u4e50\u7684\u529f\u80fd\u8868\u793a\u65b9\u6cd5\u3002\u8fd9\u79cd\u65b0\u65b9\u6cd5\u8003\u8651\u4e86\u8c03\u6027\uff0c\u8ba4\u8bc6\u5230\u5b83\u4eec\u5728\u5851\u9020\u97f3\u4e50\u60c5\u611f\u7279\u5f81\u65b9\u9762\u7684\u91cd\u8981\u4f5c\u7528\uff0c\u5c24\u5176\u662f\u5728\u5927\u8c03\u548c\u5c0f\u8c03\u4f53\u7cfb\u4e2d\u3002\u5b83\u8fd8\u5141\u8bb8\u5728\u4e0d\u540c\u8c03\u6027\u4e0b\u5bf9\u65cb\u5f8b\u8fdb\u884c\u53d8\u4f53\u5904\u7406\uff0c\u5e76\u89e3\u51b3\u4e86\u4e3a\u4e86\u66f4\u597d\u5730\u8fdb\u884c\u60c5\u611f\u5efa\u6a21\u800c\u5b58\u5728\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002\u6211\u4eec\u91c7\u7528\u4e86\u53d8\u6362\u5668\u6765\u5bf9\u53ef\u9002\u5e94\u8c03\u6027\u7684\u65cb\u5f8b\u8fdb\u884c\u548c\u58f0\u5904\u7406\uff0c\u5141\u8bb8\u4ee5\u89c4\u5219\u65b9\u5f0f\u6216\u6a21\u578b\u65b9\u5f0f\u786e\u5b9a\u8c03\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u6211\u4eec\u65b0\u8868\u793a\u65b9\u6cd5\u5728\u751f\u6210\u5177\u6709\u952e\u610f\u8bc6\u7684\u548c\u58f0\u7684\u6709\u6548\u6027\uff0c\u5ba2\u89c2\u548c\u4e3b\u89c2\u8bc4\u4f30\u5747\u8bc1\u5b9e\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u4f20\u8fbe\u591a\u53d8\u65cb\u5f8b\u7279\u5b9a\u6781\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002", "update_time": "2024-07-29 17:05:12+00:00", "publish_time": "2024-07-29 17:05:12+00:00"}, {"entry_id": "2407.20174v1", "title": "Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning", "summary": "Emerging multimodal large language models (MLLMs) exhibit great potential for\nchart question answering (CQA). Recent efforts primarily focus on scaling up\ntraining datasets (i.e., charts, data tables, and question-answer (QA) pairs)\nthrough data collection and synthesis. However, our empirical study on existing\nMLLMs and CQA datasets reveals notable gaps. First, current data collection and\nsynthesis focus on data volume and lack consideration of fine-grained visual\nencodings and QA tasks, resulting in unbalanced data distribution divergent\nfrom practical CQA scenarios. Second, existing work follows the training recipe\nof the base MLLMs initially designed for natural images, under-exploring the\nadaptation to unique chart characteristics, such as rich text elements. To fill\nthe gap, we propose a visualization-referenced instruction tuning approach to\nguide the training dataset enhancement and model development. Specifically, we\npropose a novel data engine to effectively filter diverse and high-quality data\nfrom existing datasets and subsequently refine and augment the data using\nLLM-based generation techniques to better align with practical QA tasks and\nvisual encodings. Then, to facilitate the adaptation to chart characteristics,\nwe utilize the enriched data to train an MLLM by unfreezing the vision encoder\nand incorporating a mixture-of-resolution adaptation strategy for enhanced\nfine-grained recognition. Experimental results validate the effectiveness of\nour approach. Even with fewer training examples, our model consistently\noutperforms state-of-the-art CQA models on established benchmarks. We also\ncontribute a dataset split as a benchmark for future research. Source codes and\ndatasets of this paper are available at\nhttps://github.com/zengxingchen/ChartQA-MLLM.", "pdf_path": null, "cn_title": "\u4fc3\u8fdb\u57fa\u4e8e\u56fe\u8868\u95ee\u9898\u56de\u7b54\u7684\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\uff0c\u901a\u8fc7\u53ef\u89c6\u5316\u53c2\u8003\u6307\u4ee4\u8c03\u4f18", "cn_summary": "\u65b0\u5174\u7684\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u56fe\u8868\u95ee\u9898\u56de\u7b54\uff08CQA\uff09\u9886\u57df\u5c55\u73b0\u51fa\u5de8\u5927\u7684\u6f5c\u529b\u3002\u8fd1\u671f\u7684\u52aa\u529b\u4e3b\u8981\u96c6\u4e2d\u5728\u901a\u8fc7\u6570\u636e\u6536\u96c6\u548c\u5408\u6210\u6269\u5927\u8bad\u7ec3\u6570\u636e\u96c6\uff08\u5305\u62ec\u56fe\u8868\u3001\u6570\u636e\u8868\u683c\u548c\u95ee\u7b54\u5bf9\uff09\u7684\u89c4\u6a21\u4e0a\u3002\u7136\u800c\uff0c\u6211\u4eec\u5bf9\u73b0\u6709MLLMs\u548cCQA\u6570\u636e\u96c6\u7684\u5b9e\u8bc1\u7814\u7a76\u63ed\u793a\u4e86\u663e\u8457\u7684\u5dee\u8ddd\u3002\u9996\u5148\uff0c\u5f53\u524d\u7684\u6570\u636e\u6536\u96c6\u548c\u5408\u6210\u5de5\u4f5c\u4fa7\u91cd\u4e8e\u6570\u636e\u91cf\u7684\u589e\u52a0\uff0c\u5ffd\u7565\u4e86\u7cbe\u7ec6\u89c6\u89c9\u7f16\u7801\u548c\u95ee\u7b54\u4efb\u52a1\u7684\u8003\u8651\uff0c\u5bfc\u81f4\u6570\u636e\u5206\u5e03\u4e0e\u5b9e\u9645CQA\u573a\u666f\u5b58\u5728\u4e0d\u4e00\u81f4\u7684\u60c5\u51b5\u3002\u5176\u6b21\uff0c\u73b0\u6709\u7684\u5de5\u4f5c\u9075\u5faa\u4e86\u6700\u521d\u8bbe\u8ba1\u7528\u4e8e\u81ea\u7136\u56fe\u50cf\u7684\u57fa\u7840MLLMs\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5bf9\u4e8e\u9002\u5e94\u56fe\u8868\u7684\u72ec\u7279\u7279\u6027\uff08\u5982\u4e30\u5bcc\u7684\u6587\u672c\u5143\u7d20\uff09\u8fd9\u4e00\u65b9\u9762\u5219\u63a2\u7d22\u4e0d\u8db3\u3002\n\n\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7f3a\u53e3\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u89c6\u5316\u6307\u793a\u7684\u6307\u4ee4\u8c03\u4f18\u65b9\u6cd5\u6765\u6307\u5bfc\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u589e\u5f3a\u548c\u6a21\u578b\u7684\u53d1\u5c55\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6570\u636e\u5f15\u64ce\uff0c\u6709\u6548\u5730\u4ece\u73b0\u6709\u6570\u636e\u96c6\u4e2d\u7b5b\u9009\u51fa\u591a\u6837\u6027\u548c\u9ad8\u8d28\u91cf\u7684\u6570\u636e\uff0c\u5e76\u968f\u540e\u5229\u7528\u57fa\u4e8eLLM\u7684\u751f\u6210\u6280\u672f\u8fdb\u4e00\u6b65\u7cbe\u70bc\u548c\u6269\u5145\u6570\u636e\uff0c\u4ee5\u66f4\u597d\u5730\u4e0e\u5b9e\u9645\u7684\u95ee\u7b54\u4efb\u52a1\u548c\u89c6\u89c9\u7f16\u7801\u76f8\u5339\u914d\u3002\u7136\u540e\uff0c\u4e3a\u4e86\u4fc3\u8fdb\u9002\u5e94\u56fe\u8868\u7279\u6027\u7684\u80fd\u529b\uff0c\u6211\u4eec\u5229\u7528\u4e30\u5bcc\u5316\u6570\u636e\u8bad\u7ec3\u4e86\u4e00\u4e2aMLLM\uff0c\u901a\u8fc7\u89e3\u51bb\u89c6\u89c9\u7f16\u7801\u5668\u5e76\u5f15\u5165\u5206\u8fa8\u7387\u6df7\u5408\u8c03\u6574\u7b56\u7565\u6765\u589e\u5f3a\u5176\u7ec6\u5fae\u7279\u5f81\u8bc6\u522b\u80fd\u529b\u3002\n\n\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u5373\u4f7f\u5728\u8f83\u5c11\u7684\u8bad\u7ec3\u793a\u4f8b\u4e0b\uff0c\u6211\u4eec\u7684\u6a21\u578b\u4e5f\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684CQA\u6a21\u578b\uff0c\u5728\u5df2\u5efa\u7acb\u7684\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002\u6211\u4eec\u8fd8\u8d21\u732e\u4e86\u4e00\u4e2a\u6570\u636e\u96c6\u5206\u5272\u4f5c\u4e3a\u672a\u6765\u7814\u7a76\u7684\u57fa\u51c6\u3002\u672c\u6587\u7684\u76f8\u5173\u4ee3\u7801\u548c\u6570\u636e\u96c6\u53ef\u5728https://github.com/zengxingchen/ChartQA-MLLM\u83b7\u53d6\u3002", "update_time": "2024-07-29 17:04:34+00:00", "publish_time": "2024-07-29 17:04:34+00:00"}, {"entry_id": "2407.20172v1", "title": "LatentArtiFusion: An Effective and Efficient Histological Artifacts Restoration Framework", "summary": "Histological artifacts pose challenges for both pathologists and\nComputer-Aided Diagnosis (CAD) systems, leading to errors in analysis. Current\napproaches for histological artifact restoration, based on Generative\nAdversarial Networks (GANs) and pixel-level Diffusion Models, suffer from\nperformance limitations and computational inefficiencies. In this paper, we\npropose a novel framework, LatentArtiFusion, which leverages the latent\ndiffusion model (LDM) to reconstruct histological artifacts with high\nperformance and computational efficiency. Unlike traditional pixel-level\ndiffusion frameworks, LatentArtiFusion executes the restoration process in a\nlower-dimensional latent space, significantly improving computational\nefficiency. Moreover, we introduce a novel regional artifact reconstruction\nalgorithm in latent space to prevent mistransfer in non-artifact regions,\ndistinguishing our approach from GAN-based methods. Through extensive\nexperiments on real-world histology datasets, LatentArtiFusion demonstrates\nremarkable speed, outperforming state-of-the-art pixel-level diffusion\nframeworks by more than 30X. It also consistently surpasses GAN-based methods\nby at least 5% across multiple evaluation metrics. Furthermore, we evaluate the\neffectiveness of our proposed framework in downstream tissue classification\ntasks, showcasing its practical utility. Code is available at\nhttps://github.com/bugs-creator/LatentArtiFusion.", "pdf_path": null, "cn_title": "\u6f5c\u85cf\u827a\u672f\u878d\u5408\uff1a\u4e00\u79cd\u6709\u6548\u4e14\u9ad8\u6548\u7684\u7ec4\u7ec7\u75c5\u7406\u5b66\u4f2a\u5f71\u4fee\u590d\u6846\u67b6", "cn_summary": "\u7ec4\u7ec7\u5b66\u4f2a\u50cf\u662f\u75c5\u7406\u5b66\u5bb6\u548c\u8ba1\u7b97\u673a\u8f85\u52a9\u8bca\u65ad\uff08CAD\uff09\u7cfb\u7edf\u9762\u4e34\u7684\u6311\u6218\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u5206\u6790\u51fa\u73b0\u9519\u8bef\u3002\u57fa\u4e8e\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GANs\uff09\u548c\u50cf\u7d20\u7ea7\u6269\u6563\u6a21\u578b\u7684\u5f53\u524d\u7ec4\u7ec7\u5b66\u4f2a\u50cf\u4fee\u590d\u65b9\u6cd5\u9762\u4e34\u7740\u6027\u80fd\u9650\u5236\u548c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u6846\u67b6\u2014\u2014LatentArtiFusion\uff0c\u8be5\u6846\u67b6\u5229\u7528\u6f5c\u6269\u6563\u6a21\u578b\uff08LDM\uff09\u5728\u9ad8\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u91cd\u5efa\u7ec4\u7ec7\u5b66\u4f2a\u50cf\u3002\u4e0e\u4f20\u7edf\u7684\u50cf\u7d20\u7ea7\u6269\u6563\u6846\u67b6\u4e0d\u540c\uff0cLatentArtiFusion\u5728\u4f4e\u7ef4\u6f5c\u7a7a\u95f4\u4e2d\u6267\u884c\u4fee\u590d\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u6f5c\u7a7a\u95f4\u4e2d\u7684\u65b0\u578b\u533a\u57df\u4f2a\u50cf\u91cd\u5efa\u7b97\u6cd5\uff0c\u4ee5\u9632\u6b62\u975e\u4f2a\u50cf\u533a\u57df\u7684\u8bef\u8f6c\uff0c\u8fd9\u4f7f\u6211\u4eec\u7684\u65b9\u6cd5\u4e0e\u57fa\u4e8eGAN\u7684\u65b9\u6cd5\u533a\u5206\u5f00\u6765\u3002\u901a\u8fc7\u5728\u73b0\u5b9e\u4e16\u754c\u7ec4\u7ec7\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0cLatentArtiFusion\u8868\u73b0\u51fa\u60ca\u4eba\u7684\u901f\u5ea6\u4f18\u52bf\uff0c\u76f8\u5bf9\u4e8e\u6700\u5148\u8fdb\u7684\u50cf\u7d20\u7ea7\u6269\u6563\u6846\u67b6\u63d0\u9ad8\u4e86\u8d85\u8fc730\u500d\u3002\u5b83\u8fd8\u4e00\u81f4\u5730\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u8d85\u8d8a\u4e86\u57fa\u4e8eGAN\u7684\u65b9\u6cd5\u81f3\u5c115%\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8bc4\u4f30\u4e86\u6240\u63d0\u51fa\u6846\u67b6\u5728\u4e0b\u6e38\u7ec4\u7ec7\u5206\u7c7b\u4efb\u52a1\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5b9e\u7528\u6027\u3002\u4ee3\u7801\u53ef\u8bbf\u95ee\u4e8ehttps://github.com/bugs-creator/LatentArtiFusion\u3002", "update_time": "2024-07-29 17:00:32+00:00", "publish_time": "2024-07-29 17:00:32+00:00"}, {"entry_id": "2302.01538v7", "title": "DCEM: A deep complementary energy method for solid mechanics", "summary": "In recent years, the rapid advancement of deep learning has significantly\nimpacted various fields, particularly in solving partial differential equations\n(PDEs) in the realm of solid mechanics, benefiting greatly from the remarkable\napproximation capabilities of neural networks. In solving PDEs,\nPhysics-Informed Neural Networks (PINNs) and the Deep Energy Method (DEM) have\ngarnered substantial attention. The principle of minimum potential energy and\ncomplementary energy are two important variational principles in solid\nmechanics. However, the well-known Deep Energy Method (DEM) is based on the\nprinciple of minimum potential energy, but there lacks the important form of\nminimum complementary energy. To bridge this gap, we propose the deep\ncomplementary energy method (DCEM) based on the principle of minimum\ncomplementary energy. The output function of DCEM is the stress function, which\ninherently satisfies the equilibrium equation. We present numerical results\nusing the Prandtl and Airy stress functions, and compare DCEM with existing\nPINNs and DEM algorithms when modeling representative mechanical problems. The\nresults demonstrate that DCEM outperforms DEM in terms of stress accuracy and\nefficiency and has an advantage in dealing with complex displacement boundary\nconditions, which is supported by theoretical analyses and numerical\nsimulations. We extend DCEM to DCEM-Plus (DCEM-P), adding terms that satisfy\npartial differential equations. Furthermore, we propose a deep complementary\nenergy operator method (DCEM-O) by combining operator learning with physical\nequations. Initially, we train DCEM-O using high-fidelity numerical results and\nthen incorporate complementary energy. DCEM-P and DCEM-O further enhance the\naccuracy and efficiency of DCEM.", "pdf_path": null, "cn_title": "DCEM\uff1a\u4e00\u79cd\u7528\u4e8e\u56fa\u4f53\u529b\u5b66\u7684\u6df1\u5ea6\u4e92\u8865\u80fd\u91cf\u65b9\u6cd5", "cn_summary": "\u8fd1\u5e74\u6765\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u8fc5\u901f\u53d1\u5c55\u5bf9\u5404\u4e2a\u9886\u57df\u4ea7\u751f\u4e86\u91cd\u5927\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u89e3\u51b3\u56fa\u4f53\u529b\u5b66\u9886\u57df\u7684\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDEs\uff09\u65b9\u9762\uff0c\u5f97\u76ca\u4e8e\u795e\u7ecf\u7f51\u7edc\u975e\u51e1\u7684\u903c\u8fd1\u80fd\u529b\u3002\u5728\u6c42\u89e3PDEs\u65f6\uff0c\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u548c\u6df1\u5ea6\u80fd\u91cf\u65b9\u6cd5\uff08DEM\uff09\u53d7\u5230\u4e86\u5e7f\u6cdb\u7684\u5173\u6ce8\u3002\u6700\u5c0f\u52bf\u80fd\u539f\u7406\u548c\u4e92\u8865\u80fd\u539f\u7406\u662f\u56fa\u4f53\u529b\u5b66\u4e2d\u7684\u4e24\u4e2a\u91cd\u8981\u53d8\u5206\u539f\u7406\u3002\u7136\u800c\uff0c\u5e7f\u4e3a\u4eba\u77e5\u7684\u6df1\u5ea6\u80fd\u91cf\u65b9\u6cd5\uff08DEM\uff09\u57fa\u4e8e\u6700\u5c0f\u52bf\u80fd\u539f\u7406\uff0c\u5374\u7f3a\u4e4f\u81f3\u5173\u91cd\u8981\u7684\u6700\u5c0f\u4e92\u8865\u80fd\u5f62\u5f0f\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7f3a\u53e3\uff0c\u6211\u4eec\u63d0\u51fa\u57fa\u4e8e\u6700\u5c0f\u4e92\u8865\u80fd\u539f\u7406\u7684\u6df1\u5ea6\u4e92\u8865\u80fd\u91cf\u65b9\u6cd5\uff08DCEM\uff09\u3002DCEM\u7684\u8f93\u51fa\u51fd\u6570\u4e3a\u5e94\u529b\u51fd\u6570\uff0c\u56fa\u6709\u5730\u6ee1\u8db3\u5e73\u8861\u65b9\u7a0b\u3002\u6211\u4eec\u901a\u8fc7\u666e\u6717\u7279\u5e94\u529b\u51fd\u6570\u548c\u7231\u91cc\u5e94\u529b\u51fd\u6570\u7ed9\u51fa\u4e86\u6570\u503c\u7ed3\u679c\uff0c\u5e76\u5c06DCEM\u4e0e\u73b0\u6709\u7684PINNs\u548cDEM\u7b97\u6cd5\u5728\u5efa\u6a21\u4ee3\u8868\u6027\u673a\u68b0\u95ee\u9898\u65f6\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u7ed3\u679c\u663e\u793a\uff0cDCEM\u5728\u5e94\u529b\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8eDEM\uff0c\u5e76\u4e14\u5728\u5904\u7406\u590d\u6742\u4f4d\u79fb\u8fb9\u754c\u6761\u4ef6\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u8fd9\u5f97\u5230\u4e86\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u6a21\u62df\u7684\u652f\u6301\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u6269\u5c55\u4e86DCEM\u81f3DCEM-Plus\uff08DCEM-P\uff09\uff0c\u52a0\u5165\u4e86\u6ee1\u8db3\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u9879\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u7ed3\u5408\u64cd\u4f5c\u5b66\u4e60\u4e0e\u7269\u7406\u65b9\u7a0b\u7684\u6df1\u5ea6\u4e92\u8865\u80fd\u91cf\u7b97\u5b50\u65b9\u6cd5\uff08DCEM-O\uff09\u3002\u9996\u5148\uff0c\u6211\u4eec\u5229\u7528\u9ad8\u7cbe\u5ea6\u6570\u503c\u7ed3\u679c\u8bad\u7ec3DCEM-O\uff0c\u7136\u540e\u5f15\u5165\u4e92\u8865\u80fd\u3002DCEM-P\u548cDCEM-O\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86DCEM\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "update_time": "2024-07-29 16:55:33+00:00", "publish_time": "2023-02-03 04:24:49+00:00"}, {"entry_id": "2404.10148v2", "title": "Node Similarities under Random Projections: Limits and Pathological Cases", "summary": "Random Projections have been widely used to generate embeddings for various\ngraph learning tasks due to their computational efficiency. The majority of\napplications have been justified through the Johnson-Lindenstrauss Lemma. In\nthis paper, we take a step further and investigate how well dot product and\ncosine similarity are preserved by random projections when these are applied\nover the rows of the graph matrix. Our analysis provides new asymptotic and\nfinite-sample results, identifies pathological cases, and tests them with\nnumerical experiments. We specialize our fundamental results to a ranking\napplication by computing the probability of random projections flipping the\nnode ordering induced by their embeddings. We find that, depending on the\ndegree distribution, the method produces especially unreliable embeddings for\nthe dot product, regardless of whether the adjacency or the normalized\ntransition matrix is used. With respect to the statistical noise introduced by\nrandom projections, we show that cosine similarity produces remarkably more\nprecise approximations.", "pdf_path": null, "cn_title": "\u8282\u70b9\u5728\u968f\u673a\u6295\u5f71\u4e0b\u7684\u76f8\u4f3c\u6027\uff1a\u6781\u9650\u4e0e\u75c5\u7406\u6848\u4f8b", "cn_summary": "\u968f\u673a\u6295\u5f71\u5728\u5404\u79cd\u56fe\u5b66\u4e60\u4efb\u52a1\u4e2d\u5e7f\u6cdb\u7528\u4e8e\u751f\u6210\u5d4c\u5165\uff0c\u56e0\u5176\u8ba1\u7b97\u6548\u7387\u9ad8\u3002\u5927\u591a\u6570\u5e94\u7528\u901a\u8fc7\u7ea6\u7ff0\u900a-\u6797\u767b\u65af\u7279\u62c9\u65af\u5f15\u7406\u5f97\u5230\u9a8c\u8bc1\u3002\u672c\u6587\u66f4\u8fdb\u4e00\u6b65\uff0c\u63a2\u8ba8\u4e86\u5f53\u5728\u56fe\u77e9\u9635\u7684\u884c\u4e0a\u5e94\u7528\u70b9\u79ef\u548c\u4f59\u5f26\u76f8\u4f3c\u6027\u65f6\uff0c\u968f\u673a\u6295\u5f71\u5982\u4f55\u4fdd\u6301\u8fd9\u4e9b\u5c5e\u6027\u3002\u6211\u4eec\u7684\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u6e10\u8fd1\u6027\u548c\u6709\u9650\u6837\u672c\u7ed3\u679c\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u8bc6\u522b\u5e76\u6d4b\u8bd5\u4e86\u75c5\u6001\u60c5\u51b5\u3002\u6211\u4eec\u5c06\u57fa\u672c\u7ed3\u679c\u4e13\u95e8\u5e94\u7528\u4e8e\u6392\u540d\u5e94\u7528\uff0c\u901a\u8fc7\u8ba1\u7b97\u968f\u673a\u6295\u5f71\u6539\u53d8\u5176\u5d4c\u5165\u8bf1\u5bfc\u7684\u8282\u70b9\u987a\u5e8f\u7684\u6982\u7387\u3002\u6211\u4eec\u53d1\u73b0\uff0c\u6839\u636e\u5ea6\u5206\u5e03\uff0c\u8be5\u65b9\u6cd5\u5bf9\u70b9\u79ef\u751f\u6210\u7684\u5d4c\u5165\u7279\u522b\u4e0d\u53ef\u9760\uff0c\u65e0\u8bba\u4f7f\u7528\u90bb\u63a5\u77e9\u9635\u8fd8\u662f\u5f52\u4e00\u5316\u8f6c\u79fb\u77e9\u9635\u3002\u4e0e\u968f\u673a\u6295\u5f71\u5f15\u5165\u7684\u7edf\u8ba1\u566a\u58f0\u76f8\u6bd4\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u4f59\u5f26\u76f8\u4f3c\u6027\u4ea7\u751f\u66f4\u4e3a\u7cbe\u786e\u7684\u8fd1\u4f3c\u3002", "update_time": "2024-07-29 16:51:26+00:00", "publish_time": "2024-04-15 21:35:25+00:00"}, {"entry_id": "2407.20164v1", "title": "Language-Conditioned Offline RL for Multi-Robot Navigation", "summary": "We present a method for developing navigation policies for multi-robot teams\nthat interpret and follow natural language instructions. We condition these\npolicies on embeddings from pretrained Large Language Models (LLMs), and train\nthem via offline reinforcement learning with as little as 20 minutes of\nrandomly-collected data. Experiments on a team of five real robots show that\nthese policies generalize well to unseen commands, indicating an understanding\nof the LLM latent space. Our method requires no simulators or environment\nmodels, and produces low-latency control policies that can be deployed directly\nto real robots without finetuning. We provide videos of our experiments at\nhttps://sites.google.com/view/llm-marl.", "pdf_path": null, "cn_title": "\u57fa\u4e8e\u8bed\u8a00\u6761\u4ef6\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728\u591a\u673a\u5668\u4eba\u5bfc\u822a\u4e2d\u7684\u5e94\u7528", "cn_summary": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u7528\u4e8e\u4e3a\u591a\u673a\u5668\u4eba\u56e2\u961f\u5f00\u53d1\u80fd\u591f\u7406\u89e3\u548c\u9075\u5faa\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u7684\u5bfc\u822a\u7b56\u7565\u3002\u6211\u4eec\u901a\u8fc7\u9884\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5d4c\u5165\u6765\u6761\u4ef6\u5316\u8fd9\u4e9b\u7b56\u7565\uff0c\u5e76\u5229\u7528\u6700\u5c1120\u5206\u949f\u968f\u673a\u6536\u96c6\u7684\u6570\u636e\u8fdb\u884c\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002\u5728\u4e94\u53f0\u5b9e\u9645\u673a\u5668\u4eba\u7ec4\u6210\u7684\u56e2\u961f\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u4e9b\u7b56\u7565\u5bf9\u672a\u89c1\u8fc7\u7684\u547d\u4ee4\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u6697\u793a\u4e86\u5bf9LLM\u6f5c\u5728\u7a7a\u95f4\u7684\u7406\u89e3\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u65e0\u9700\u6a21\u62df\u5668\u6216\u73af\u5883\u6a21\u578b\uff0c\u4ea7\u751f\u4f4e\u5ef6\u8fdf\u7684\u63a7\u5236\u7b56\u7565\uff0c\u53ef\u4ee5\u76f4\u63a5\u90e8\u7f72\u5230\u5b9e\u9645\u673a\u5668\u4eba\u4e0a\u800c\u65e0\u9700\u5fae\u8c03\u3002\u6211\u4eec\u63d0\u4f9b\u4e86\u5b9e\u9a8c\u89c6\u9891\u4f9b\u53c2\u8003\uff0c\u7f51\u5740\u4e3ahttps://sites.google.com/view/llm-marl\u3002", "update_time": "2024-07-29 16:49:30+00:00", "publish_time": "2024-07-29 16:49:30+00:00"}, {"entry_id": "2407.20158v1", "title": "Machine Learning for predicting chaotic systems", "summary": "Predicting chaotic dynamical systems is critical in many scientific fields\nsuch as weather prediction, but challenging due to the characterizing sensitive\ndependence on initial conditions. Traditional modeling approaches require\nextensive domain knowledge, often leading to a shift towards data-driven\nmethods using machine learning. However, existing research provides\ninconclusive results on which machine learning methods are best suited for\npredicting chaotic systems. In this paper, we compare different lightweight and\nheavyweight machine learning architectures using extensive existing databases,\nas well as a newly introduced one that allows for uncertainty quantification in\nthe benchmark results. We perform hyperparameter tuning based on computational\ncost and introduce a novel error metric, the cumulative maximum error, which\ncombines several desirable properties of traditional metrics, tailored for\nchaotic systems. Our results show that well-tuned simple methods, as well as\nuntuned baseline methods, often outperform state-of-the-art deep learning\nmodels, but their performance can vary significantly with different\nexperimental setups. These findings underscore the importance of matching\nprediction methods to data characteristics and available computational\nresources.", "pdf_path": null, "cn_title": "\u673a\u5668\u5b66\u4e60\u5728\u9884\u6d4b\u6df7\u6c8c\u7cfb\u7edf\u7684\u5e94\u7528", "cn_summary": "\u9884\u6d4b\u6df7\u6c8c\u52a8\u529b\u5b66\u7cfb\u7edf\u5728\u8bb8\u591a\u79d1\u5b66\u9886\u57df\u81f3\u5173\u91cd\u8981\uff0c\u4f8b\u5982\u5929\u6c14\u9884\u62a5\uff0c\u4f46\u7531\u4e8e\u521d\u59cb\u6761\u4ef6\u7684\u654f\u611f\u4f9d\u8d56\u6027\uff0c\u8fd9\u4e00\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\u3002\u4f20\u7edf\u5efa\u6a21\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7684\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5f80\u5f80\u5bfc\u81f4\u8f6c\u5411\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u5229\u7528\u673a\u5668\u5b66\u4e60\u3002\u7136\u800c\uff0c\u73b0\u6709\u7814\u7a76\u5bf9\u54ea\u79cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6700\u9002\u5408\u9884\u6d4b\u6df7\u6c8c\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e0d\u660e\u786e\u7684\u7ed3\u679c\u3002\u5728\u8fd9\u7bc7\u8bba\u6587\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u5e7f\u6cdb\u7684\u73b0\u6709\u6570\u636e\u5e93\u548c\u4e00\u4e2a\u65b0\u5f15\u5165\u7684\u6570\u636e\u5e93\u8fdb\u884c\u6bd4\u8f83\uff0c\u8be5\u6570\u636e\u5e93\u5141\u8bb8\u5728\u57fa\u51c6\u7ed3\u679c\u4e2d\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u5bf9\u6bd4\u4e0d\u540c\u8f7b\u91cf\u7ea7\u548c\u91cd\u91cf\u7ea7\u7684\u673a\u5668\u5b66\u4e60\u67b6\u6784\u3002\u57fa\u4e8e\u8ba1\u7b97\u6210\u672c\u8fdb\u884c\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u578b\u9519\u8bef\u5ea6\u91cf\u6807\u51c6\u2014\u2014\u7d2f\u79ef\u6700\u5927\u8bef\u5dee\uff0c\u7ed3\u5408\u4e86\u4f20\u7edf\u5ea6\u91cf\u6807\u51c6\u7684\u4e00\u4e9b\u4f18\u70b9\uff0c\u5e76\u9488\u5bf9\u6df7\u6c8c\u7cfb\u7edf\u8fdb\u884c\u4e86\u5b9a\u5236\u3002\u6211\u4eec\u7684\u7ed3\u679c\u663e\u793a\uff0c\u7cbe\u5fc3\u8c03\u6574\u7684\u7b80\u5355\u65b9\u6cd5\u4ee5\u53ca\u672a\u7ecf\u8c03\u6574\u7684\u57fa\u672c\u65b9\u6cd5\u901a\u5e38\u6bd4\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u5176\u6027\u80fd\u968f\u7740\u4e0d\u540c\u7684\u5b9e\u9a8c\u8bbe\u7f6e\u53ef\u80fd\u6709\u5f88\u5927\u5dee\u5f02\u3002\u8fd9\u4e9b\u53d1\u73b0\u5f3a\u8c03\u4e86\u5339\u914d\u9884\u6d4b\u65b9\u6cd5\u5230\u6570\u636e\u7279\u6027\u548c\u53ef\u7528\u8ba1\u7b97\u8d44\u6e90\u7684\u91cd\u8981\u6027\u3002", "update_time": "2024-07-29 16:34:47+00:00", "publish_time": "2024-07-29 16:34:47+00:00"}, {"entry_id": "2407.20157v1", "title": "rLLM: Relational Table Learning with LLMs", "summary": "We introduce rLLM (relationLLM), a PyTorch library designed for Relational\nTable Learning (RTL) with Large Language Models (LLMs). The core idea is to\ndecompose state-of-the-art Graph Neural Networks, LLMs, and Table Neural\nNetworks into standardized modules, to enable the fast construction of novel\nRTL-type models in a simple \"combine, align, and co-train\" manner. To\nillustrate the usage of rLLM, we introduce a simple RTL method named\n\\textbf{BRIDGE}. Additionally, we present three novel relational tabular\ndatasets (TML1M, TLF2K, and TACM12K) by enhancing classic datasets. We hope\nrLLM can serve as a useful and easy-to-use development framework for\nRTL-related tasks. Our code is available at:\nhttps://github.com/rllm-project/rllm.", "pdf_path": null, "cn_title": "RLLM\uff1a\u57fa\u4e8eLLMs\u7684\u5173\u7cfb\u8868\u5b66\u4e60", "cn_summary": "\u6211\u4eec\u5f15\u5165\u4e86rLLM\uff08\u5173\u7cfbLLM\uff09\uff0c\u4e00\u4e2a\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u5173\u7cfb\u8868\u5b66\u4e60\uff08RTL\uff09\u76f8\u7ed3\u5408\u7684PyTorch\u5e93\u3002\u6838\u5fc3\u601d\u60f3\u662f\u5c06\u6700\u5148\u8fdb\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u3001LLMs\u548c\u8868\u683c\u795e\u7ecf\u7f51\u7edc\u5206\u89e3\u4e3a\u6807\u51c6\u5316\u6a21\u5757\uff0c\u4ee5\u5b9e\u73b0\u5feb\u901f\u6784\u5efa\u65b0\u578bRTL\u578b\u6a21\u578b\u7684\u7b80\u5355\u201c\u7ec4\u5408\u3001\u5bf9\u9f50\u548c\u5171\u8bad\u7ec3\u201d\u65b9\u5f0f\u3002\u4e3a\u4e86\u8bf4\u660erLLM\u7684\u4f7f\u7528\u65b9\u6cd5\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7b80\u5355\u7684RTL\u65b9\u6cd5\u540d\u4e3aBRIDGE\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u589e\u5f3a\u7ecf\u5178\u6570\u636e\u96c6\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u4e09\u4e2a\u65b0\u7684\u5173\u7cfb\u8868\u683c\u6570\u636e\u96c6\uff08TML1M\u3001TLF2K\u548cTACM12K\uff09\u3002\u6211\u4eec\u5e0c\u671brLLM\u80fd\u591f\u4f5c\u4e3a\u5173\u7cfb\u8868\u5b66\u4e60\u76f8\u5173\u4efb\u52a1\u6709\u7528\u4e14\u6613\u4e8e\u4f7f\u7528\u7684\u5f00\u53d1\u6846\u67b6\u3002\u6211\u4eec\u7684\u4ee3\u7801\u53ef\u4ee5\u5728\u4ee5\u4e0b\u4f4d\u7f6e\u83b7\u53d6\uff1ahttps://github.com/rllm-project/rllm\u3002", "update_time": "2024-07-29 16:33:40+00:00", "publish_time": "2024-07-29 16:33:40+00:00"}, {"entry_id": "2305.15220v2", "title": "Selection for short-term empowerment accelerates the evolution of homeostatic neural cellular automata", "summary": "Empowerment -- a domain independent, information-theoretic metric -- has\npreviously been shown to assist in the evolutionary search for neural cellular\nautomata (NCA) capable of homeostasis when employed as a fitness function. In\nour previous study, we successfully extended empowerment, defined as maximum\ntime-lagged mutual information between agents' actions and future sensations,\nto a distributed sensorimotor system embodied as an NCA. However, the\ntime-delay between actions and their corresponding sensations was arbitrarily\nchosen. Here, we expand upon previous work by exploring how the time scale at\nwhich empowerment operates impacts its efficacy as an auxiliary objective to\naccelerate the discovery of homeostatic NCAs. We show that shorter time delays\nresult in marked improvements over empowerment with longer delays, when\ncompared to evolutionary selection only for homeostasis. Moreover, we evaluate\nstability and adaptability of evolved NCAs, both hallmarks of living systems\nthat are of interest to replicate in artificial ones. We find that short-term\nempowered NCA are more stable and are capable of generalizing better to unseen\nhomeostatic challenges. Taken together, these findings motivate the use of\nempowerment during the evolution of other artifacts, and suggest how it should\nbe incorporated to accelerate evolution of desired behaviors for them. Source\ncode for the experiments in this paper can be found at:\nhttps://github.com/caitlingrasso/empowered-nca-II.", "pdf_path": null, "cn_title": "\u4e3a\u4e86\u77ed\u671f\u589e\u5f3a\u800c\u8fdb\u884c\u7684\u9009\u62e9\u52a0\u901f\u4e86\u7a33\u6001\u795e\u7ecf\u7ec6\u80de\u81ea\u52a8\u673a\u7684\u8fdb\u5316\u3002", "cn_summary": "\u8d4b\u80fd\u2014\u2014\u4e00\u4e2a\u72ec\u7acb\u4e8e\u9886\u57df\u7684\u3001\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u5ea6\u91cf\u6807\u51c6\u2014\u2014\u5148\u524d\u5df2\u88ab\u8bc1\u660e\u5728\u4f5c\u4e3a\u9002\u5e94\u6027\u51fd\u6570\u65f6\uff0c\u80fd\u591f\u8f85\u52a9\u795e\u7ecf\u7ec6\u80de\u81ea\u52a8\u673a\uff08NCA\uff09\u7684\u8fdb\u5316\u641c\u7d22\uff0c\u5bfb\u627e\u80fd\u591f\u5728\u4f53\u5185\u7ef4\u6301\u7a33\u6001\u7684\u7cfb\u7edf\u3002\u5728\u6211\u4eec\u4e4b\u524d\u7684\u7814\u7a76\u6240\u4e2d\uff0c\u6210\u529f\u5730\u5c06\u8d4b\u80fd\u5b9a\u4e49\u4e3a\u884c\u52a8\u8005\u884c\u4e3a\u4e0e\u672a\u6765\u611f\u89c9\u4e4b\u95f4\u7684\u6700\u5927\u65f6\u95f4\u6ede\u540e\u4e92\u4fe1\u606f\uff0c\u6269\u5c55\u5230\u4e86\u7531NCA\u6784\u6210\u7684\u5206\u5e03\u5f0f\u4f20\u611f\u5668-\u8fd0\u52a8\u7cfb\u7edf\u4e2d\u3002\u7136\u800c\uff0c\u884c\u52a8\u4e0e\u5176\u76f8\u5e94\u611f\u89c9\u4e4b\u95f4\u7684\u65f6\u95f4\u5ef6\u8fdf\u662f\u4efb\u610f\u9009\u62e9\u7684\u3002\u5728\u6b64\uff0c\u6211\u4eec\u8fdb\u4e00\u6b65\u7814\u7a76\u4e86\u8d4b\u80fd\u64cd\u4f5c\u7684\u65f6\u95f4\u5c3a\u5ea6\u5982\u4f55\u5f71\u54cd\u5176\u4f5c\u4e3a\u8f85\u52a9\u76ee\u6807\u7684\u6709\u6548\u6027\uff0c\u4ee5\u52a0\u901f\u53d1\u73b0\u5177\u6709\u7a33\u6001\u529f\u80fd\u7684NCA\u3002\u6211\u4eec\u5c55\u793a\u4e86\u4e0e\u4ec5\u901a\u8fc7\u8fdb\u5316\u9009\u62e9\u6765\u5bfb\u627e\u7a33\u6001\u76f8\u6bd4\uff0c\u8f83\u77ed\u7684\u65f6\u95f4\u5ef6\u8fdf\u5bfc\u81f4\u4e86\u663e\u8457\u7684\u6539\u5584\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8bc4\u4f30\u4e86\u8fdb\u5316\u540e\u7684NCA\u7684\u7a33\u5b9a\u6027\u548c\u9002\u5e94\u6027\uff0c\u8fd9\u662f\u751f\u6d3b\u7cfb\u7edf\u4e2d\u7684\u4e24\u4e2a\u91cd\u8981\u7279\u5f81\uff0c\u5e76\u4e14\u5bf9\u4e8e\u590d\u5236\u5230\u4eba\u5de5\u7cfb\u7edf\u4e2d\u540c\u6837\u611f\u5174\u8da3\u3002\u6211\u4eec\u53d1\u73b0\uff0c\u77ed\u671f\u8d4b\u80fd\u7684NCA\u66f4\u4e3a\u7a33\u5b9a\uff0c\u5e76\u4e14\u80fd\u591f\u5728\u672a\u89c1\u7684\u7a33\u6001\u6311\u6218\u4e2d\u66f4\u597d\u5730\u6cdb\u5316\u3002\u7efc\u5408\u8fd9\u4e9b\u53d1\u73b0\uff0c\u5b83\u4eec\u9f13\u52b1\u5728\u8fdb\u5316\u5176\u4ed6\u5236\u54c1\u65f6\u4f7f\u7528\u8d4b\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u5982\u4f55\u5c06\u5176\u6574\u5408\u4ee5\u52a0\u901f\u5bf9\u6240\u9700\u884c\u4e3a\u7684\u8fdb\u5316\u7684\u5efa\u8bae\u3002\u5b9e\u9a8c\u4ee3\u7801\u53ef\u5728\u4ee5\u4e0b\u94fe\u63a5\u4e2d\u627e\u5230\uff1ahttps://github.com/caitlingrasso/empowered-nca-II.", "update_time": "2024-07-29 16:30:49+00:00", "publish_time": "2023-05-24 15:01:30+00:00"}, {"entry_id": "2407.20152v1", "title": "Hierarchically Disentangled Recurrent Network for Factorizing System Dynamics of Multi-scale Systems", "summary": "We present a knowledge-guided machine learning (KGML) framework for modeling\nmulti-scale processes, and study its performance in the context of streamflow\nforecasting in hydrology. Specifically, we propose a novel hierarchical\nrecurrent neural architecture that factorizes the system dynamics at multiple\ntemporal scales and captures their interactions. This framework consists of an\ninverse and a forward model. The inverse model is used to empirically resolve\nthe system's temporal modes from data (physical model simulations, observed\ndata, or a combination of them from the past), and these states are then used\nin the forward model to predict streamflow. In a hydrological system, these\nmodes can represent different processes, evolving at different temporal scales\n(e.g., slow: groundwater recharge and baseflow vs. fast: surface runoff due to\nextreme rainfall). A key advantage of our framework is that once trained, it\ncan incorporate new observations into the model's context (internal state)\nwithout expensive optimization approaches (e.g., EnKF) that are traditionally\nused in physical sciences for data assimilation. Experiments with several river\ncatchments from the NWS NCRFC region show the efficacy of this ML-based data\nassimilation framework compared to standard baselines, especially for basins\nthat have a long history of observations. Even for basins that have a shorter\nobservation history, we present two orthogonal strategies of training our FHNN\nframework: (a) using simulation data from imperfect simulations and (b) using\nobservation data from multiple basins to build a global model. We show that\nboth of these strategies (that can be used individually or together) are highly\neffective in mitigating the lack of training data. The improvement in forecast\naccuracy is particularly noteworthy for basins where local models perform\npoorly because of data sparsity.", "pdf_path": null, "cn_title": "\u5206\u5c42\u89e3\u8026\u5faa\u73af\u7f51\u7edc\uff1a\u591a\u5c3a\u5ea6\u7cfb\u7edf\u52a8\u529b\u5b66\u5206\u89e3\u65b9\u6cd5", "cn_summary": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u77e5\u8bc6\u5f15\u5bfc\u7684\u673a\u5668\u5b66\u4e60\uff08KGML\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21\u591a\u5c3a\u5ea6\u8fc7\u7a0b\uff0c\u5e76\u5728\u6c34\u6587\u4e2d\u7684\u5f84\u6d41\u9884\u62a5\u80cc\u666f\u4e0b\u7814\u7a76\u5176\u6027\u80fd\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5c42\u6b21\u9012\u5f52\u795e\u7ecf\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u5728\u591a\u4e2a\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u5206\u89e3\u7cfb\u7edf\u52a8\u529b\u5b66\u5e76\u6355\u83b7\u5b83\u4eec\u4e4b\u95f4\u7684\u4ea4\u4e92\u3002\u6b64\u6846\u67b6\u7531\u9006\u6a21\u578b\u548c\u6b63\u5411\u6a21\u578b\u7ec4\u6210\u3002\u9006\u6a21\u578b\u88ab\u7528\u6765\u4ece\u6570\u636e\uff08\u7269\u7406\u6a21\u578b\u6a21\u62df\u3001\u89c2\u6d4b\u6570\u636e\u6216\u8fc7\u53bb\u7684\u6570\u636e\u7ec4\u5408\uff09\u4e2d\u7ecf\u9a8c\u6027\u5730\u89e3\u6790\u7cfb\u7edf\u7684\u65f6\u6001\u6a21\u5f0f\uff0c\u5e76\u4f7f\u7528\u8fd9\u4e9b\u72b6\u6001\u4f5c\u4e3a\u6b63\u5411\u6a21\u578b\u9884\u6d4b\u5f84\u6d41\u7684\u57fa\u7840\u3002\u5728\u6c34\u6587\u7cfb\u7edf\u4e2d\uff0c\u8fd9\u4e9b\u6a21\u5f0f\u53ef\u4ee5\u4ee3\u8868\u4e0d\u540c\u8fdb\u7a0b\uff0c\u5728\u4e0d\u540c\u7684\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u6f14\u53d8\uff08\u4f8b\u5982\uff0c\u6162\u901f\uff1a\u5730\u4e0b\u6c34\u8865\u7ed9\u548c\u57fa\u6d41\u4e0e\u5feb\u901f\uff1a\u6781\u7aef\u964d\u96e8\u5bfc\u81f4\u7684\u5730\u8868\u5f84\u6d41\uff09\u3002\u6211\u4eec\u7684\u6846\u67b6\u7684\u5173\u952e\u4f18\u52bf\u5728\u4e8e\uff0c\u4e00\u65e6\u8bad\u7ec3\u5b8c\u6210\uff0c\u5b83\u4fbf\u80fd\u4e0d\u9700\u6602\u8d35\u7684\u4f18\u5316\u65b9\u6cd5\uff08\u5982EnKF\uff09\u5c31\u53ef\u5c06\u65b0\u89c2\u5bdf\u878d\u5165\u6a21\u578b\u4e0a\u4e0b\u6587\uff08\u5185\u90e8\u72b6\u6001\uff09\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4f20\u7edf\u4e0a\u5728\u7269\u7406\u79d1\u5b66\u4e2d\u7528\u4e8e\u6570\u636e\u540c\u5316\u3002\u5728NWS NCRFC\u5730\u533a\u7684\u591a\u4e2a\u6d41\u57df\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u6570\u636e\u540c\u5316\u6846\u67b6\u76f8\u8f83\u4e8e\u6807\u51c6\u57fa\u51c6\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u6709\u957f\u671f\u89c2\u6d4b\u8bb0\u5f55\u7684\u6d41\u57df\u4e2d\u8868\u73b0\u5c24\u4e3a\u663e\u8457\u3002\u5373\u4f7f\u5bf9\u4e8e\u89c2\u6d4b\u8bb0\u5f55\u8f83\u77ed\u7684\u6d41\u57df\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e24\u79cd\u8bad\u7ec3\u6211\u4eec\u7684FHNN\u6846\u67b6\u7684\u76f8\u4e92\u72ec\u7acb\u7b56\u7565\uff1a(a) \u4f7f\u7528\u4e0d\u5b8c\u7f8e\u7684\u6a21\u62df\u6570\u636e\uff0c(b) \u4f7f\u7528\u6765\u81ea\u591a\u4e2a\u6d41\u57df\u7684\u89c2\u6d4b\u6570\u636e\u6784\u5efa\u5168\u5c40\u6a21\u578b\u3002\u6211\u4eec\u8bc1\u660e\u4e86\u8fd9\u4e24\u79cd\u7b56\u7565\uff08\u53ef\u4ee5\u5355\u72ec\u4f7f\u7528\u6216\u7ed3\u5408\u4f7f\u7528\uff09\u5bf9\u4e8e\u7f13\u89e3\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u95ee\u9898\u5177\u6709\u9ad8\u5ea6\u6709\u6548\u6027\u3002\u5c24\u5176\u662f\u5728\u5c40\u90e8\u6a21\u578b\u56e0\u6570\u636e\u7a00\u758f\u800c\u8868\u73b0\u4e0d\u4f73\u7684\u6d41\u57df\u4e2d\uff0c\u9884\u62a5\u51c6\u786e\u6027\u7684\u63d0\u9ad8\u5c24\u5176\u503c\u5f97\u6ce8\u610f\u3002", "update_time": "2024-07-29 16:25:43+00:00", "publish_time": "2024-07-29 16:25:43+00:00"}, {"entry_id": "2407.07934v3", "title": "Identifying macro conditional independencies and macro total effects in summary causal graphs with latent confounding", "summary": "Understanding causal relations in dynamic systems is essential in\nepidemiology. While causal inference methods have been extensively studied,\nthey often rely on fully specified causal graphs, which may not always be\navailable in complex dynamic systems. Partially specified causal graphs, such\nas summary causal graphs (SCGs), provide a simplified representation of causal\nrelations, omitting temporal information and focusing on high-level causal\nstructures. This simplification introduces new challenges concerning the types\nof queries of interest: macro queries, which involve relationships between\nclusters represented as vertices in the graph, and micro queries, which pertain\nto relationships between variables that are not directly visible through the\nvertices of the graph. In this paper, we first clearly distinguish between\nmacro conditional independencies and micro conditional independencies and\nbetween macro total effects and micro total effects. Then, we demonstrate the\nsoundness and completeness of the d-separation to identify macro conditional\nindependencies in SCGs. Furthermore, we establish that the do-calculus is sound\nand complete for identifying macro total effects in SCGs. Finally, we give a\ngraphical characterization for the non-identifiability of macro total effects\nin SCGs.", "pdf_path": null, "cn_title": "\u8bc6\u522b\u9690\u533f\u6df7\u6742\u56e0\u7d20\u5728\u6982\u8981\u56e0\u679c\u56fe\u4e2d\u7684\u5b8f\u89c2\u6761\u4ef6\u72ec\u7acb\u6027\u548c\u5b8f\u89c2\u603b\u6548\u5e94", "cn_summary": "\u5728\u6d41\u884c\u75c5\u5b66\u4e2d\uff0c\u7406\u89e3\u52a8\u6001\u7cfb\u7edf\u4e2d\u7684\u56e0\u679c\u5173\u7cfb\u81f3\u5173\u91cd\u8981\u3002\u5c3d\u7ba1\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u5df2\u7ecf\u5f97\u5230\u4e86\u5e7f\u6cdb\u7684\u7814\u7a76\uff0c\u4f46\u5b83\u4eec\u5f80\u5f80\u4f9d\u8d56\u4e8e\u5b8c\u5168\u6307\u5b9a\u7684\u56e0\u679c\u56fe\uff0c\u800c\u5728\u590d\u6742\u7684\u52a8\u6001\u7cfb\u7edf\u4e2d\uff0c\u8fd9\u79cd\u56fe\u53ef\u80fd\u5e76\u4e0d\u603b\u662f\u53ef\u7528\u7684\u3002\u90e8\u5206\u6307\u5b9a\u7684\u56e0\u679c\u56fe\uff08\u5982\u6458\u8981\u56e0\u679c\u56feSCGs\uff09\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5316\u8868\u793a\u56e0\u679c\u5173\u7cfb\u7684\u65b9\u5f0f\uff0c\u5b83\u5ffd\u7565\u4e86\u65f6\u95f4\u4fe1\u606f\uff0c\u800c\u4e13\u6ce8\u4e8e\u9ad8\u7ea7\u522b\u7684\u56e0\u679c\u7ed3\u6784\u3002\u8fd9\u79cd\u7b80\u5316\u5e26\u6765\u4e86\u65b0\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u4e0e\u611f\u5174\u8da3\u67e5\u8be2\u7c7b\u578b\u6709\u5173\u7684\u95ee\u9898\uff1a\u6d89\u53ca\u56fe\u5f62\u4e2d\u8282\u70b9\u8868\u793a\u7684\u7c07\u4e4b\u95f4\u7684\u5b8f\u89c2\u67e5\u8be2\uff0c\u4ee5\u53ca\u6d89\u53ca\u901a\u8fc7\u56fe\u5f62\u4e2d\u8282\u70b9\u65e0\u6cd5\u76f4\u63a5\u770b\u5230\u7684\u53d8\u91cf\u4e4b\u95f4\u7684\u5fae\u89c2\u67e5\u8be2\u3002\n\n\u5728\u8fd9\u7bc7\u8bba\u6587\u4e2d\uff0c\u6211\u4eec\u9996\u5148\u660e\u786e\u5730\u533a\u5206\u4e86\u5b8f\u89c2\u6761\u4ef6\u72ec\u7acb\u6027\u548c\u5fae\u89c2\u6761\u4ef6\u72ec\u7acb\u6027\uff0c\u4ee5\u53ca\u5b8f\u89c2\u603b\u6548\u5e94\u548c\u5fae\u89c2\u603b\u6548\u5e94\u3002\u7136\u540e\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5728SCGs\u4e2d\u8bc6\u522b\u5b8f\u89c2\u6761\u4ef6\u72ec\u7acb\u6027\u7684d\u5206\u79bb\u7684\u6b63\u786e\u6027\u548c\u5b8c\u6574\u6027\u3002\u8fdb\u4e00\u6b65\u5730\uff0c\u6211\u4eec\u8bc1\u660e\u4e86do-\u8ba1\u7b97\u5bf9\u4e8e\u5728SCGs\u4e2d\u8bc6\u522b\u5b8f\u89c2\u603b\u6548\u5e94\u7684\u6b63\u786e\u6027\u548c\u5b8c\u6574\u6027\u662f\u6210\u7acb\u7684\u3002\u6700\u540e\uff0c\u6211\u4eec\u7ed9\u51fa\u4e86SCGs\u4e2d\u5b8f\u89c2\u603b\u6548\u5e94\u4e0d\u53ef\u8bc6\u522b\u6027\u7684\u56fe\u5f62\u7279\u5f81\u63cf\u8ff0\u3002", "update_time": "2024-07-29 16:24:45+00:00", "publish_time": "2024-07-10 16:03:04+00:00"}, {"entry_id": "2407.20147v1", "title": "Quantum Machine Learning Architecture Search via Deep Reinforcement Learning", "summary": "The rapid advancement of quantum computing (QC) and machine learning (ML) has\ngiven rise to the burgeoning field of quantum machine learning (QML), aiming to\ncapitalize on the strengths of quantum computing to propel ML forward. Despite\nits promise, crafting effective QML models necessitates profound expertise to\nstrike a delicate balance between model intricacy and feasibility on Noisy\nIntermediate-Scale Quantum (NISQ) devices. While complex models offer robust\nrepresentation capabilities, their extensive circuit depth may impede seamless\nexecution on extant noisy quantum platforms. In this paper, we address this\nquandary of QML model design by employing deep reinforcement learning to\nexplore proficient QML model architectures tailored for designated supervised\nlearning tasks. Specifically, our methodology involves training an RL agent to\ndevise policies that facilitate the discovery of QML models without\npredetermined ansatz. Furthermore, we integrate an adaptive mechanism to\ndynamically adjust the learning objectives, fostering continuous improvement in\nthe agent's learning process. Through extensive numerical simulations, we\nillustrate the efficacy of our approach within the realm of classification\ntasks. Our proposed method successfully identifies VQC architectures capable of\nachieving high classification accuracy while minimizing gate depth. This\npioneering approach not only advances the study of AI-driven quantum circuit\ndesign but also holds significant promise for enhancing performance in the NISQ\nera.", "pdf_path": null, "cn_title": "\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u67b6\u6784\u901a\u8fc7\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u641c\u7d22", "cn_summary": "\u91cf\u5b50\u8ba1\u7b97\uff08QC\uff09\u548c\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u7684\u98de\u901f\u53d1\u5c55\u50ac\u751f\u4e86\u91cf\u5b50\u673a\u5668\u5b66\u4e60\uff08QML\uff09\u8fd9\u4e00\u65b0\u5174\u9886\u57df\uff0c\u65e8\u5728\u5229\u7528\u91cf\u5b50\u8ba1\u7b97\u7684\u4f18\u52bf\u63a8\u52a8\u673a\u5668\u5b66\u4e60\u7684\u8fdb\u6b65\u3002\u5c3d\u7ba1\u524d\u666f\u5e7f\u9614\uff0c\u4f46\u8bbe\u8ba1\u6709\u6548\u7684QML\u6a21\u578b\u9700\u8981\u6df1\u5165\u7684\u4e13\u4e1a\u77e5\u8bc6\u6765\u5728\u6a21\u578b\u590d\u6742\u6027\u548c\u5728Noisy Intermediate-Scale Quantum\uff08NISQ\uff09\u8bbe\u5907\u4e0a\u7684\u53ef\u884c\u6027\u4e4b\u95f4\u627e\u5230\u5fae\u5999\u7684\u5e73\u8861\u3002\u590d\u6742\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u8868\u793a\u80fd\u529b\uff0c\u4f46\u5176\u7e41\u590d\u7684\u7535\u8def\u6df1\u5ea6\u53ef\u80fd\u4f1a\u963b\u788d\u73b0\u6709\u5608\u6742\u91cf\u5b50\u5e73\u53f0\u4e0a\u7684\u65e0\u7f1d\u6267\u884c\u3002\u672c\u6587\u901a\u8fc7\u5e94\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6765\u63a2\u7d22\u9002\u5408\u7279\u5b9a\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\u7684\u9ad8\u6548QML\u6a21\u578b\u67b6\u6784\uff0c\u4ee5\u89e3\u51b3QML\u6a21\u578b\u8bbe\u8ba1\u4e2d\u7684\u8fd9\u4e00\u56f0\u5883\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5305\u62ec\u8bad\u7ec3\u4e00\u4e2aRL\u4ee3\u7406\u4ee5\u5236\u5b9a\u7b56\u7565\uff0c\u8fd9\u4e9b\u7b56\u7565\u80fd\u591f\u4fc3\u8fdb\u65e0\u9884\u8bbe\u7b54\u6848\u6784\u9020\u7684QML\u6a21\u578b\u7684\u53d1\u73b0\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u6574\u5408\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u673a\u5236\uff0c\u7528\u4e8e\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u76ee\u6807\uff0c\u4ece\u800c\u4fc3\u8fdb\u4ee3\u7406\u5b66\u4e60\u8fc7\u7a0b\u7684\u6301\u7eed\u6539\u8fdb\u3002\u901a\u8fc7\u5e7f\u6cdb\u7684\u6570\u503c\u6a21\u62df\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u8fd9\u79cd\u65b9\u6cd5\u5728\u5206\u7c7b\u4efb\u52a1\u9886\u57df\u7684\u6709\u6548\u6027\u3002\u6211\u4eec\u63d0\u51fa\u7684\u65b9\u6cd5\u6210\u529f\u8bc6\u522b\u51faVQC\u67b6\u6784\uff0c\u8fd9\u4e9b\u67b6\u6784\u80fd\u591f\u5728\u4fdd\u6301\u9ad8\u5206\u7c7b\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u6700\u5c0f\u5316\u95e8\u6df1\u5ea6\u3002\u8fd9\u4e00\u5f00\u521b\u6027\u65b9\u6cd5\u4e0d\u4ec5\u63a8\u8fdb\u4e86\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u91cf\u5b50\u7535\u8def\u8bbe\u8ba1\u7684\u7814\u7a76\uff0c\u800c\u4e14\u5bf9\u4e8e\u63d0\u5347NISQ\u65f6\u4ee3\u7684\u6027\u80fd\u5177\u6709\u91cd\u5927\u6f5c\u529b\u3002", "update_time": "2024-07-29 16:20:51+00:00", "publish_time": "2024-07-29 16:20:51+00:00"}, {"entry_id": "2407.20143v1", "title": "ByteCheckpoint: A Unified Checkpointing System for LLM Development", "summary": "The development of real-world Large Language Models (LLMs) necessitates\ncheckpointing of training states in persistent storage to mitigate potential\nsoftware and hardware failures, as well as to facilitate checkpoint\ntransferring within the training pipeline and across various tasks. Due to the\nimmense size of LLMs, saving and loading checkpoints often incur intolerable\nminute-level stalls, significantly diminishing training efficiency. Besides,\nwhen transferring checkpoints across tasks, checkpoint resharding, defined as\nloading checkpoints into parallel configurations differing from those used for\nsaving, is often required according to the characteristics and resource quota\nof specific tasks. Previous checkpointing systems [16,3,33,6] assume consistent\nparallel configurations, failing to address the complexities of checkpoint\ntransformation during resharding. Furthermore, in the industry platform,\ndevelopers create checkpoints from different training frameworks[23,36,21,11],\neach with its own unique storage and I/O logic. This diversity complicates the\nimplementation of unified checkpoint management and optimization. To address\nthese challenges, we introduce ByteCheckpoint, a PyTorch-native multi-framework\nLLM checkpointing system that supports automatic online checkpoint resharding.\nByteCheckpoint employs a data/metadata disaggregated storage architecture,\ndecoupling checkpoint storage from the adopted parallelism strategies and\ntraining frameworks. We design an efficient asynchronous tensor merging\ntechnique to settle the irregular tensor sharding problem and propose several\nI/O performance optimizations to significantly enhance the efficiency of\ncheckpoint saving and loading. Experimental results demonstrate\nByteCheckpoint's substantial advantages in reducing checkpoint saving (by up to\n529.22X) and loading (by up to 3.51X) costs, compared to baseline methods.", "pdf_path": null, "cn_title": "\u5b57\u8282\u68c0\u67e5\u70b9\uff1aLLM\u5f00\u53d1\u7684\u7edf\u4e00\u68c0\u67e5\u70b9\u7cfb\u7edf", "cn_summary": "\u73b0\u5b9e\u4e16\u754c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u53d1\u5c55\u9700\u8981\u5728\u6301\u4e45\u5b58\u50a8\u4e2d\u4fdd\u5b58\u8bad\u7ec3\u72b6\u6001\u7684\u68c0\u67e5\u70b9\uff0c\u4ee5\u5e94\u5bf9\u6f5c\u5728\u7684\u8f6f\u4ef6\u548c\u786c\u4ef6\u6545\u969c\uff0c\u5e76\u4e14\u4fbf\u4e8e\u5728\u8bad\u7ec3\u7ba1\u9053\u4e2d\u4ee5\u53ca\u8de8\u4e0d\u540c\u4efb\u52a1\u8fdb\u884c\u68c0\u67e5\u70b9\u8f6c\u79fb\u3002\u7531\u4e8eLLMs\u7684\u89c4\u6a21\u5e9e\u5927\uff0c\u4fdd\u5b58\u548c\u52a0\u8f7d\u68c0\u67e5\u70b9\u901a\u5e38\u4f1a\u5bfc\u81f4\u4e0d\u53ef\u63a5\u53d7\u7684\u5206\u949f\u7ea7\u5ef6\u8fdf\uff0c\u6781\u5927\u5730\u964d\u4f4e\u4e86\u8bad\u7ec3\u6548\u7387\u3002\u6b64\u5916\uff0c\u5f53\u5728\u4e0d\u540c\u4efb\u52a1\u4e4b\u95f4\u8f6c\u79fb\u68c0\u67e5\u70b9\u65f6\uff0c\u6839\u636e\u7279\u5b9a\u4efb\u52a1\u7684\u7279\u6027\u548c\u8d44\u6e90\u914d\u989d\uff0c\u901a\u5e38\u9700\u8981\u6267\u884c\u68c0\u67e5\u70b9\u91cd\u65b0\u5206\u7247\uff0c\u5373\u5728\u4e0e\u4fdd\u5b58\u65f6\u4f7f\u7528\u7684\u5e76\u884c\u914d\u7f6e\u4e0d\u540c\u7684\u914d\u7f6e\u4e0b\u52a0\u8f7d\u68c0\u67e5\u70b9\u3002\u5148\u524d\u7684\u68c0\u67e5\u70b9\u7cfb\u7edf[16,3,33,6]\u5047\u5b9a\u5e76\u884c\u914d\u7f6e\u4e00\u81f4\uff0c\u672a\u80fd\u89e3\u51b3\u5728\u91cd\u65b0\u5206\u7247\u8fc7\u7a0b\u4e2d\u68c0\u67e5\u70b9\u8f6c\u6362\u7684\u590d\u6742\u6027\u3002\u6b64\u5916\uff0c\u5728\u5de5\u4e1a\u5e73\u53f0\u4e0a\uff0c\u5f00\u53d1\u8005\u4ece\u4e0d\u540c\u7684\u8bad\u7ec3\u6846\u67b6\u521b\u5efa\u68c0\u67e5\u70b9[23,36,21,11]\uff0c\u6bcf\u4e2a\u6846\u67b6\u90fd\u6709\u5176\u72ec\u7279\u7684\u5b58\u50a8\u548cI/O\u903b\u8f91\u3002\u8fd9\u79cd\u591a\u6837\u6027\u4f7f\u7edf\u4e00\u7684\u68c0\u67e5\u70b9\u7ba1\u7406\u548c\u4f18\u5316\u7684\u5b9e\u73b0\u53d8\u5f97\u590d\u6742\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u6211\u4eec\u5f15\u5165\u4e86ByteCheckpoint\uff0c\u4e00\u4e2a\u652f\u6301\u81ea\u52a8\u5728\u7ebf\u68c0\u67e5\u70b9\u91cd\u65b0\u5206\u7247\u7684PyTorch\u539f\u751f\u591a\u6846\u67b6LLM\u68c0\u67e5\u70b9\u7cfb\u7edf\u3002ByteCheckpoint\u91c7\u7528\u6570\u636e/\u5143\u6570\u636e\u5206\u79bb\u7684\u5b58\u50a8\u67b6\u6784\uff0c\u89e3\u8026\u4e86\u68c0\u67e5\u70b9\u5b58\u50a8\u4e0e\u6240\u91c7\u7528\u7684\u5e76\u884c\u5316\u7b56\u7565\u548c\u8bad\u7ec3\u6846\u67b6\u3002\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5f02\u6b65\u5f20\u91cf\u5408\u5e76\u6280\u672f\u6765\u89e3\u51b3\u4e0d\u89c4\u5219\u5f20\u91cf\u5206\u5757\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217I/O\u6027\u80fd\u4f18\u5316\u63aa\u65bd\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u67e5\u70b9\u4fdd\u5b58\u548c\u52a0\u8f7d\u7684\u6548\u7387\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cByteCheckpoint\u5728\u51cf\u5c11\u68c0\u67e5\u70b9\u4fdd\u5b58\uff08\u9ad8\u8fbe529.22\u500d\uff09\u548c\u52a0\u8f7d\uff08\u9ad8\u8fbe3.51\u500d\uff09\u6210\u672c\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "update_time": "2024-07-29 16:18:20+00:00", "publish_time": "2024-07-29 16:18:20+00:00"}, {"entry_id": "2311.03583v2", "title": "Finding Increasingly Large Extremal Graphs with AlphaZero and Tabu Search", "summary": "This work studies a central extremal graph theory problem inspired by a 1975\nconjecture of Erd\\H{o}s, which aims to find graphs with a given size (number of\nnodes) that maximize the number of edges without having 3- or 4-cycles. We\nformulate this problem as a sequential decision-making problem and compare\nAlphaZero, a neural network-guided tree search, with tabu search, a heuristic\nlocal search method. Using either method, by introducing a curriculum --\njump-starting the search for larger graphs using good graphs found at smaller\nsizes -- we improve the state-of-the-art lower bounds for several sizes. We\nalso propose a flexible graph-generation environment and a\npermutation-invariant network architecture for learning to search in the space\nof graphs.", "pdf_path": null, "cn_title": "\u5229\u7528AlphaZero\u4e0e\u7981\u5fcc\u641c\u7d22\u7b97\u6cd5\u5bfb\u627e\u65e5\u76ca\u5e9e\u5927\u7684\u6781\u503c\u56fe", "cn_summary": "\u672c\u6587\u63a2\u8ba8\u4e86\u4e00\u4e2a\u75311975\u5e74Erd\\H{o}s\u63d0\u51fa\u7684\u4e2d\u5fc3\u6781\u503c\u56fe\u8bba\u95ee\u9898\uff0c\u65e8\u5728\u5bfb\u627e\u5177\u6709\u7ed9\u5b9a\u8282\u70b9\u6570\u91cf\u7684\u56fe\uff0c\u4ee5\u6700\u5927\u5316\u8fb9\u7684\u6570\u91cf\uff0c\u540c\u65f6\u907f\u514d\u5f62\u62103\u62164\u9636\u73af\u3002\u6211\u4eec\u5c06\u8fd9\u4e2a\u95ee\u9898\u8868\u8ff0\u4e3a\u4e00\u4e2a\u987a\u5e8f\u51b3\u7b56\u95ee\u9898\uff0c\u5e76\u5c06AlphaZero\uff08\u795e\u7ecf\u7f51\u7edc\u5f15\u5bfc\u7684\u6811\u641c\u7d22\uff09\u4e0etabu\u641c\u7d22\uff08\u542f\u53d1\u5f0f\u5c40\u90e8\u641c\u7d22\u65b9\u6cd5\uff09\u8fdb\u884c\u6bd4\u8f83\u3002\u901a\u8fc7\u5f15\u5165\u8bfe\u7a0b\u8bbe\u7f6e\u2014\u2014\u5229\u7528\u5728\u8f83\u5c0f\u89c4\u6a21\u4e0b\u627e\u5230\u7684\u597d\u56fe\u6765\u542f\u52a8\u641c\u7d22\u5927\u578b\u56fe\u7684\u8fc7\u7a0b\u2014\u2014\u6211\u4eec\u80fd\u591f\u6539\u8fdb\u51e0\u79cd\u89c4\u6a21\u4e0b\u7684\u6700\u65b0\u4e0b\u754c\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u7075\u6d3b\u7684\u56fe\u751f\u6210\u73af\u5883\u548c\u4e00\u79cd\u5bf9\u79f0\u4e8e\u6392\u5217\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u7528\u4e8e\u5b66\u4e60\u5728\u56fe\u7a7a\u95f4\u4e2d\u8fdb\u884c\u641c\u7d22\u3002", "update_time": "2024-07-29 16:13:22+00:00", "publish_time": "2023-11-06 22:29:55+00:00"}, {"entry_id": "2407.20126v1", "title": "Extreme time extrapolation capabilities and thermodynamic consistency of physics-inspired Neural Networks for the 3D microstructure evolution of materials", "summary": "A Convolutional Recurrent Neural Network (CRNN) is trained to reproduce the\nevolution of the spinodal decomposition process in three dimensions as\ndescribed by the Cahn-Hilliard equation. A specialized, physics-inspired\narchitecture is proven to provide close accordance between the predicted\nevolutions and the ground truth ones obtained via conventional integration\nschemes. The method can closely reproduce the evolution of microstructures not\nrepresented in the training set at a fraction of the computational costs.\nExtremely long-time extrapolation capabilities are achieved, up to reaching the\ntheoretically expected equilibrium state of the system, despite the training\nset containing only relatively-short, initial phases of the evolution.\nQuantitative accordance with the decay rate of the Free energy is also\ndemonstrated up to late coarsening stages, providing an example of a\ndata-driven, physically consistent and high-accuracy Machine Learning method\nfor the long timescale simulation of materials.", "pdf_path": null, "cn_title": "\u7269\u7406\u5b66\u542f\u53d1\u5f0f\u795e\u7ecf\u7f51\u7edc\u5728\u6750\u65993D\u5fae\u7ed3\u6784\u6f14\u53d8\u4e2d\u7684\u6781\u7aef\u65f6\u95f4\u5916\u63a8\u80fd\u529b\u548c\u70ed\u529b\u5b66\u4e00\u81f4\u6027", "cn_summary": "\u4e00\u79cd\u5377\u79ef\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08CRNN\uff09\u88ab\u8bad\u7ec3\u7528\u4e8e\u5728\u4e09\u7ef4\u4e2d\u91cd\u73b0\u7531Cahn-Hilliard\u65b9\u7a0b\u63cf\u8ff0\u7684\u76f8\u5206\u79bb\u8fc7\u7a0b\u7684\u6f14\u5316\u3002\u8bc1\u660e\u4e86\u4e00\u79cd\u4e13\u95e8\u8bbe\u8ba1\u3001\u57fa\u4e8e\u7269\u7406\u7684\u67b6\u6784\u80fd\u591f\u63d0\u4f9b\u9884\u6d4b\u6f14\u5316\u4e0e\u901a\u8fc7\u4f20\u7edf\u79ef\u5206\u65b9\u6848\u83b7\u5f97\u7684\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u7d27\u5bc6\u4e00\u81f4\u6027\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u4ee5\u6781\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u7cbe\u786e\u590d\u5236\u8bad\u7ec3\u96c6\u672a\u5305\u542b\u7684\u5fae\u89c2\u7ed3\u6784\u7684\u6f14\u5316\u3002\u5b9e\u73b0\u4e86\u957f\u65f6\u95f4\u5c3a\u5ea6\u5916\u63a8\u80fd\u529b\uff0c\u76f4\u81f3\u7cfb\u7edf\u7406\u8bba\u4e0a\u9884\u671f\u7684\u5e73\u8861\u72b6\u6001\uff0c\u5c3d\u7ba1\u8bad\u7ec3\u96c6\u4ec5\u5305\u542b\u6f14\u5316\u521d\u671f\u76f8\u5bf9\u8f83\u77ed\u7684\u9636\u6bb5\u3002\u8fd8\u5c55\u793a\u4e86\u5728\u8f83\u665a\u7684\u7c97\u5316\u9636\u6bb5\u4e0e\u81ea\u7531\u80fd\u8870\u51cf\u7387\u7684\u91cf\u5316\u4e00\u81f4\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6570\u636e\u9a71\u52a8\u3001\u7269\u7406\u4e00\u81f4\u4e14\u9ad8\u7cbe\u5ea6\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u5b9e\u4f8b\uff0c\u7528\u4e8e\u6750\u6599\u957f\u65f6\u95f4\u5c3a\u5ea6\u7684\u6a21\u62df\u3002", "update_time": "2024-07-29 15:55:52+00:00", "publish_time": "2024-07-29 15:55:52+00:00"}, {"entry_id": "2407.20122v1", "title": "Tightening the Evaluation of PAC Bounds Using Formal Verification Results", "summary": "Probably Approximately Correct (PAC) bounds are widely used to derive\nprobabilistic guarantees for the generalisation of machine learning models.\nThey highlight the components of the model which contribute to its\ngeneralisation capacity. However, current state-of-the-art results are loose in\napproximating the generalisation capacity of deployed machine learning models.\nConsequently, while PAC bounds are theoretically useful, their applicability\nfor evaluating a model's generalisation property in a given operational design\ndomain is limited. The underlying classical theory is supported by the idea\nthat bounds can be tightened when the number of test points available to the\nuser to evaluate the model increases. Yet, in the case of neural networks, the\nnumber of test points required to obtain bounds of interest is often\nimpractical even for small problems.\n  In this paper, we take the novel approach of using the formal verification of\nneural systems to inform the evaluation of PAC bounds. Rather than using\npointwise information obtained from repeated tests, we use verification results\non regions around test points. We show that conditioning existing bounds on\nverification results leads to a tightening proportional to the underlying\nprobability mass of the verified region.", "pdf_path": null, "cn_title": "\u5229\u7528\u5f62\u5f0f\u9a8c\u8bc1\u7ed3\u679c\u6536\u7d27\u6709\u754c\u9884\u6d4b\u533a\u95f4\u8bc4\u4f30", "cn_summary": "\u53ef\u80fd\u8fd1\u4f3c\u6b63\u786e\uff08PAC\uff09\u8fb9\u754c\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u63a8\u5bfc\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u6982\u7387\u4e0a\u7684\u4fdd\u8bc1\uff0c\u4ee5\u9610\u8ff0\u6a21\u578b\u63d0\u5347\u80fd\u529b\u7684\u6784\u6210\u90e8\u5206\u3002\u7136\u800c\uff0c\u5f53\u524d\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u5728\u8fd1\u4f3c\u5df2\u90e8\u7f72\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u4e0a\u8f83\u4e3a\u5bbd\u677e\u3002\u56e0\u6b64\uff0c\u5c3d\u7ba1PAC\u8fb9\u754c\u5728\u7406\u8bba\u4e0a\u5f88\u6709\u7528\uff0c\u4f46\u5b83\u4eec\u5728\u8bc4\u4f30\u7ed9\u5b9a\u64cd\u4f5c\u8bbe\u8ba1\u9886\u57df\u4e2d\u6a21\u578b\u6cdb\u5316\u6027\u8d28\u7684\u5e94\u7528\u8303\u56f4\u6709\u9650\u3002\u652f\u6301\u8be5\u7ecf\u5178\u7406\u8bba\u7684\u57fa\u7840\u662f\uff0c\u5f53\u7528\u6237\u53ef\u7528\u7684\u6d4b\u8bd5\u70b9\u6570\u91cf\u589e\u52a0\u65f6\uff0c\u53ef\u4ee5\u6536\u7d27\u8fb9\u754c\u3002\u4f46\u5728\u795e\u7ecf\u7f51\u7edc\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3a\u4e86\u83b7\u5f97\u611f\u5174\u8da3\u7684\u8fb9\u754c\uff0c\u751a\u81f3\u5bf9\u4e8e\u5c0f\u578b\u95ee\u9898\u6765\u8bf4\uff0c\u6240\u9700\u7684\u6d4b\u8bd5\u70b9\u6570\u91cf\u5f80\u5f80\u96be\u4ee5\u5b9e\u73b0\u3002\n\n\u672c\u6587\u91c7\u53d6\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u5373\u5c06\u795e\u7ecf\u7cfb\u7edf\u7684\u5f62\u5f0f\u9a8c\u8bc1\u7528\u4e8e\u6307\u5bfcPAC\u8fb9\u754c\u8bc4\u4f30\u3002\u6211\u4eec\u4e0d\u518d\u4f9d\u8d56\u4e8e\u91cd\u590d\u6d4b\u8bd5\u83b7\u5f97\u7684\u5355\u70b9\u4fe1\u606f\uff0c\u800c\u662f\u5229\u7528\u56f4\u7ed5\u6d4b\u8bd5\u70b9\u7684\u9a8c\u8bc1\u7ed3\u679c\u3002\u6211\u4eec\u5c55\u793a\u4e86\u57fa\u4e8e\u9a8c\u8bc1\u7ed3\u679c\u5bf9\u73b0\u6709\u8fb9\u754c\u8fdb\u884c\u6761\u4ef6\u5316\uff0c\u53ef\u4ee5\u5f97\u5230\u4e0e\u9a8c\u8bc1\u533a\u57df\u5e95\u5c42\u6982\u7387\u8d28\u91cf\u6210\u6bd4\u4f8b\u7684\u6536\u7d27\u3002", "update_time": "2024-07-29 15:53:14+00:00", "publish_time": "2024-07-29 15:53:14+00:00"}, {"entry_id": "2407.20119v1", "title": "Adaptive Self-supervised Robust Clustering for Unstructured Data with Unknown Cluster Number", "summary": "We introduce a novel self-supervised deep clustering approach tailored for\nunstructured data without requiring prior knowledge of the number of clusters,\ntermed Adaptive Self-supervised Robust Clustering (ASRC). In particular, ASRC\nadaptively learns the graph structure and edge weights to capture both local\nand global structural information. The obtained graph enables us to learn\nclustering-friendly feature representations by an enhanced graph auto-encoder\nwith contrastive learning technique. It further leverages the clustering\nresults adaptively obtained by robust continuous clustering (RCC) to generate\nprototypes for negative sampling, which can further contribute to promoting\nconsistency among positive pairs and enlarging the gap between positive and\nnegative samples. ASRC obtains the final clustering results by applying RCC to\nthe learned feature representations with their consistent graph structure and\nedge weights. Extensive experiments conducted on seven benchmark datasets\ndemonstrate the efficacy of ASRC, demonstrating its superior performance over\nother popular clustering models. Notably, ASRC even outperforms methods that\nrely on prior knowledge of the number of clusters, highlighting its\neffectiveness in addressing the challenges of clustering unstructured data.", "pdf_path": null, "cn_title": "\u9002\u5e94\u6027\u81ea\u6211\u76d1\u7763\u9c81\u68d2\u805a\u7c7b\u65b9\u6cd5\u5728\u672a\u77e5\u7c07\u6570\u7684\u65e0\u7ed3\u6784\u6570\u636e\u4e0a\u7684\u5e94\u7528", "cn_summary": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u81ea\u76d1\u7763\u6df1\u5ea6\u805a\u7c7b\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u65e0\u7ed3\u6784\u6570\u636e\uff0c\u65e0\u9700\u9884\u5148\u77e5\u9053\u805a\u7c7b\u7684\u6570\u91cf\uff0c\u79f0\u4e3a\u81ea\u9002\u5e94\u81ea\u76d1\u7763\u9c81\u68d2\u805a\u7c7b\uff08ASRC\uff09\u3002\u7279\u522b\u5730\uff0cASRC\u80fd\u591f\u81ea\u9002\u5e94\u5730\u5b66\u4e60\u56fe\u7ed3\u6784\u548c\u8fb9\u6743\u91cd\uff0c\u4ee5\u6355\u83b7\u5c40\u90e8\u548c\u5168\u5c40\u7ed3\u6784\u4fe1\u606f\u3002\u83b7\u5f97\u7684\u56fe\u4f7f\u6211\u4eec\u80fd\u591f\u901a\u8fc7\u589e\u5f3a\u7684\u56fe\u81ea\u52a8\u7f16\u7801\u5668\u548c\u5bf9\u6bd4\u5b66\u4e60\u6280\u672f\u6765\u5b66\u4e60\u6709\u5229\u4e8e\u805a\u7c7b\u7684\u7279\u5f81\u8868\u793a\u3002\u8fdb\u4e00\u6b65\u5730\uff0c\u5b83\u5229\u7528\u7531\u9c81\u68d2\u8fde\u7eed\u805a\u7c7b\uff08RCC\uff09\u81ea\u9002\u5e94\u83b7\u5f97\u7684\u805a\u7c7b\u7ed3\u679c\u751f\u6210\u8d1f\u91c7\u6837\u539f\u578b\uff0c\u8fd9\u6709\u52a9\u4e8e\u4fc3\u8fdb\u6b63\u5bf9\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u5e76\u6269\u5927\u6b63\u6837\u672c\u4e0e\u8d1f\u6837\u672c\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u6700\u540e\uff0c\u901a\u8fc7\u5c06RCC\u5e94\u7528\u4e8e\u5b66\u4e60\u5230\u7684\u7279\u5f81\u8868\u793a\u53ca\u5176\u4e00\u81f4\u7684\u56fe\u7ed3\u6784\u548c\u8fb9\u6743\u91cd\uff0cASRC\u83b7\u5f97\u6700\u7ec8\u7684\u805a\u7c7b\u7ed3\u679c\u3002\u5728\u4e03\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cASRC\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u4e0e\u5176\u4ed6\u6d41\u884c\u7684\u805a\u7c7b\u6a21\u578b\u76f8\u6bd4\u65f6\u7684\u4f18\u8d8a\u6027\u80fd\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cASRC\u751a\u81f3\u8d85\u8fc7\u4e86\u4f9d\u8d56\u4e8e\u805a\u7c7b\u6570\u91cf\u5148\u9a8c\u77e5\u8bc6\u7684\u65b9\u6cd5\uff0c\u5728\u5904\u7406\u65e0\u7ed3\u6784\u6570\u636e\u805a\u7c7b\u6311\u6218\u65b9\u9762\u663e\u793a\u51fa\u4e86\u5176\u6709\u6548\u6027\u3002", "update_time": "2024-07-29 15:51:09+00:00", "publish_time": "2024-07-29 15:51:09+00:00"}, {"entry_id": "2407.08623v2", "title": "Surpassing Cosine Similarity for Multidimensional Comparisons: Dimension Insensitive Euclidean Metric (DIEM)", "summary": "The advancement in computational power and hardware efficiency enabled the\ntackling of increasingly complex and high-dimensional problems. While\nartificial intelligence (AI) achieved remarkable results, the interpretability\nof high-dimensional solutions remains challenging. A critical issue is the\ncomparison of multidimensional quantities, which is essential in techniques\nlike Principal Component Analysis (PCA), or k-means clustering. Common metrics\nsuch as cosine similarity, Euclidean distance, and Manhattan distance are often\nused for such comparisons - for example in muscular synergies of the human\nmotor control system. However, their applicability and interpretability\ndiminish as dimensionality increases. This paper provides a comprehensive\nanalysis of the effects of dimensionality on these metrics. Our results reveal\nsignificant limitations of cosine similarity, particularly its dependency on\nthe dimensionality of the vectors, leading to biased and less interpretable\noutcomes. To address this, we introduce the Dimension Insensitive Euclidean\nMetric (DIEM) which demonstrates superior robustness and generalizability\nacross dimensions. DIEM maintains consistent variability and eliminates the\nbiases observed in traditional metrics, making it a reliable tool for\nhigh-dimensional comparisons. This novel metric has the potential to replace\ncosine similarity, providing a more accurate and insightful method to analyze\nmultidimensional data in fields ranging from neuromotor control to machine and\ndeep learning.", "pdf_path": null, "cn_title": "\u8d85\u8d8a\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u591a\u7ef4\u6bd4\u8f83\uff1a\u7ef4\u5ea6\u4e0d\u654f\u611f\u6b27\u6c0f\u5ea6\u91cf\uff08DIEM\uff09", "cn_summary": "\u8ba1\u7b97\u80fd\u529b\u4e0e\u786c\u4ef6\u6548\u7387\u7684\u63d0\u5347\u4f7f\u5f97\u6211\u4eec\u80fd\u591f\u89e3\u51b3\u65e5\u76ca\u590d\u6742\u548c\u9ad8\u7ef4\u7684\u95ee\u9898\u3002\u867d\u7136\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\uff0c\u4f46\u9ad8\u7ef4\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u89e3\u91ca\u6027\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002\u5173\u952e\u95ee\u9898\u5728\u4e8e\u591a\u7ef4\u91cf\u7684\u6bd4\u8f83\uff0c\u8fd9\u5bf9\u4e8e\u5982\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09\u3001\u6216k-\u5747\u503c\u805a\u7c7b\u7b49\u6280\u672f\u81f3\u5173\u91cd\u8981\u3002\u5e38\u7528\u7684\u5ea6\u91cf\u6807\u51c6\u5982\u4f59\u5f26\u76f8\u4f3c\u5ea6\u3001\u6b27\u6c0f\u8ddd\u79bb\u548c\u66fc\u54c8\u987f\u8ddd\u79bb\u901a\u5e38\u7528\u4e8e\u6b64\u7c7b\u6bd4\u8f83\uff0c\u4f8b\u5982\u5728\u4eba\u7c7b\u8fd0\u52a8\u63a7\u5236\u7cfb\u7edf\u4e2d\u7684\u808c\u8089\u534f\u540c\u4f5c\u7528\u3002\u7136\u800c\uff0c\u968f\u7740\u7ef4\u5ea6\u7684\u589e\u52a0\uff0c\u8fd9\u4e9b\u5ea6\u91cf\u6807\u51c6\u7684\u5e94\u7528\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4f1a\u51cf\u5f31\u3002\u672c\u6587\u5168\u9762\u5206\u6790\u4e86\u7ef4\u5ea6\u5bf9\u8fd9\u4e9b\u5ea6\u91cf\u6807\u51c6\u7684\u5f71\u54cd\u3002\u6211\u4eec\u7684\u7ed3\u679c\u63ed\u793a\u4e86\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u91cd\u5927\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5b83\u5bf9\u5411\u91cf\u7ef4\u5ea6\u7684\u4f9d\u8d56\u5bfc\u81f4\u4e86\u6709\u504f\u89c1\u4e14\u53ef\u89e3\u91ca\u6027\u8f83\u5dee\u7684\u7ed3\u679c\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u7ef4\u5ea6\u4e0d\u654f\u611f\u6b27\u6c0f\u5ea6\u91cf\uff08DIEM\uff09\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u4e0d\u540c\u7ef4\u5ea6\u4e0b\u5177\u6709\u4f18\u8d8a\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002DIEM\u4fdd\u6301\u4e86\u4e00\u81f4\u7684\u53d8\u5316\u6027\uff0c\u5e76\u6d88\u9664\u4e86\u4f20\u7edf\u5ea6\u91cf\u4e2d\u89c2\u5bdf\u5230\u7684\u504f\u89c1\uff0c\u4f7f\u5176\u6210\u4e3a\u9ad8\u7ef4\u6bd4\u8f83\u7684\u53ef\u9760\u5de5\u5177\u3002\u8fd9\u4e00\u65b0\u9896\u7684\u5ea6\u91cf\u65b9\u6cd5\u6709\u53ef\u80fd\u66ff\u4ee3\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u63d0\u4f9b\u4e00\u79cd\u66f4\u51c6\u786e\u3001\u66f4\u6df1\u5165\u7684\u65b9\u6cd5\u6765\u5206\u6790\u4ece\u795e\u7ecf\u8fd0\u52a8\u63a7\u5236\u5230\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u7b49\u9886\u57df\u7684\u591a\u7ef4\u6570\u636e\u3002", "update_time": "2024-07-29 15:49:29+00:00", "publish_time": "2024-07-11 16:00:22+00:00"}, {"entry_id": "2407.20109v1", "title": "Diffusion-DICE: In-Sample Diffusion Guidance for Offline Reinforcement Learning", "summary": "One important property of DIstribution Correction Estimation (DICE) methods\nis that the solution is the optimal stationary distribution ratio between the\noptimized and data collection policy. In this work, we show that DICE-based\nmethods can be viewed as a transformation from the behavior distribution to the\noptimal policy distribution. Based on this, we propose a novel approach,\nDiffusion-DICE, that directly performs this transformation using diffusion\nmodels. We find that the optimal policy's score function can be decomposed into\ntwo terms: the behavior policy's score function and the gradient of a guidance\nterm which depends on the optimal distribution ratio. The first term can be\nobtained from a diffusion model trained on the dataset and we propose an\nin-sample learning objective to learn the second term. Due to the\nmulti-modality contained in the optimal policy distribution, the transformation\nin Diffusion-DICE may guide towards those local-optimal modes. We thus generate\na few candidate actions and carefully select from them to approach\nglobal-optimum. Different from all other diffusion-based offline RL methods,\nthe guide-then-select paradigm in Diffusion-DICE only uses in-sample actions\nfor training and brings minimal error exploitation in the value function. We\nuse a didatic toycase example to show how previous diffusion-based methods fail\nto generate optimal actions due to leveraging these errors and how\nDiffusion-DICE successfully avoids that. We then conduct extensive experiments\non benchmark datasets to show the strong performance of Diffusion-DICE.", "pdf_path": null, "cn_title": "\u6269\u6563-DICE\uff1a\u57fa\u4e8e\u6837\u672c\u5185\u6269\u6563\u6307\u5bfc\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60", "cn_summary": "\u5206\u5e03\u6821\u6b63\u4f30\u8ba1(Distribution Correction Estimation, DICE)\u65b9\u6cd5\u7684\u4e00\u4e2a\u91cd\u8981\u7279\u6027\u662f\uff0c\u5176\u89e3\u662f\u4f18\u5316\u7b56\u7565\u4e0e\u6570\u636e\u6536\u96c6\u7b56\u7565\u4e4b\u95f4\u7684\u6700\u4f18\u7a33\u6001\u5206\u5e03\u6bd4\u7387\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u57fa\u4e8eDICE\u7684\u65b9\u6cd5\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4ece\u884c\u4e3a\u5206\u5e03\u5230\u6700\u4f18\u7b56\u7565\u5206\u5e03\u7684\u8f6c\u6362\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\u2014\u2014\u6269\u6563-DICE\uff08Diffusion-DICE\uff09\uff0c\u8be5\u65b9\u6cd5\u76f4\u63a5\u4f7f\u7528\u6269\u6563\u6a21\u578b\u6267\u884c\u8fd9\u4e00\u8f6c\u6362\u3002\u6211\u4eec\u53d1\u73b0\uff0c\u6700\u4f18\u7b56\u7565\u7684\u8bc4\u5206\u51fd\u6570\u53ef\u4ee5\u5206\u89e3\u4e3a\u4e24\u4e2a\u90e8\u5206\uff1a\u884c\u4e3a\u7b56\u7565\u7684\u8bc4\u5206\u51fd\u6570\u548c\u4f9d\u8d56\u4e8e\u6700\u4f18\u5206\u5e03\u6bd4\u7387\u7684\u6307\u5bfc\u9879\u7684\u68af\u5ea6\u3002\u7b2c\u4e00\u90e8\u5206\u53ef\u4ee5\u4ece\u7528\u4e8e\u8bad\u7ec3\u7684\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6269\u6563\u6a21\u578b\u4e2d\u83b7\u5f97\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u6837\u672c\u5185\u5b66\u4e60\u76ee\u6807\u6765\u5b66\u4e60\u7b2c\u4e8c\u90e8\u5206\u3002\u7531\u4e8e\u6700\u4f18\u7b56\u7565\u5206\u5e03\u5305\u542b\u591a\u6a21\u6001\u6027\uff0cDiffusion-DICE\u4e2d\u7684\u8f6c\u6362\u53ef\u80fd\u4f1a\u5f15\u5bfc\u81f3\u5c40\u90e8\u6700\u4f18\u6a21\u5f0f\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u751f\u6210\u4e86\u51e0\u79cd\u5019\u9009\u52a8\u4f5c\uff0c\u5e76\u4ece\u4e2d\u4ed4\u7ec6\u9009\u62e9\u4ee5\u63a5\u8fd1\u5168\u5c40\u6700\u4f18\u3002\u4e0e\u6240\u6709\u5176\u4ed6\u57fa\u4e8e\u6269\u6563\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e0d\u540c\uff0cDiffusion-DICE\u4e2d\u7684\u6307\u5bfc-\u9009\u62e9\u8303\u5f0f\u4ec5\u4f7f\u7528\u6837\u672c\u5185\u7684\u52a8\u4f5c\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ece\u800c\u5728\u4ef7\u503c\u51fd\u6570\u4e2d\u5e26\u6765\u6700\u5c0f\u7684\u9519\u8bef\u5229\u7528\u3002\u6211\u4eec\u4f7f\u7528\u4e86\u4e00\u4e2a\u793a\u8303\u6027\u73a9\u5177\u6848\u4f8b\u6765\u5c55\u793a\u4e4b\u524d\u7684\u57fa\u4e8e\u6269\u6563\u7684\u65b9\u6cd5\u4e3a\u4f55\u7531\u4e8e\u5229\u7528\u8fd9\u4e9b\u9519\u8bef\u800c\u65e0\u6cd5\u751f\u6210\u6700\u4f18\u52a8\u4f5c\uff0c\u4ee5\u53caDiffusion-DICE\u5982\u4f55\u6210\u529f\u907f\u514d\u4e86\u8fd9\u79cd\u60c5\u51b5\u3002\u7136\u540e\uff0c\u6211\u4eec\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u4ee5\u5c55\u793aDiffusion-DICE\u7684\u5f3a\u5927\u6027\u80fd\u3002", "update_time": "2024-07-29 15:36:42+00:00", "publish_time": "2024-07-29 15:36:42+00:00"}, {"entry_id": "2407.20105v1", "title": "Strong Copyright Protection for Language Models via Adaptive Model Fusion", "summary": "The risk of language models unintentionally reproducing copyrighted material\nfrom their training data has led to the development of various protective\nmeasures. In this paper, we propose model fusion as an effective solution to\nsafeguard against copyright infringement. In particular, we introduce\nCopyright-Protecting Fusion (CP-Fuse), an algorithm that adaptively combines\nlanguage models to minimize the reproduction of protected materials. CP-Fuse is\ninspired by the recently proposed Near-Access Free (NAF) framework and\nadditionally incorporates a desirable balancing property that we demonstrate\nprevents the reproduction of memorized training data. Our results show that\nCP-Fuse significantly reduces the memorization of copyrighted content while\nmaintaining high-quality text and code generation. Furthermore, we demonstrate\nhow CP-Fuse can be integrated with other techniques for enhanced protection.", "pdf_path": null, "cn_title": "\u901a\u8fc7\u81ea\u9002\u5e94\u6a21\u578b\u878d\u5408\u5f3a\u5316\u8bed\u8a00\u6a21\u578b\u7684\u7248\u6743\u4fdd\u62a4", "cn_summary": "\u8bed\u8a00\u6a21\u578b\u5728\u65e0\u610f\u4e2d\u590d\u5236\u5176\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u53d7\u7248\u6743\u4fdd\u62a4\u6750\u6599\u7684\u98ce\u9669\uff0c\u5bfc\u81f4\u4e86\u5404\u79cd\u4fdd\u62a4\u63aa\u65bd\u7684\u5f00\u53d1\u3002\u672c\u6587\u63d0\u51fa\u6a21\u578b\u878d\u5408\u4f5c\u4e3a\u9632\u6b62\u4fb5\u6743\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002\u5177\u4f53\u5730\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u7248\u6743\u4fdd\u62a4\u878d\u5408\uff08CP-Fuse\uff09\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u9002\u5e94\u6027\u5730\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u4ee5\u6700\u5c0f\u5316\u5bf9\u53d7\u4fdd\u62a4\u6750\u6599\u7684\u590d\u5236\u3002CP-Fuse\u7075\u611f\u6765\u6e90\u4e8e\u6700\u8fd1\u63d0\u51fa\u7684\u63a5\u8fd1\u65e0\u8bbf\u95ee\u81ea\u7531\uff08NAF\uff09\u6846\u67b6\uff0c\u5e76\u4e14\u8fd8\u878d\u5165\u4e86\u4e00\u4e2a\u6211\u4eec\u8bc1\u660e\u53ef\u4ee5\u9632\u6b62\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u590d\u5236\u7684\u53ef\u559c\u5e73\u8861\u5c5e\u6027\u3002\u6211\u4eec\u7684\u7ed3\u679c\u663e\u793a\uff0cCP-Fuse\u663e\u8457\u51cf\u5c11\u4e86\u5bf9\u53d7\u7248\u6743\u4fdd\u62a4\u5185\u5bb9\u7684\u8bb0\u5fc6\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8d28\u91cf\u7684\u6587\u5b57\u548c\u4ee3\u7801\u751f\u6210\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5982\u4f55\u5c06CP-Fuse\u4e0e\u5176\u4ed6\u589e\u5f3a\u4fdd\u62a4\u6280\u672f\u96c6\u6210\u7684\u65b9\u6cd5\u3002", "update_time": "2024-07-29 15:32:30+00:00", "publish_time": "2024-07-29 15:32:30+00:00"}, {"entry_id": "2407.20100v1", "title": "F-KANs: Federated Kolmogorov-Arnold Networks", "summary": "In this paper, we present an innovative federated learning (FL) approach that\nutilizes Kolmogorov-Arnold Networks (KANs) for classification tasks. By\nutilizing the adaptive activation capabilities of KANs in a federated\nframework, we aim to improve classification capabilities while preserving\nprivacy. The study evaluates the performance of federated KANs (F- KANs)\ncompared to traditional Multi-Layer Perceptrons (MLPs) on classification task.\nThe results show that the F-KANs model significantly outperforms the federated\nMLP model in terms of accuracy, precision, recall, F1 score and stability, and\nachieves better performance, paving the way for more efficient and\nprivacy-preserving predictive analytics.", "pdf_path": null, "cn_title": "F-KANs: \u8054\u90a6\u67ef\u5c14\u83ab\u54e5\u6d1b\u592b-\u963f\u8bfa\u5fb7\u7f51\u7edc", "cn_summary": "\u5728\u8fd9\u7bc7\u8bba\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u65b9\u6cd5\uff0c\u5229\u7528\u67ef\u5c14\u83ab\u54e5\u6d1b\u592b-\u963f\u8bfa\u5fb7\u7f51\u7edc\uff08KANs\uff09\u8fdb\u884c\u5206\u7c7b\u4efb\u52a1\u3002\u901a\u8fc7\u5728\u8054\u90a6\u6846\u67b6\u4e0b\u5229\u7528KANs\u7684\u81ea\u9002\u5e94\u6fc0\u6d3b\u80fd\u529b\uff0c\u65e8\u5728\u63d0\u9ad8\u5206\u7c7b\u80fd\u529b\u7684\u540c\u65f6\u4fdd\u6301\u9690\u79c1\u3002\u7814\u7a76\u8bc4\u4f30\u4e86\u8054\u90a6KANs\uff08F-KANs\uff09\u4e0e\u4f20\u7edf\u591a\u5c42\u611f\u77e5\u5668\uff08MLPs\uff09\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002\u7ed3\u679c\u663e\u793a\uff0cF-KANs\u6a21\u578b\u5728\u51c6\u786e\u7387\u3001\u7cbe\u786e\u5ea6\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8e\u8054\u90a6MLP\u6a21\u578b\uff0c\u5e76\u4e14\u8fbe\u5230\u4e86\u66f4\u597d\u7684\u6027\u80fd\uff0c\u4e3a\u66f4\u9ad8\u6548\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u9884\u6d4b\u5206\u6790\u94fa\u5e73\u4e86\u9053\u8def\u3002", "update_time": "2024-07-29 15:28:26+00:00", "publish_time": "2024-07-29 15:28:26+00:00"}, {"entry_id": "2407.14435v2", "title": "Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse Autoencoders", "summary": "Sparse autoencoders (SAEs) are a promising unsupervised approach for\nidentifying causally relevant and interpretable linear features in a language\nmodel's (LM) activations. To be useful for downstream tasks, SAEs need to\ndecompose LM activations faithfully; yet to be interpretable the decomposition\nmust be sparse -- two objectives that are in tension. In this paper, we\nintroduce JumpReLU SAEs, which achieve state-of-the-art reconstruction fidelity\nat a given sparsity level on Gemma 2 9B activations, compared to other recent\nadvances such as Gated and TopK SAEs. We also show that this improvement does\nnot come at the cost of interpretability through manual and automated\ninterpretability studies. JumpReLU SAEs are a simple modification of vanilla\n(ReLU) SAEs -- where we replace the ReLU with a discontinuous JumpReLU\nactivation function -- and are similarly efficient to train and run. By\nutilising straight-through-estimators (STEs) in a principled manner, we show\nhow it is possible to train JumpReLU SAEs effectively despite the discontinuous\nJumpReLU function introduced in the SAE's forward pass. Similarly, we use STEs\nto directly train L0 to be sparse, instead of training on proxies such as L1,\navoiding problems like shrinkage.", "pdf_path": null, "cn_title": "\u63d0\u524d\u8df3\u8dc3\uff1a\u901a\u8fc7\u8df3\u8dc3ReLU\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u63d0\u5347\u91cd\u6784\u7cbe\u5ea6", "cn_summary": "\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\uff08Sparse Autoencoders, SAEs\uff09\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u65e8\u5728\u8bc6\u522b\u8bed\u8a00\u6a21\u578b\uff08Language Model, LM\uff09\u6fc0\u6d3b\u4e2d\u7684\u56e0\u679c\u76f8\u5173\u4e14\u53ef\u89e3\u91ca\u7684\u7ebf\u6027\u7279\u5f81\u3002\u4e3a\u4e86\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u53d1\u6325\u4f5c\u7528\uff0cSAEs\u9700\u8981\u4ee5\u5fe0\u5b9e\u7684\u65b9\u5f0f\u5206\u89e3LM\u6fc0\u6d3b\uff1b\u7136\u800c\uff0c\u5206\u89e3\u5fc5\u987b\u662f\u7a00\u758f\u7684\u2014\u2014\u8fd9\u662f\u4e24\u4e2a\u5b58\u5728\u7d27\u5f20\u5173\u7cfb\u7684\u76ee\u6807\u3002\u5728\u8fd9\u7bc7\u8bba\u6587\u4e2d\uff0c\u6211\u4eec\u5f15\u5165\u4e86JumpReLU SAEs\uff0c\u5b83\u5728\u7ed9\u5b9a\u7a00\u758f\u7ea7\u522b\u4e0a\uff0c\u5728Gemma 2 9B\u6fc0\u6d3b\u4e0a\u7684\u91cd\u6784\u7cbe\u786e\u5ea6\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\uff0c\u4e0e\u8fd1\u671f\u7684\u5176\u4ed6\u8fdb\u5c55\u5982\u95e8\u63a7\u548cTopK SAEs\u76f8\u6bd4\u3002\u6211\u4eec\u8fd8\u5c55\u793a\u4e86\u8fd9\u79cd\u6539\u8fdb\u4e0d\u4f1a\u4ee5\u727a\u7272\u53ef\u89e3\u91ca\u6027\u4e3a\u4ee3\u4ef7\uff0c\u901a\u8fc7\u624b\u52a8\u548c\u81ea\u52a8\u5316\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u3002JumpReLU SAEs\u662f\u5bf9\u5e38\u89c4\uff08ReLU\uff09SAEs\u7684\u7b80\u5355\u4fee\u6539\u2014\u2014\u6211\u4eec\u5c06ReLU\u66ff\u6362\u4e3a\u4e0d\u8fde\u7eed\u7684JumpReLU\u6fc0\u6d3b\u51fd\u6570\u2014\u2014\u5e76\u4e14\u5177\u6709\u7c7b\u4f3c\u7684\u8bad\u7ec3\u548c\u8fd0\u884c\u6548\u7387\u3002\u901a\u8fc7\u5728\u539f\u7406\u4e0a\u5408\u7406\u5730\u4f7f\u7528\u76f4\u901a\u4f30\u8ba1\u5668\uff08Straight-through-estimator, STEs\uff09\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5373\u4f7f\u5728SAE\u7684\u524d\u5411\u4f20\u64ad\u4e2d\u5f15\u5165\u4e86\u4e0d\u8fde\u7eed\u7684JumpReLU\u51fd\u6570\uff0c\u4e5f\u6709\u53ef\u80fd\u6709\u6548\u5730\u8bad\u7ec3JumpReLU SAEs\u3002\u540c\u6837\uff0c\u6211\u4eec\u76f4\u63a5\u4f7f\u7528STEs\u6765\u8bad\u7ec3L0\u4f7f\u5176\u7a00\u758f\uff0c\u800c\u4e0d\u662f\u5728\u4ee3\u7406\u5982L1\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ece\u800c\u907f\u514d\u4e86\u50cf\u538b\u7f29\u8fd9\u6837\u7684\u95ee\u9898\u3002", "update_time": "2024-07-29 15:27:03+00:00", "publish_time": "2024-07-19 16:07:19+00:00"}, {"entry_id": "2406.01805v2", "title": "TabMDA: Tabular Manifold Data Augmentation for Any Classifier using Transformers with In-context Subsetting", "summary": "Tabular data is prevalent in many critical domains, yet it is often\nchallenging to acquire in large quantities. This scarcity usually results in\npoor performance of machine learning models on such data. Data augmentation, a\ncommon strategy for performance improvement in vision and language tasks,\ntypically underperforms for tabular data due to the lack of explicit symmetries\nin the input space. To overcome this challenge, we introduce TabMDA, a novel\nmethod for manifold data augmentation on tabular data. This method utilises a\npre-trained in-context model, such as TabPFN, to map the data into an embedding\nspace. TabMDA performs label-invariant transformations by encoding the data\nmultiple times with varied contexts. This process explores the learned\nembedding space of the underlying in-context models, thereby enlarging the\ntraining dataset. TabMDA is a training-free method, making it applicable to any\nclassifier. We evaluate TabMDA on five standard classifiers and observe\nsignificant performance improvements across various tabular datasets. Our\nresults demonstrate that TabMDA provides an effective way to leverage\ninformation from pre-trained in-context models to enhance the performance of\ndownstream classifiers. Code is available at\nhttps://github.com/AdrianBZG/TabMDA.", "pdf_path": null, "cn_title": "TabMDA\uff1a\u8868\u683c\u6570\u636e\u6d41\u5f62\u589e\u5f3a\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u5206\u7c7b\u5668\uff0c\u4f7f\u7528\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5b50\u96c6\u7684\u8f6c\u6362\u5668", "cn_summary": "\u8868\u683c\u6570\u636e\u5728\u8bb8\u591a\u5173\u952e\u9886\u57df\u666e\u904d\u5b58\u5728\uff0c\u7136\u800c\uff0c\u83b7\u53d6\u5927\u91cf\u6b64\u7c7b\u6570\u636e\u5f80\u5f80\u5177\u6709\u6311\u6218\u6027\u3002\u8fd9\u79cd\u7a00\u7f3a\u6027\u901a\u5e38\u5bfc\u81f4\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5904\u7406\u6b64\u7c7b\u6570\u636e\u65f6\u6027\u80fd\u4e0d\u4f73\u3002\u5bf9\u4e8e\u89c6\u89c9\u548c\u8bed\u8a00\u4efb\u52a1\u4e2d\u5e38\u7528\u7684\u6027\u80fd\u63d0\u5347\u7b56\u7565\u2014\u2014\u6570\u636e\u589e\u5f3a\uff0c\u5bf9\u4e8e\u8868\u683c\u6570\u636e\u7684\u8868\u73b0\u901a\u5e38\u4e0d\u4f73\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a\u8f93\u5165\u7a7a\u95f4\u7f3a\u4e4f\u660e\u786e\u7684\u5bf9\u79f0\u6027\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u6311\u6218\uff0c\u6211\u4eec\u5f15\u5165\u4e86TabMDA\uff0c\u4e00\u79cd\u9488\u5bf9\u8868\u683c\u6570\u636e\u7684\u6d41\u5f62\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u9884\u8bad\u7ec3\u7684\u4e0a\u4e0b\u6587\u6a21\u578b\uff08\u5982TabPFN\uff09\u5c06\u6570\u636e\u6620\u5c04\u5230\u5d4c\u5165\u7a7a\u95f4\u3002\u901a\u8fc7\u591a\u6b21\u4ee5\u4e0d\u540c\u7684\u4e0a\u4e0b\u6587\u7f16\u7801\u6570\u636e\uff0cTabMDA\u6267\u884c\u4e0d\u53d8\u6027\u7684\u6807\u7b7e\u8f6c\u6362\u3002\u8fd9\u4e2a\u8fc7\u7a0b\u63a2\u7d22\u4e86\u5e95\u5c42\u4e0a\u4e0b\u6587\u6a21\u578b\u5b66\u4e60\u7684\u5d4c\u5165\u7a7a\u95f4\uff0c\u4ece\u800c\u6269\u5927\u4e86\u8bad\u7ec3\u6570\u636e\u96c6\u3002TabMDA\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u56e0\u6b64\u9002\u7528\u4e8e\u4efb\u4f55\u5206\u7c7b\u5668\u3002\u6211\u4eec\u5728\u4e94\u4e2a\u6807\u51c6\u5206\u7c7b\u5668\u4e0a\u8bc4\u4f30\u4e86TabMDA\uff0c\u5e76\u89c2\u5bdf\u5230\u4e86\u5404\u79cd\u8868\u683c\u6570\u636e\u96c6\u4e0a\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002\u6211\u4eec\u7684\u7ed3\u679c\u663e\u793a\uff0cTabMDA\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u7684\u4e0a\u4e0b\u6587\u6a21\u578b\u7684\u4fe1\u606f\u6765\u589e\u5f3a\u4e0b\u6e38\u5206\u7c7b\u5668\u7684\u6027\u80fd\u3002\u76f8\u5173\u4ee3\u7801\u53ef\u8bbf\u95ee https://github.com/AdrianBZG/TabMDA\u3002", "update_time": "2024-07-29 15:08:17+00:00", "publish_time": "2024-06-03 21:51:13+00:00"}, {"entry_id": "2407.20080v1", "title": "UniTTA: Unified Benchmark and Versatile Framework Towards Realistic Test-Time Adaptation", "summary": "Test-Time Adaptation (TTA) aims to adapt pre-trained models to the target\ndomain during testing. In reality, this adaptability can be influenced by\nmultiple factors. Researchers have identified various challenging scenarios and\ndeveloped diverse methods to address these challenges, such as dealing with\ncontinual domain shifts, mixed domains, and temporally correlated or imbalanced\nclass distributions. Despite these efforts, a unified and comprehensive\nbenchmark has yet to be established. To this end, we propose a Unified\nTest-Time Adaptation (UniTTA) benchmark, which is comprehensive and widely\napplicable. Each scenario within the benchmark is fully described by a Markov\nstate transition matrix for sampling from the original dataset. The UniTTA\nbenchmark considers both domain and class as two independent dimensions of data\nand addresses various combinations of imbalance/balance and\ni.i.d./non-i.i.d./continual conditions, covering a total of \\( (2 \\times 3)^2 =\n36 \\) scenarios. It establishes a comprehensive evaluation benchmark for\nrealistic TTA and provides a guideline for practitioners to select the most\nsuitable TTA method. Alongside this benchmark, we propose a versatile UniTTA\nframework, which includes a Balanced Domain Normalization (BDN) layer and a\nCOrrelated Feature Adaptation (COFA) method--designed to mitigate distribution\ngaps in domain and class, respectively. Extensive experiments demonstrate that\nour UniTTA framework excels within the UniTTA benchmark and achieves\nstate-of-the-art performance on average. Our code is available at\n\\url{https://github.com/LeapLabTHU/UniTTA}.", "pdf_path": null, "cn_title": "UniTTA: \u7edf\u4e00\u57fa\u51c6\u4e0e\u591a\u529f\u80fd\u6846\u67b6\uff0c\u65e8\u5728\u5b9e\u73b0\u8d34\u8fd1\u73b0\u5b9e\u7684\u6d4b\u8bd5\u65f6\u9002\u5e94", "cn_summary": "\u6d4b\u8bd5\u65f6\u8c03\u6574\uff08TTA\uff09\u65e8\u5728\u901a\u8fc7\u6d4b\u8bd5\u9636\u6bb5\u5bf9\u9884\u5148\u8bad\u7ec3\u7684\u6a21\u578b\u8fdb\u884c\u9002\u5e94\uff0c\u4ee5\u4f7f\u5176\u66f4\u597d\u5730\u9488\u5bf9\u76ee\u6807\u9886\u57df\u8fdb\u884c\u5de5\u4f5c\u3002\u5b9e\u9645\u4e0a\uff0c\u8fd9\u79cd\u53ef\u9002\u5e94\u6027\u53d7\u5230\u591a\u79cd\u56e0\u7d20\u7684\u5f71\u54cd\u3002\u7814\u7a76\u8005\u5df2\u8bc6\u522b\u51fa\u591a\u79cd\u5177\u6709\u6311\u6218\u6027\u7684\u573a\u666f\uff0c\u5e76\u5f00\u53d1\u4e86\u591a\u6837\u5316\u7684\u7b56\u7565\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u5982\u5e94\u5bf9\u8fde\u7eed\u57df\u6f02\u79fb\u3001\u6df7\u5408\u57df\u4ee5\u53ca\u65f6\u95f4\u76f8\u5173\u6216\u4e0d\u5e73\u8861\u7c7b\u5206\u5e03\u7b49\u95ee\u9898\u3002\u5c3d\u7ba1\u5df2\u7ecf\u505a\u51fa\u4e86\u52aa\u529b\uff0c\u4f46\u5c1a\u672a\u5efa\u7acb\u7edf\u4e00\u4e14\u5168\u9762\u7684\u57fa\u51c6\u8bc4\u4f30\u4f53\u7cfb\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u5bf9\u6bd4\u6d4b\u8bd5\u65f6\u8c03\u6574\uff08UniTTA\uff09\u57fa\u51c6\uff0c\u8be5\u57fa\u51c6\u65e2\u5168\u9762\u53c8\u5e7f\u6cdb\u9002\u7528\u3002\u57fa\u51c6\u4e2d\u7684\u6bcf\u4e2a\u573a\u666f\u90fd\u7531\u4e00\u4e2a\u9a6c\u5c14\u79d1\u592b\u72b6\u6001\u8f6c\u6362\u77e9\u9635\u5b8c\u6574\u63cf\u8ff0\uff0c\u7528\u4e8e\u4ece\u539f\u59cb\u6570\u636e\u96c6\u4e2d\u91c7\u6837\u3002UniTTA\u57fa\u51c6\u8003\u8651\u4e86\u57df\u548c\u7c7b\u4f5c\u4e3a\u6570\u636e\u7684\u4e24\u4e2a\u72ec\u7acb\u7ef4\u5ea6\uff0c\u5e76\u89e3\u51b3\u4e86\u4e0d\u5e73\u8861/\u5e73\u8861\u548c\u72ec\u7acb\u540c\u5206\u5e03/\u975e\u72ec\u7acb\u540c\u5206\u5e03/\u8fde\u7eed\u6761\u4ef6\u7b49\u5404\u79cd\u7ec4\u5408\uff0c\u603b\u5171\u8986\u76d6\u4e86\\( (2 \\times 3)^2 = 36 \\)\u79cd\u573a\u666f\u3002\u5b83\u4e3a\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684TTA\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u5e76\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6307\u5357\uff0c\u4ee5\u9009\u62e9\u6700\u5408\u9002\u7684TTA\u65b9\u6cd5\u3002\u4e0e\u8fd9\u4e2a\u57fa\u51c6\u4e00\u540c\u63d0\u51fa\u7684\u662f\u4e00\u79cd\u7075\u6d3b\u7684UniTTA\u6846\u67b6\uff0c\u5305\u62ec\u5e73\u8861\u57df\u5f52\u4e00\u5316\uff08BDN\uff09\u5c42\u548c\u76f8\u5173\u7279\u5f81\u8c03\u6574\uff08COFA\uff09\u65b9\u6cd5\u2014\u2014\u5206\u522b\u8bbe\u8ba1\u7528\u4e8e\u51cf\u5c11\u57df\u548c\u7c7b\u4e4b\u95f4\u7684\u5206\u5e03\u5dee\u8ddd\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684UniTTA\u6846\u67b6\u5728UniTTA\u57fa\u51c6\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u5e76\u4e14\u5e73\u5747\u6027\u80fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\u3002\u6211\u4eec\u7684\u4ee3\u7801\u53ef\u4ee5\u5728\u7f51\u5740\\url{https://github.com/LeapLabTHU/UniTTA}\u83b7\u53d6\u3002", "update_time": "2024-07-29 15:04:53+00:00", "publish_time": "2024-07-29 15:04:53+00:00"}, {"entry_id": "2407.01445v2", "title": "FastCLIP: A Suite of Optimization Techniques to Accelerate CLIP Training with Limited Resources", "summary": "Existing studies of training state-of-the-art Contrastive Language-Image\nPretraining (CLIP) models on large-scale data involve hundreds of or even\nthousands of GPUs due to the requirement of a large batch size. However, such a\nlarge amount of resources is not accessible to most people. While advanced\ncompositional optimization techniques for optimizing global contrastive losses\nhave been demonstrated effective for removing the requirement of large batch\nsize, their performance on large-scale data remains underexplored and not\noptimized. To bridge the gap, this paper explores several aspects of CLIP\ntraining with limited resources (e.g., up to tens of GPUs). First, we introduce\nFastCLIP, a general CLIP training framework built on advanced compositional\noptimization techniques while designed and optimized for the distributed\nsetting. Our framework is equipped with an efficient gradient reduction\nstrategy to reduce communication overhead. Second, to further boost training\nefficiency, we investigate three components of the framework from an\noptimization perspective: the schedule of the inner learning rate, the update\nrules of the temperature parameter and the model parameters, respectively.\nExperiments on different strategies for each component shed light on how to\nconduct CLIP training more efficiently. Finally, we benchmark the performance\nof FastCLIP and the state-of-the-art training baseline (OpenCLIP) on different\ncompute scales up to 32 GPUs on 8 nodes, and three data scales ranging from 2.7\nmillion, 9.1 million to 315 million image-text pairs to demonstrate the\nsignificant improvement of FastCLIP in the resource-limited setting. We release\nthe code of FastCLIP at https://github.com/Optimization-AI/fast_clip .", "pdf_path": null, "cn_title": "\u5feb\u901fCLIP\uff1a\u4e00\u5957\u4f18\u5316\u6280\u672f\u5957\u4ef6\uff0c\u7528\u4e8e\u5728\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u52a0\u901fCLIP\u8bad\u7ec3", "cn_summary": "\u73b0\u6709\u5bf9\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u8bad\u7ec3\u6700\u5148\u8fdb\u7684\u5bf9\u6bd4\u8bed\u8a00-\u56fe\u50cf\u9884\u8bad\u7ec3\uff08CLIP\uff09\u6a21\u578b\u7684\u7814\u7a76\uff0c\u901a\u5e38\u9700\u8981\u6570\u767e\u4e43\u81f3\u6570\u5343\u4e2aGPU\uff0c\u8fd9\u662f\u7531\u4e8e\u9700\u8981\u8f83\u5927\u7684\u6279\u6b21\u5927\u5c0f\u3002\u7136\u800c\uff0c\u5982\u6b64\u5927\u91cf\u7684\u8d44\u6e90\u5e76\u975e\u5927\u591a\u6570\u4eba\u90fd\u80fd\u83b7\u53d6\u5230\u3002\u5c3d\u7ba1\u5df2\u8bc1\u660e\u901a\u8fc7\u9ad8\u7ea7\u7ec4\u5408\u4f18\u5316\u6280\u672f\u6765\u4f18\u5316\u5168\u5c40\u5bf9\u6bd4\u635f\u5931\u53ef\u4ee5\u6709\u6548\u53bb\u9664\u5927\u6279\u6b21\u9700\u6c42\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u7684\u6027\u80fd\u4ecd\u5904\u4e8e\u672a\u5145\u5206\u63a2\u7d22\u548c\u4f18\u5316\u7684\u72b6\u6001\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u6709\u9650\u8d44\u6e90\uff08\u4f8b\u5982\u81f3\u591a\u6570\u5341\u4e2aGPU\uff09\u4e0b\u8fdb\u884cCLIP\u8bad\u7ec3\u7684\u51e0\u4e2a\u65b9\u9762\u3002\n\n\u9996\u5148\uff0c\u6211\u4eec\u5f15\u5165\u4e86FastCLIP\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u9ad8\u7ea7\u7ec4\u5408\u4f18\u5316\u6280\u672f\u6784\u5efa\u7684\u4e00\u822c\u6027CLIP\u8bad\u7ec3\u6846\u67b6\uff0c\u5e76\u9488\u5bf9\u5206\u5e03\u5f0f\u73af\u5883\u8fdb\u884c\u4e86\u8bbe\u8ba1\u548c\u4f18\u5316\u3002\u6211\u4eec\u7684\u6846\u67b6\u914d\u5907\u4e86\u4e00\u79cd\u9ad8\u6548\u68af\u5ea6\u51cf\u5c11\u7b56\u7565\uff0c\u4ee5\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u3002\u5176\u6b21\uff0c\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u5347\u8bad\u7ec3\u6548\u7387\uff0c\u4ece\u4f18\u5316\u7684\u89d2\u5ea6\u63a2\u8ba8\u4e86\u6846\u67b6\u7684\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u5185\u90e8\u5b66\u4e60\u7387\u7684\u65f6\u95f4\u8868\u3001\u6e29\u5ea6\u53c2\u6570\u7684\u66f4\u65b0\u89c4\u5219\u4ee5\u53ca\u6a21\u578b\u53c2\u6570\u7684\u66f4\u65b0\u89c4\u5219\u3002\u4e0d\u540c\u7b56\u7565\u7684\u5b9e\u9a8c\u63ed\u793a\u4e86\u5982\u4f55\u66f4\u6709\u6548\u5730\u6267\u884cCLIP\u8bad\u7ec3\u3002\n\n\u6700\u540e\uff0c\u6211\u4eec\u572832\u4e2aGPU\u5206\u5e03\u57288\u4e2a\u8282\u70b9\u4e0a\uff0c\u4ee5\u53ca\u4e09\u4e2a\u6570\u636e\u89c4\u6a21\u8303\u56f4\u5185\u7684\u5b9e\u9a8c\uff0c\u4ece270\u4e07\u3001910\u4e07\u52303.15\u4ebf\u5f20\u56fe\u50cf-\u6587\u672c\u5bf9\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u8bad\u7ec3\u57fa\u51c6\uff08OpenCLIP\uff09\u8fdb\u884c\u4e86\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u5c55\u793aFastCLIP\u5728\u8d44\u6e90\u53d7\u9650\u60c5\u51b5\u4e0b\u7684\u663e\u8457\u6539\u8fdb\u3002\u6211\u4eec\u63d0\u4f9b\u4e86FastCLIP\u7684\u4ee3\u7801\uff0c\u53d1\u5e03\u4e8ehttps://github.com/Optimization-AI/fast_clip \u3002", "update_time": "2024-07-29 15:04:15+00:00", "publish_time": "2024-07-01 16:37:18+00:00"}, {"entry_id": "2407.20070v1", "title": "An Interpretable Rule Creation Method for Black-Box Models based on Surrogate Trees -- SRules", "summary": "As artificial intelligence (AI) systems become increasingly integrated into\ncritical decision-making processes, the need for transparent and interpretable\nmodels has become paramount. In this article we present a new ruleset creation\nmethod based on surrogate decision trees (SRules), designed to improve the\ninterpretability of black-box machine learning models. SRules balances the\naccuracy, coverage, and interpretability of machine learning models by\nrecursively creating surrogate interpretable decision tree models that\napproximate the decision boundaries of a complex model. We propose a systematic\nframework for generating concise and meaningful rules from these surrogate\nmodels, allowing stakeholders to understand and trust the AI system's\ndecision-making process. Our approach not only provides interpretable rules,\nbut also quantifies the confidence and coverage of these rules. The proposed\nmodel allows to adjust its parameters to counteract the lack of\ninterpretability by precision and coverage by allowing a near perfect fit and\nhigh interpretability of some parts of the model . The results show that SRules\nimproves on other state-of-the-art techniques and introduces the possibility of\ncreating highly interpretable specific rules for specific sub-parts of the\nmodel.", "pdf_path": null, "cn_title": "\u57fa\u4e8e\u66ff\u4ee3\u6811\u7684\u9ed1\u76d2\u6a21\u578b\u53ef\u89e3\u91ca\u89c4\u5219\u751f\u6210\u65b9\u6cd5\u2014\u2014SRules", "cn_summary": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u7cfb\u7edf\u5728\u5173\u952e\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u65e5\u76ca\u6574\u5408\uff0c\u5bf9\u900f\u660e\u548c\u53ef\u89e3\u91ca\u6a21\u578b\u7684\u9700\u6c42\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7406\u51b3\u7b56\u6811\uff08SRules\uff09\u7684\u65b0\u89c4\u5219\u96c6\u521b\u5efa\u65b9\u6cd5\uff0c\u65e8\u5728\u6539\u8fdb\u9ed1\u76d2\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002SRules\u901a\u8fc7\u9012\u5f52\u521b\u5efa\u8fd1\u4f3c\u590d\u6742\u6a21\u578b\u51b3\u7b56\u8fb9\u754c\u7684\u53ef\u89e3\u91ca\u51b3\u7b56\u6811\u6a21\u578b\uff0c\u5e73\u8861\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u51c6\u786e\u5ea6\u3001\u8986\u76d6\u8303\u56f4\u548c\u53ef\u89e3\u91ca\u6027\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u5957\u7cfb\u7edf\u6846\u67b6\uff0c\u4ece\u8fd9\u4e9b\u4ee3\u7406\u6a21\u578b\u4e2d\u751f\u6210\u7b80\u6d01\u4e14\u6709\u610f\u4e49\u7684\u89c4\u5219\uff0c\u4f7f\u5229\u76ca\u76f8\u5173\u8005\u80fd\u591f\u7406\u89e3\u548c\u4fe1\u4efbAI\u7cfb\u7edf\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u89c4\u5219\uff0c\u800c\u4e14\u8fd8\u91cf\u5316\u4e86\u8fd9\u4e9b\u89c4\u5219\u7684\u7f6e\u4fe1\u5ea6\u548c\u8986\u76d6\u7387\u3002\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5141\u8bb8\u8c03\u6574\u5176\u53c2\u6570\u4ee5\u62b5\u6d88\u53ef\u89e3\u91ca\u6027\u7684\u7f3a\u4e4f\uff0c\u5e76\u901a\u8fc7\u5141\u8bb8\u5bf9\u6a21\u578b\u7684\u90e8\u5206\u8fdb\u884c\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u62df\u5408\u548c\u9ad8\u53ef\u89e3\u91ca\u6027\u6765\u63d0\u9ad8\u7cbe\u786e\u5ea6\u548c\u8986\u76d6\u7387\u3002\u7ed3\u679c\u663e\u793a\uff0cSRules\u5728\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u6280\u672f\u4e0a\u6709\u6240\u6539\u8fdb\uff0c\u5e76\u5f15\u5165\u4e86\u4e3a\u6a21\u578b\u7279\u5b9a\u5b50\u90e8\u5206\u521b\u5efa\u9ad8\u5ea6\u53ef\u89e3\u91ca\u7684\u7279\u5b9a\u89c4\u5219\u7684\u53ef\u80fd\u6027\u3002", "update_time": "2024-07-29 14:56:56+00:00", "publish_time": "2024-07-29 14:56:56+00:00"}]