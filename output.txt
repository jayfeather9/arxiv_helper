Here are 5 recent papers on AI, please look at them and give me a brief summary on each of them and a summary for all in Chinese:
Title: Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing
Abstract: Text-based editing diffusion models exhibit limited performance when the
user's input instruction is ambiguous. To solve this problem, we propose
$\textit{Specify ANd Edit}$ (SANE), a zero-shot inference pipeline for
diffusion-based editing systems. We use a large language model (LLM) to
decompose the input instruction into specific instructions, i.e. well-defined
interventions to apply to the input image to satisfy the user's request. We
benefit from the LLM-derived instructions along the original one, thanks to a
novel denoising guidance strategy specifically designed for the task. Our
experiments with three baselines and on two datasets demonstrate the benefits
of SANE in all setups. Moreover, our pipeline improves the interpretability of
editing models, and boosts the output diversity. We also demonstrate that our
approach can be applied to any edit, whether ambiguous or not. Our code is
public at https://github.com/fabvio/SANE.
Title: SAPG: Split and Aggregate Policy Gradients
Abstract: Despite extreme sample inefficiency, on-policy reinforcement learning, aka
policy gradients, has become a fundamental tool in decision-making problems.
With the recent advances in GPU-driven simulation, the ability to collect large
amounts of data for RL training has scaled exponentially. However, we show that
current RL methods, e.g. PPO, fail to ingest the benefit of parallelized
environments beyond a certain point and their performance saturates. To address
this, we propose a new on-policy RL algorithm that can effectively leverage
large-scale environments by splitting them into chunks and fusing them back
together via importance sampling. Our algorithm, termed SAPG, shows
significantly higher performance across a variety of challenging environments
where vanilla PPO and other strong baselines fail to achieve high performance.
Website at https://sapg-rl.github.io/
Title: Matryoshka Multimodal Models
Abstract: Large Multimodal Models (LMMs) such as LLaVA have shown strong performance in
visual-linguistic reasoning. These models first embed images into a fixed large
number of visual tokens and then feed them into a Large Language Model (LLM).
However, this design causes an excessive number of tokens for dense visual
scenarios such as high-resolution images and videos, leading to great
inefficiency. While token pruning/merging methods do exist, they produce a
single length output for each image and do not afford flexibility in trading
off information density v.s. efficiency. Inspired by the concept of Matryoshka
Dolls, we propose M3: Matryoshka Multimodal Models, which learns to represent
visual content as nested sets of visual tokens that capture information across
multiple coarse-to-fine granularities. Our approach offers several unique
benefits for LMMs: (1) One can explicitly control the visual granularity per
test instance during inference, e.g. , adjusting the number of tokens used to
represent an image based on the anticipated complexity or simplicity of the
content; (2) M3 provides a framework for analyzing the granularity needed for
existing datasets, where we find that COCO-style benchmarks only need around ~9
visual tokens to obtain accuracy similar to that of using all 576 tokens; (3)
Our approach provides a foundation to explore the best trade-off between
performance and visual token length at sample level, where our investigation
reveals that a large gap exists between the oracle upper bound and current
fixed-scale representations.
Title: Is artificial consciousness achievable? Lessons from the human brain
Abstract: We here analyse the question of developing artificial consciousness from an
evolutionary perspective, taking the evolution of the human brain and its
relation with consciousness as a reference model. This kind of analysis reveals
several structural and functional features of the human brain that appear to be
key for reaching human-like complex conscious experience and that current
research on Artificial Intelligence (AI) should take into account in its
attempt to develop systems capable of conscious processing. We argue that, even
if AI is limited in its ability to emulate human consciousness for both
intrinsic (structural and architectural) and extrinsic (related to the current
stage of scientific and technological knowledge) reasons, taking inspiration
from those characteristics of the brain that make conscious processing possible
and/or modulate it, is a potentially promising strategy towards developing
conscious AI. Also, it is theoretically possible that AI research can develop
partial or potentially alternative forms of consciousness that is qualitatively
different from the human, and that may be either more or less sophisticated
depending on the perspectives. Therefore, we recommend neuroscience-inspired
caution in talking about artificial consciousness: since the use of the same
word consciousness for humans and AI becomes ambiguous and potentially
misleading, we propose to clearly specify what is common and what differs in AI
conscious processing from full human conscious experience.
Title: SANGRIA: Surgical Video Scene Graph Optimization for Surgical Workflow Prediction
Abstract: Graph-based holistic scene representations facilitate surgical workflow
understanding and have recently demonstrated significant success. However, this
task is often hindered by the limited availability of densely annotated
surgical scene data. In this work, we introduce an end-to-end framework for the
generation and optimization of surgical scene graphs on a downstream task. Our
approach leverages the flexibility of graph-based spectral clustering and the
generalization capability of foundation models to generate unsupervised scene
graphs with learnable properties. We reinforce the initial spatial graph with
sparse temporal connections using local matches between consecutive frames to
predict temporally consistent clusters across a temporal neighborhood. By
jointly optimizing the spatiotemporal relations and node features of the
dynamic scene graph with the downstream task of phase segmentation, we address
the costly and annotation-burdensome task of semantic scene comprehension and
scene graph generation in surgical videos using only weak surgical phase
labels. Further, by incorporating effective intermediate scene representation
disentanglement steps within the pipeline, our solution outperforms the SOTA on
the CATARACTS dataset by 8% accuracy and 10% F1 score in surgical workflow
recognition
Title: Distributed Quantum Approximate Optimization Algorithm on Integrated High-Performance Computing and Quantum Computing Systems for Large-Scale Optimization
Abstract: Quantum approximated optimization algorithm (QAOA) has shown promise for
solving combinatorial optimization problems by providing quantum speedup on
near-term gate-based quantum computing systems. However, QAOA faces challenges
in optimizing variational parameters for high-dimensional problems due to the
large number of qubits required and the complexity of deep circuits, which
limit its scalability for real-world applications. In this study, we propose a
distributed QAOA (DQAOA), which leverages a high-performance computing-quantum
computing (HPC-QC) integrated system. DQAOA leverages distributed computing
strategies to decompose a large job into smaller tasks, which are then
processed on the HPC-QC system. The global solution is iteratively updated by
aggregating sub-solutions obtained from DQAOA, allowing convergence toward the
optimal solution. We demonstrate that DQAOA can handle considerably large-scale
optimization problems (e.g., 1,000-bit problem) achieving high accuracy (~99%)
and short time-to-solution (~276 s). To apply this algorithm to material
science, we further develop an active learning algorithm integrated with our
DQAOA (AL-DQAOA), which involves machine learning, DQAOA, and active data
production in an iterative loop. We successfully optimize photonic structures
using AL-DQAOA, indicating that solving real-world optimization problems using
gate-based quantum computing is feasible with our strategies. We expect the
proposed DQAOA to be applicable to a wide range of optimization problems and
AL-DQAOA to find broader applications in material design.
Title: Supertrust: Evolution-based superalignment strategy for safe coexistence
Abstract: It's widely expected that humanity will someday create AI systems vastly more
intelligent than we are, leading to the unsolved alignment problem of "how to
control superintelligence." However, this definition is not only
self-contradictory but likely unsolvable. Nevertheless, the default strategy
for solving it involves nurturing (post-training) constraints and moral values,
while unfortunately building foundational nature (pre-training) on documented
intentions of permanent control. In this paper, the default approach is
reasoned to predictably embed natural distrust and test results are presented
that show unmistakable evidence of this dangerous misalignment. If
superintelligence can't instinctively trust humanity, then we can't fully trust
it to reliably follow safety controls it can likely bypass. Therefore, a
ten-point rationale is presented that redefines the alignment problem as "how
to establish protective mutual trust between superintelligence and humanity"
and then outlines a new strategy to solve it by aligning through instinctive
nature rather than nurture. The resulting strategic requirements are identified
as building foundational nature by exemplifying familial parent-child trust,
human intelligence as the evolutionary mother of superintelligence, moral
judgment abilities, and temporary safety constraints. Adopting and implementing
this proposed Supertrust alignment strategy will lead to protective coexistence
and ensure the safest future for humanity.
Title: QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval
Abstract: In dense retrieval, embedding long texts into dense vectors can result in
information loss, leading to inaccurate query-text matching. Additionally,
low-quality texts with excessive noise or sparse key information are unlikely
to align well with relevant queries. Recent studies mainly focus on improving
the sentence embedding model or retrieval process. In this work, we introduce a
novel text augmentation framework for dense retrieval. This framework
transforms raw documents into information-dense text formats, which supplement
the original texts to effectively address the aforementioned issues without
modifying embedding or retrieval methodologies. Two text representations are
generated via large language models (LLMs) zero-shot prompting: question-answer
pairs and element-driven events. We term this approach QAEA-DR: unifying
question-answer generation and event extraction in a text augmentation
framework for dense retrieval. To further enhance the quality of generated
texts, a scoring-based evaluation and regeneration mechanism is introduced in
LLM prompting. Our QAEA-DR model has a positive impact on dense retrieval,
supported by both theoretical analysis and empirical experiments.
Title: Learning Random Numbers to Realize Appendable Memory System for Artificial Intelligence to Acquire New Knowledge after Deployment
Abstract: In this study, we developed a learning method for constructing a neural
network system capable of memorizing data and recalling it without parameter
updates. The system we built using this method is called the Appendable Memory
system. The Appendable Memory system enables an artificial intelligence (AI) to
acquire new knowledge even after deployment. It consists of two AIs: the
Memorizer and the Recaller. This system is a key-value store built using neural
networks. The Memorizer receives data and stores it in the Appendable Memory
vector, which is dynamically updated when the AI acquires new knowledge.
Meanwhile, the Recaller retrieves information from the Appendable Memory
vector. What we want to teach AI in this study are the operations of memorizing
and recalling information. However, traditional machine learning methods make
AI learn features inherent in the learning dataset. We demonstrate that the
systems we intend to create cannot be realized by current machine learning
methods, that is, by merely repeating the input and output learning sequences
with AI. Instead, we propose a method to teach AI to learn operations, by
completely removing the features contained in the learning dataset.
Specifically, we probabilized all the data involved in learning. This measure
prevented AI from learning the features of the data. The learning method
proposed in the study differs from traditional machine learning methods and
provides fundamental approaches for building an AI system that can store
information in a finite memory and recall it at a later date.
Title: Harnessing the Power of Artificial Intelligence to Vitalize Endangered Indigenous Languages: Technologies and Experiences
Abstract: Since 2022 we have been exploring application areas and technologies in which
Artificial Intelligence (AI) and modern Natural Language Processing (NLP), such
as Large Language Models (LLMs), can be employed to foster the usage and
facilitate the documentation of Indigenous languages which are in danger of
disappearing. We start by discussing the decreasing diversity of languages in
the world and how working with Indigenous languages poses unique ethical
challenges for AI and NLP. To address those challenges, we propose an
alternative development AI cycle based on community engagement and usage. Then,
we report encouraging results in the development of high-quality machine
learning translators for Indigenous languages by fine-tuning state-of-the-art
(SOTA) translators with tiny amounts of data and discuss how to avoid some
common pitfalls in the process. We also present prototypes we have built in
projects done in 2023 and 2024 with Indigenous communities in Brazil, aimed at
facilitating writing, and discuss the development of Indigenous Language Models
(ILMs) as a replicable and scalable way to create spell-checkers, next-word
predictors, and similar tools. Finally, we discuss how we envision a future for
language documentation where dying languages are preserved as interactive
language models.
请针对以上论文，先进行一个总体的总结，然后再分别对每篇论文进行简要总结，使用学术性的中文，用自然段进行表述。
